import streamlit as st
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np

# Set page configuration
st.set_page_config(
    page_title="An√°lise de Classificadores",
    page_icon="üìä",
    layout="wide"
)

# Title
st.markdown("<h1 style='text-align: center;'>Minera√ß√£o de Dados</h1>", unsafe_allow_html=True)
st.title("An√°lise de Classificadores de Machine Learning")

# Authors information
st.sidebar.image("cin.png", use_column_width=True)

st.sidebar.markdown("""
### Autores
- Fagner Fernandes
  - [LinkedIn](linkedin.com/in/fagner-fernandes-38a25a3b)
- William Lapa Santos Filho
  - [LinkedIn](www.linkedin.com/in/william-lapa)
""")

# Sidebar menu
menu = st.sidebar.selectbox(
    "Menu",
    ["An√°lise Estat√≠stica", "Par√¢metros dos Classificadores", "An√°lise de Custo x Benef√≠cio", "Balanceamento classes ADASYN", "Base Treino x Teste", "Explainable AI", "Downloads"]
)

# Add development information
st.sidebar.markdown("""
Aplicativo desenvolvido em Dezembro de 2024 como produto dos estudos realizados na disciplina **Minera√ß√£o de Dados**
""")

# Load data
@st.cache_data
def load_data():
    friedman_results = pd.read_csv('friedman_results.csv', index_col=0)
    nemenyi_accuracy = pd.read_csv('nemenyi_results_Accuracy.csv', index_col=0)
    nemenyi_f1 = pd.read_csv('nemenyi_results_F1 Score.csv', index_col=0)
    nemenyi_recall = pd.read_csv('nemenyi_results_Recall.csv', index_col=0)
    nemenyi_acsa = pd.read_csv('nemenyi_results_ACSA.csv', index_col=0)
    performance_metrics = pd.read_excel('results_with_cost_benefit.xlsx')
    adasyn_results = pd.read_excel('results_adasyn_comparison.xlsx')
    train_test_results = pd.read_excel('results_train_teste_comparison.xlsx')
    return friedman_results, nemenyi_accuracy, nemenyi_f1, nemenyi_recall, nemenyi_acsa, performance_metrics, adasyn_results, train_test_results

# Function to create heatmap
def plot_heatmap(data, title):
    plt.figure(figsize=(10, 8))
    sns.heatmap(data, annot=True, cmap='YlGnBu', fmt='.3f')
    plt.title(title)
    return plt

if menu == "An√°lise Estat√≠stica":
    st.header("Resultados das An√°lises Estat√≠sticas")
    
    try:
        # Load data
        friedman_results, nemenyi_accuracy, nemenyi_f1, nemenyi_recall, nemenyi_acsa, _, _, _ = load_data()
        
        # Display Friedman results with full P-value precision
        st.subheader("Resultados do Teste de Friedman")
        
        # Format P-value to show all decimal places
        friedman_results_formatted = friedman_results.copy()
        friedman_results_formatted['P-value'] = friedman_results_formatted['P-value'].apply(lambda x: f"{x:.20f}")
        
        # Display formatted results
        st.dataframe(friedman_results_formatted)
        
        # Display Nemenyi results with tabs
        st.subheader("Resultados do Teste de Nemenyi")
        tab1, tab2, tab3, tab4 = st.tabs(["Accuracy", "F1 Score", "Recall", "ACSA"])
        
        with tab1:
            st.pyplot(plot_heatmap(nemenyi_accuracy, "Teste de Nemenyi - Accuracy"))
            
        with tab2:
            st.pyplot(plot_heatmap(nemenyi_f1, "Teste de Nemenyi - F1 Score"))
            
        with tab3:
            st.pyplot(plot_heatmap(nemenyi_recall, "Teste de Nemenyi - Recall"))
            
        with tab4:
            st.pyplot(plot_heatmap(nemenyi_acsa, "Teste de Nemenyi - ACSA"))
            
    except Exception as e:
        st.error(f"Erro ao carregar os dados: {str(e)}")

elif menu == "Par√¢metros dos Classificadores":
    st.header("Par√¢metros dos Classificadores")
    
    try:
        # Load performance metrics
        _, _, _, _, _, performance_metrics, _, _ = load_data()
        
        # Dictionary with classifier parameters and optimization info
        classifiers = {
            'KNN': {
                'params': {
                    'n_neighbors': 1,
                    'p': 1,
                    'weights': 'uniform'
                },
                'optimization': 'Bayesian Search',
                'default_desc': None,  # N√£o necess√°rio pois est√° otimizado
                'performance': {
                    'training_time': performance_metrics.loc[performance_metrics['Unnamed: 0'] == 'KNN', 'Training Time (s)'].values[0],
                    'memory_usage': performance_metrics.loc[performance_metrics['Unnamed: 0'] == 'KNN', 'Memory Usage (MB)'].values[0]
                }
            },
            'SVM': {
                'params': 'Par√¢metros padr√£o',
                'optimization': 'Nenhuma otimiza√ß√£o',
                'default_desc': """
                - kernel='rbf' (Fun√ß√£o de kernel Gaussiana)
                - C=1.0 (Par√¢metro de regulariza√ß√£o)
                - gamma='scale' (Coeficiente do kernel)
                - probability=True (Habilita estimativas de probabilidade)
                """,
                'performance': {
                    'training_time': performance_metrics.loc[performance_metrics['Unnamed: 0'] == 'SVM', 'Training Time (s)'].values[0],
                    'memory_usage': performance_metrics.loc[performance_metrics['Unnamed: 0'] == 'SVM', 'Memory Usage (MB)'].values[0]
                }
            },
            'Decision Tree': {
                'params': {
                    'criterion': 'entropy',
                    'max_depth': 36,
                    'min_samples_leaf': 1,
                    'min_samples_split': 2
                },
                'optimization': 'Bayesian Search',
                'default_desc': None,  # N√£o necess√°rio pois est√° otimizado
                'performance': {
                    'training_time': performance_metrics.loc[performance_metrics['Unnamed: 0'] == 'Decision Tree', 'Training Time (s)'].values[0],
                    'memory_usage': performance_metrics.loc[performance_metrics['Unnamed: 0'] == 'Decision Tree', 'Memory Usage (MB)'].values[0]
                }
            },
            'LVQ': {
                'params': 'Par√¢metros padr√£o',
                'optimization': 'Nenhuma otimiza√ß√£o',
                'default_desc': """
                - n_neighbors=3 (N√∫mero de vizinhos)
                - weights='distance' (Pondera√ß√£o por dist√¢ncia)
                - prototypes_per_class=3 (Prot√≥tipos por classe)
                """,
                'performance': {
                    'training_time': performance_metrics.loc[performance_metrics['Unnamed: 0'] == 'LVQ', 'Training Time (s)'].values[0],
                    'memory_usage': performance_metrics.loc[performance_metrics['Unnamed: 0'] == 'LVQ', 'Memory Usage (MB)'].values[0]
                }
            },
            'MLP': {
                'params': 'Par√¢metros padr√£o',
                'optimization': 'Nenhuma otimiza√ß√£o',
                'default_desc': """
                - hidden_layer_sizes=(100,) (Uma camada oculta com 100 neur√¥nios)
                - activation='relu' (Fun√ß√£o de ativa√ß√£o ReLU)
                - solver='adam' (Otimizador Adam)
                - learning_rate='constant' (Taxa de aprendizado constante)
                - max_iter=200 (M√°ximo de itera√ß√µes)
                """,
                'performance': {
                    'training_time': performance_metrics.loc[performance_metrics['Unnamed: 0'] == 'MLP', 'Training Time (s)'].values[0],
                    'memory_usage': performance_metrics.loc[performance_metrics['Unnamed: 0'] == 'MLP', 'Memory Usage (MB)'].values[0]
                }
            },
            'Ensemble Neural Network': {
                'params': 'Par√¢metros padr√£o',
                'optimization': 'Nenhuma otimiza√ß√£o',
                'default_desc': """
                Conjunto de 3 MLPs com:
                - hidden_layer_sizes=(100,) (Uma camada oculta com 100 neur√¥nios)
                - activation='relu' (Fun√ß√£o de ativa√ß√£o ReLU)
                - solver='adam' (Otimizador Adam)
                - max_iter=200 (M√°ximo de itera√ß√µes)
                """,
                'performance': {
                    'training_time': performance_metrics.loc[performance_metrics['Unnamed: 0'] == 'Ensemble Neural Network', 'Training Time (s)'].values[0],
                    'memory_usage': performance_metrics.loc[performance_metrics['Unnamed: 0'] == 'Ensemble Neural Network', 'Memory Usage (MB)'].values[0]
                }
            },
            'Stacking': {
                'params': 'Par√¢metros padr√£o',
                'optimization': 'Nenhuma otimiza√ß√£o',
                'default_desc': """
                Meta-classificador: Regress√£o Log√≠stica com:
                - C=1.0 (Par√¢metro de regulariza√ß√£o)
                - solver='lbfgs' (Otimizador LBFGS)
                - max_iter=100 (M√°ximo de itera√ß√µes)
                
                Classificadores base:
                - Random Forest
                - SVM
                - KNN
                """,
                'performance': {
                    'training_time': performance_metrics.loc[performance_metrics['Unnamed: 0'] == 'Stacking', 'Training Time (s)'].values[0],
                    'memory_usage': performance_metrics.loc[performance_metrics['Unnamed: 0'] == 'Stacking', 'Memory Usage (MB)'].values[0]
                }
            },
            'Random Forest': {
                'params': {
                    'max_depth': 28,
                    'n_estimators': 97
                },
                'optimization': 'Optuna',
                'default_desc': None,  # N√£o necess√°rio pois est√° otimizado
                'performance': {
                    'training_time': performance_metrics.loc[performance_metrics['Unnamed: 0'] == 'Random Forest', 'Training Time (s)'].values[0],
                    'memory_usage': performance_metrics.loc[performance_metrics['Unnamed: 0'] == 'Random Forest', 'Memory Usage (MB)'].values[0]
                }
            },
            'XGBoost': {
                'params': {
                    'objective': 'binary:logistic',
                    'enable_categorical': False,
                    'eval_metric': 'logloss',
                    'learning_rate': 0.09504317284612004,
                    'max_depth': 6,
                    'n_estimators': 188
                },
                'optimization': 'Optuna',
                'default_desc': None,  # N√£o necess√°rio pois est√° otimizado
                'performance': {
                    'training_time': performance_metrics.loc[performance_metrics['Unnamed: 0'] == 'XGBoost', 'Training Time (s)'].values[0],
                    'memory_usage': performance_metrics.loc[performance_metrics['Unnamed: 0'] == 'XGBoost', 'Memory Usage (MB)'].values[0]
                }
            },
            'LightGBM': {
                'params': 'Par√¢metros padr√£o',
                'optimization': 'Nenhuma otimiza√ß√£o',
                'default_desc': """
                - learning_rate=0.1 (Taxa de aprendizado)
                - n_estimators=100 (N√∫mero de √°rvores)
                - max_depth=-1 (Profundidade m√°xima ilimitada)
                - num_leaves=31 (N√∫mero m√°ximo de folhas)
                - min_child_samples=20 (Amostras m√≠nimas por n√≥ folha)
                - objective='binary' (Objetivo para classifica√ß√£o bin√°ria)
                """,
                'performance': {
                    'training_time': performance_metrics.loc[performance_metrics['Unnamed: 0'] == 'LightGBM', 'Training Time (s)'].values[0],
                    'memory_usage': performance_metrics.loc[performance_metrics['Unnamed: 0'] == 'LightGBM', 'Memory Usage (MB)'].values[0]
                }
            }
        }
        
        # Create tabs for each classifier
        tabs = st.tabs(list(classifiers.keys()))
        
        # Display information in each tab
        for tab, (classifier_name, info) in zip(tabs, classifiers.items()):
            with tab:
                st.subheader(f"{classifier_name}")
                
                # Display optimization method
                st.markdown(f"**M√©todo de Otimiza√ß√£o:** {info['optimization']}")
                
                # Display parameters
                st.markdown("**Par√¢metros:**")
                if isinstance(info['params'], dict):
                    for param, value in info['params'].items():
                        st.write(f"- {param}: {value}")
                else:
                    st.write(info['params'])
                    if info['default_desc']:
                        st.markdown("**Descri√ß√£o dos Par√¢metros Padr√£o:**")
                        st.markdown(info['default_desc'])
                
                # Display performance metrics
                st.markdown("**M√©tricas de Desempenho:**")
                st.write(f"- Tempo de Treinamento: {info['performance']['training_time']:.2f} segundos")
                st.write(f"- Uso de Mem√≥ria: {info['performance']['memory_usage']:.2f} MB")
    except Exception as e:
        st.error(f"Erro ao carregar os dados: {str(e)}")

elif menu == "An√°lise de Custo x Benef√≠cio":
    st.header("An√°lise de Custo x Benef√≠cio dos Classificadores")
    
    try:
        # Load performance metrics
        _, _, _, _, _, performance_metrics, _, _ = load_data()
        
        # Criar DataFrame com m√©tricas de desempenho
        cost_benefit_df = pd.DataFrame({
            'Classificador': performance_metrics['Unnamed: 0'],
            'Tempo de Treinamento (s)': performance_metrics['Training Time (s)'].round(2),
            'Uso de Mem√≥ria (MB)': performance_metrics['Memory Usage (MB)'].round(2),
            'Accuracy': performance_metrics['Accuracy'].round(4),
            'F1 Score': performance_metrics['F1 Score'].round(4),
            'Recall': performance_metrics['Recall'].round(4),
            'ACSA': performance_metrics['ACSA'].round(4)
        })
        
        # Exibir tabela com todas as m√©tricas
        st.subheader("Tabela Comparativa")
        st.dataframe(cost_benefit_df.style.highlight_max(axis=0, color='lightgreen', subset=['Accuracy', 'F1 Score', 'Recall', 'ACSA'])
                                        .highlight_min(axis=0, color='lightpink', subset=['Tempo de Treinamento (s)', 'Uso de Mem√≥ria (MB)']))
        
        # Criar gr√°ficos
        st.subheader("Visualiza√ß√µes")
        
        # Criar duas colunas para os gr√°ficos
        col1, col2 = st.columns(2)
        
        with col1:
            # Gr√°fico de Tempo de Treinamento
            fig_time = plt.figure(figsize=(10, 6))
            plt.barh(cost_benefit_df['Classificador'], cost_benefit_df['Tempo de Treinamento (s)'])
            plt.title('Tempo de Treinamento por Classificador')
            plt.xlabel('Tempo (segundos)')
            plt.ylabel('Classificador')
            st.pyplot(fig_time)
        
        with col2:
            # Gr√°fico de Uso de Mem√≥ria
            fig_memory = plt.figure(figsize=(10, 6))
            plt.barh(cost_benefit_df['Classificador'], cost_benefit_df['Uso de Mem√≥ria (MB)'])
            plt.title('Uso de Mem√≥ria por Classificador')
            plt.xlabel('Mem√≥ria (MB)')
            plt.ylabel('Classificador')
            st.pyplot(fig_memory)      
                
        # Adicionar algumas observa√ß√µes
        st.subheader("Observa√ß√µes")
        st.markdown("""
        - Os valores em verde na tabela indicam os melhores resultados para m√©tricas de desempenho (Accuracy, F1 Score, Recall, ACSA)
        - Os valores em rosa na tabela indicam os menores valores para m√©tricas de custo (Tempo de Treinamento, Uso de Mem√≥ria)
        """)
        
    except Exception as e:
        st.error(f"Erro ao carregar os dados: {str(e)}")

elif menu == "Balanceamento classes ADASYN":
    st.header("Balanceamento de Classes usando ADASYN")
    
    try:
        # Load ADASYN results
        _, _, _, _, _, _, adasyn_results, _ = load_data()
        
        tab1, tab2 = st.tabs(["Distribui√ß√£o de Classes", "Resultados"])
        
        with tab1:
            st.subheader("Distribui√ß√£o de Classes")
            st.image("class_distribution.png", caption="Distribui√ß√£o de Classes antes e depois do ADASYN", use_column_width=True)
            
        with tab2:
            st.subheader("Resultados ap√≥s ADASYN")
            
            # Display the results dataframe
            if not adasyn_results.empty:
                st.dataframe(adasyn_results, use_container_width=True)
            else:
                st.error("N√£o foi poss√≠vel carregar os resultados do ADASYN.")
                
    except Exception as e:
        st.error(f"Erro ao carregar os dados: {str(e)}")

elif menu == "Base Treino x Teste":
    st.header("Compara√ß√£o entre Base de Treino e Teste")
    
    try:
        # Load train-test comparison results
        _, _, _, _, _, _, _, train_test_results = load_data()
        
        # Display the results
        st.dataframe(train_test_results)
            
    except Exception as e:
        st.error(f"Erro ao carregar os dados de compara√ß√£o treino-teste: {str(e)}")

elif menu == "Explainable AI":
    st.header("Explainable AI - LIME Results")
    
    tab1, tab2 = st.tabs(["KNN", "XGBoost"])
    
    with tab1:
        st.subheader("LIME Results for KNN")
        
        # Display KNN parameters
        st.markdown("### KNN Parameters")
        st.markdown("""
        - n_neighbors: 1
        - weights: uniform
        - p: 1 (Manhattan distance)
        """)
        
        # Display LIME results image
        st.image("lime_results_knn.png", caption="LIME Results for KNN", use_column_width=True)
        
    with tab2:
        st.subheader("LIME Results for XGBoost")
        
        # Display XGBoost parameters
        st.markdown("### XGBoost Parameters")
        st.markdown("""
        - objective: binary:logistic
        - enable_categorical: False
        - eval_metric: logloss
        - learning_rate: 0.09504
        - max_depth: 6
        - n_estimators: 188
        """)
        
        # Display LIME results image
        st.image("lime_results_xgboost.png", caption="LIME Results for XGBoost", use_column_width=True)

elif menu == "Downloads":
    st.header("Downloads dos Notebooks")
    
    st.markdown("""
    ### Notebooks Dispon√≠veis
    
    Aqui voc√™ pode baixar os notebooks utilizados na an√°lise:
    """)
    
    # Function to read file as bytes
    def get_binary_file_downloader_html(file_path, file_label):
        with open(file_path, 'rb') as f:
            data = f.read()
        return st.download_button(
            label=f"Download {file_label}",
            data=data,
            file_name=file_path.split('/')[-1],
            mime='application/x-ipynb+json'
        )
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("#### An√°lise Estat√≠stica")
        st.markdown("Notebook contendo a an√°lise estat√≠stica dos resultados usando os testes de Friedman e Nemenyi.")
        get_binary_file_downloader_html('notebook_estatistica.ipynb', 'An√°lise Estat√≠stica')
    
    with col2:
        st.markdown("#### Experimentos")
        st.markdown("Notebook contendo os experimentos realizados com os diferentes classificadores.")
        get_binary_file_downloader_html('notebook_experimento.ipynb', 'Experimentos')
