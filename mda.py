import streamlit as st
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np

# Set page configuration
st.set_page_config(
    page_title="An치lise de Classificadores",
    page_icon="游늵",
    layout="wide"
)

# Title
st.title("An치lise de Classificadores de Machine Learning")

# Authors information
st.sidebar.markdown("""
### Autores
- Fagner Fernandes
  - [LinkedIn](linkedin.com/in/fagner-fernandes-38a25a3b)
- William Lapa Santos Filho
  - [LinkedIn](www.linkedin.com/in/william-lapa)
""")

# Sidebar menu
menu = st.sidebar.selectbox(
    "Menu",
    ["An치lise Estat칤stica", "Par칙metros dos Classificadores", "An치lise de Custo x Benef칤cio", "Balanceamento de classes ap칩s ADASYN", "Resultados dos classificadores ap칩s ADASYN", "Base Treino x Teste", "Downloads"]
)

# Load data
@st.cache_data
def load_data():
    friedman_results = pd.read_csv('friedman_results.csv', index_col=0)
    nemenyi_accuracy = pd.read_csv('nemenyi_results_Accuracy.csv', index_col=0)
    nemenyi_f1 = pd.read_csv('nemenyi_results_F1 Score.csv', index_col=0)
    nemenyi_recall = pd.read_csv('nemenyi_results_Recall.csv', index_col=0)
    nemenyi_acsa = pd.read_csv('nemenyi_results_ACSA.csv', index_col=0)
    performance_metrics = pd.read_excel('results_with_cost_benefit.xlsx')
    adasyn_results = pd.read_excel('results_adasyn_comparison.xlsx')
    train_test_results = pd.read_excel('results_train_teste_comparison.xlsx')
    return friedman_results, nemenyi_accuracy, nemenyi_f1, nemenyi_recall, nemenyi_acsa, performance_metrics, adasyn_results, train_test_results

# Function to create heatmap
def plot_heatmap(data, title):
    plt.figure(figsize=(10, 8))
    sns.heatmap(data, annot=True, cmap='YlGnBu', fmt='.3f')
    plt.title(title)
    return plt

if menu == "An치lise Estat칤stica":
    st.header("Resultados das An치lises Estat칤sticas")
    
    try:
        # Load data
        friedman_results, nemenyi_accuracy, nemenyi_f1, nemenyi_recall, nemenyi_acsa, _, _, _ = load_data()
        
        # Display Friedman results with full P-value precision
        st.subheader("Resultados do Teste de Friedman")
        
        # Format P-value to show all decimal places
        friedman_results_formatted = friedman_results.copy()
        friedman_results_formatted['P-value'] = friedman_results_formatted['P-value'].apply(lambda x: f"{x:.20f}")
        
        # Display formatted results
        st.dataframe(friedman_results_formatted)
        
        # Display Nemenyi results with tabs
        st.subheader("Resultados do Teste de Nemenyi")
        tab1, tab2, tab3, tab4 = st.tabs(["Accuracy", "F1 Score", "Recall", "ACSA"])
        
        with tab1:
            st.pyplot(plot_heatmap(nemenyi_accuracy, "Teste de Nemenyi - Accuracy"))
            
        with tab2:
            st.pyplot(plot_heatmap(nemenyi_f1, "Teste de Nemenyi - F1 Score"))
            
        with tab3:
            st.pyplot(plot_heatmap(nemenyi_recall, "Teste de Nemenyi - Recall"))
            
        with tab4:
            st.pyplot(plot_heatmap(nemenyi_acsa, "Teste de Nemenyi - ACSA"))
            
    except Exception as e:
        st.error(f"Erro ao carregar os dados: {str(e)}")

elif menu == "Par칙metros dos Classificadores":
    st.header("Par칙metros dos Classificadores")
    
    try:
        # Load performance metrics
        _, _, _, _, _, performance_metrics, _, _ = load_data()
        
        # Dictionary with classifier parameters and optimization info
        classifiers = {
            'KNN': {
                'params': {
                    'n_neighbors': 1,
                    'p': 1,
                    'weights': 'uniform'
                },
                'optimization': 'Bayesian Search',
                'default_desc': None,  # N칚o necess치rio pois est치 otimizado
                'performance': {
                    'training_time': performance_metrics.loc[performance_metrics['Unnamed: 0'] == 'KNN', 'Training Time (s)'].values[0],
                    'memory_usage': performance_metrics.loc[performance_metrics['Unnamed: 0'] == 'KNN', 'Memory Usage (MB)'].values[0]
                }
            },
            'SVM': {
                'params': 'Par칙metros padr칚o',
                'optimization': 'Nenhuma otimiza칞칚o',
                'default_desc': """
                - kernel='rbf' (Fun칞칚o de kernel Gaussiana)
                - C=1.0 (Par칙metro de regulariza칞칚o)
                - gamma='scale' (Coeficiente do kernel)
                - probability=True (Habilita estimativas de probabilidade)
                """,
                'performance': {
                    'training_time': performance_metrics.loc[performance_metrics['Unnamed: 0'] == 'SVM', 'Training Time (s)'].values[0],
                    'memory_usage': performance_metrics.loc[performance_metrics['Unnamed: 0'] == 'SVM', 'Memory Usage (MB)'].values[0]
                }
            },
            'Decision Tree': {
                'params': {
                    'criterion': 'entropy',
                    'max_depth': 36,
                    'min_samples_leaf': 1,
                    'min_samples_split': 2
                },
                'optimization': 'Bayesian Search',
                'default_desc': None,  # N칚o necess치rio pois est치 otimizado
                'performance': {
                    'training_time': performance_metrics.loc[performance_metrics['Unnamed: 0'] == 'Decision Tree', 'Training Time (s)'].values[0],
                    'memory_usage': performance_metrics.loc[performance_metrics['Unnamed: 0'] == 'Decision Tree', 'Memory Usage (MB)'].values[0]
                }
            },
            'LVQ': {
                'params': 'Par칙metros padr칚o',
                'optimization': 'Nenhuma otimiza칞칚o',
                'default_desc': """
                - n_neighbors=3 (N칰mero de vizinhos)
                - weights='distance' (Pondera칞칚o por dist칙ncia)
                - prototypes_per_class=3 (Prot칩tipos por classe)
                """,
                'performance': {
                    'training_time': performance_metrics.loc[performance_metrics['Unnamed: 0'] == 'LVQ', 'Training Time (s)'].values[0],
                    'memory_usage': performance_metrics.loc[performance_metrics['Unnamed: 0'] == 'LVQ', 'Memory Usage (MB)'].values[0]
                }
            },
            'MLP': {
                'params': 'Par칙metros padr칚o',
                'optimization': 'Nenhuma otimiza칞칚o',
                'default_desc': """
                - hidden_layer_sizes=(100,) (Uma camada oculta com 100 neur칪nios)
                - activation='relu' (Fun칞칚o de ativa칞칚o ReLU)
                - solver='adam' (Otimizador Adam)
                - learning_rate='constant' (Taxa de aprendizado constante)
                - max_iter=200 (M치ximo de itera칞칫es)
                """,
                'performance': {
                    'training_time': performance_metrics.loc[performance_metrics['Unnamed: 0'] == 'MLP', 'Training Time (s)'].values[0],
                    'memory_usage': performance_metrics.loc[performance_metrics['Unnamed: 0'] == 'MLP', 'Memory Usage (MB)'].values[0]
                }
            },
            'Ensemble Neural Network': {
                'params': 'Par칙metros padr칚o',
                'optimization': 'Nenhuma otimiza칞칚o',
                'default_desc': """
                Conjunto de 3 MLPs com:
                - hidden_layer_sizes=(100,) (Uma camada oculta com 100 neur칪nios)
                - activation='relu' (Fun칞칚o de ativa칞칚o ReLU)
                - solver='adam' (Otimizador Adam)
                - max_iter=200 (M치ximo de itera칞칫es)
                """,
                'performance': {
                    'training_time': performance_metrics.loc[performance_metrics['Unnamed: 0'] == 'Ensemble Neural Network', 'Training Time (s)'].values[0],
                    'memory_usage': performance_metrics.loc[performance_metrics['Unnamed: 0'] == 'Ensemble Neural Network', 'Memory Usage (MB)'].values[0]
                }
            },
            'Stacking': {
                'params': 'Par칙metros padr칚o',
                'optimization': 'Nenhuma otimiza칞칚o',
                'default_desc': """
                Meta-classificador: Regress칚o Log칤stica com:
                - C=1.0 (Par칙metro de regulariza칞칚o)
                - solver='lbfgs' (Otimizador LBFGS)
                - max_iter=100 (M치ximo de itera칞칫es)
                
                Classificadores base:
                - Random Forest
                - SVM
                - KNN
                """,
                'performance': {
                    'training_time': performance_metrics.loc[performance_metrics['Unnamed: 0'] == 'Stacking', 'Training Time (s)'].values[0],
                    'memory_usage': performance_metrics.loc[performance_metrics['Unnamed: 0'] == 'Stacking', 'Memory Usage (MB)'].values[0]
                }
            },
            'Random Forest': {
                'params': {
                    'max_depth': 28,
                    'n_estimators': 97
                },
                'optimization': 'Optuna',
                'default_desc': None,  # N칚o necess치rio pois est치 otimizado
                'performance': {
                    'training_time': performance_metrics.loc[performance_metrics['Unnamed: 0'] == 'Random Forest', 'Training Time (s)'].values[0],
                    'memory_usage': performance_metrics.loc[performance_metrics['Unnamed: 0'] == 'Random Forest', 'Memory Usage (MB)'].values[0]
                }
            },
            'XGBoost': {
                'params': {
                    'objective': 'binary:logistic',
                    'enable_categorical': False,
                    'eval_metric': 'logloss',
                    'learning_rate': 0.09504317284612004,
                    'max_depth': 6,
                    'n_estimators': 188
                },
                'optimization': 'Optuna',
                'default_desc': None,  # N칚o necess치rio pois est치 otimizado
                'performance': {
                    'training_time': performance_metrics.loc[performance_metrics['Unnamed: 0'] == 'XGBoost', 'Training Time (s)'].values[0],
                    'memory_usage': performance_metrics.loc[performance_metrics['Unnamed: 0'] == 'XGBoost', 'Memory Usage (MB)'].values[0]
                }
            },
            'LightGBM': {
                'params': 'Par칙metros padr칚o',
                'optimization': 'Nenhuma otimiza칞칚o',
                'default_desc': """
                - learning_rate=0.1 (Taxa de aprendizado)
                - n_estimators=100 (N칰mero de 치rvores)
                - max_depth=-1 (Profundidade m치xima ilimitada)
                - num_leaves=31 (N칰mero m치ximo de folhas)
                - min_child_samples=20 (Amostras m칤nimas por n칩 folha)
                - objective='binary' (Objetivo para classifica칞칚o bin치ria)
                """,
                'performance': {
                    'training_time': performance_metrics.loc[performance_metrics['Unnamed: 0'] == 'LightGBM', 'Training Time (s)'].values[0],
                    'memory_usage': performance_metrics.loc[performance_metrics['Unnamed: 0'] == 'LightGBM', 'Memory Usage (MB)'].values[0]
                }
            }
        }
        
        # Create tabs for each classifier
        tabs = st.tabs(list(classifiers.keys()))
        
        # Display information in each tab
        for tab, (classifier_name, info) in zip(tabs, classifiers.items()):
            with tab:
                st.subheader(f"{classifier_name}")
                
                # Display optimization method
                st.markdown(f"**M칠todo de Otimiza칞칚o:** {info['optimization']}")
                
                # Display parameters
                st.markdown("**Par칙metros:**")
                if isinstance(info['params'], dict):
                    for param, value in info['params'].items():
                        st.write(f"- {param}: {value}")
                else:
                    st.write(info['params'])
                    if info['default_desc']:
                        st.markdown("**Descri칞칚o dos Par칙metros Padr칚o:**")
                        st.markdown(info['default_desc'])
                
                # Display performance metrics
                st.markdown("**M칠tricas de Desempenho:**")
                st.write(f"- Tempo de Treinamento: {info['performance']['training_time']:.2f} segundos")
                st.write(f"- Uso de Mem칩ria: {info['performance']['memory_usage']:.2f} MB")
    except Exception as e:
        st.error(f"Erro ao carregar os dados: {str(e)}")

elif menu == "An치lise de Custo x Benef칤cio":
    st.header("An치lise de Custo x Benef칤cio dos Classificadores")
    
    try:
        # Load performance metrics
        _, _, _, _, _, performance_metrics, _, _ = load_data()
        
        # Criar DataFrame com m칠tricas de desempenho
        cost_benefit_df = pd.DataFrame({
            'Classificador': performance_metrics['Unnamed: 0'],
            'Tempo de Treinamento (s)': performance_metrics['Training Time (s)'].round(2),
            'Uso de Mem칩ria (MB)': performance_metrics['Memory Usage (MB)'].round(2),
            'Accuracy': performance_metrics['Accuracy'].round(4),
            'F1 Score': performance_metrics['F1 Score'].round(4),
            'Recall': performance_metrics['Recall'].round(4),
            'ACSA': performance_metrics['ACSA'].round(4)
        })
        
        # Exibir tabela com todas as m칠tricas
        st.subheader("Tabela Comparativa")
        st.dataframe(cost_benefit_df.style.highlight_max(axis=0, color='lightgreen', subset=['Accuracy', 'F1 Score', 'Recall', 'ACSA'])
                                        .highlight_min(axis=0, color='lightpink', subset=['Tempo de Treinamento (s)', 'Uso de Mem칩ria (MB)']))
        
        # Criar gr치ficos
        st.subheader("Visualiza칞칫es")
        
        # Criar duas colunas para os gr치ficos
        col1, col2 = st.columns(2)
        
        with col1:
            # Gr치fico de Tempo de Treinamento
            fig_time = plt.figure(figsize=(10, 6))
            plt.barh(cost_benefit_df['Classificador'], cost_benefit_df['Tempo de Treinamento (s)'])
            plt.title('Tempo de Treinamento por Classificador')
            plt.xlabel('Tempo (segundos)')
            plt.ylabel('Classificador')
            st.pyplot(fig_time)
        
        with col2:
            # Gr치fico de Uso de Mem칩ria
            fig_memory = plt.figure(figsize=(10, 6))
            plt.barh(cost_benefit_df['Classificador'], cost_benefit_df['Uso de Mem칩ria (MB)'])
            plt.title('Uso de Mem칩ria por Classificador')
            plt.xlabel('Mem칩ria (MB)')
            plt.ylabel('Classificador')
            st.pyplot(fig_memory)      
                
        # Adicionar algumas observa칞칫es
        st.subheader("Observa칞칫es")
        st.markdown("""
        - Os valores em verde na tabela indicam os melhores resultados para m칠tricas de desempenho (Accuracy, F1 Score, Recall, ACSA)
        - Os valores em rosa na tabela indicam os menores valores para m칠tricas de custo (Tempo de Treinamento, Uso de Mem칩ria)
        """)
        
    except Exception as e:
        st.error(f"Erro ao carregar os dados: {str(e)}")

elif menu == "Balanceamento de classes ap칩s ADASYN":
    st.header("Distribui칞칚o das Classes ap칩s Balanceamento com ADASYN")
    
    try:
        st.image("class_distribution.jpeg", caption="Distribui칞칚o das classes ap칩s aplica칞칚o do ADASYN")
    except Exception as e:
        st.error(f"Erro ao carregar a imagem: {str(e)}")

elif menu == "Resultados dos classificadores ap칩s ADASYN":
    st.header("Resultados dos Classificadores ap칩s Aplica칞칚o do ADASYN")
    
    try:
        # Load ADASYN results
        _, _, _, _, _, _, adasyn_results, _ = load_data()
        
        # Display the results
        st.dataframe(adasyn_results)
            
    except Exception as e:
        st.error(f"Erro ao carregar os dados do ADASYN: {str(e)}")

elif menu == "Base Treino x Teste":
    st.header("Compara칞칚o entre Base de Treino e Teste")
    
    try:
        # Load train-test comparison results
        _, _, _, _, _, _, _, train_test_results = load_data()
        
        # Display the results
        st.dataframe(train_test_results)
            
    except Exception as e:
        st.error(f"Erro ao carregar os dados de compara칞칚o treino-teste: {str(e)}")

elif menu == "Downloads":
    st.header("Downloads dos Notebooks")
    
    st.markdown("""
    ### Notebooks Dispon칤veis
    
    Aqui voc칡 pode baixar os notebooks utilizados na an치lise:
    """)
    
    # Function to read file as bytes
    def get_binary_file_downloader_html(file_path, file_label):
        with open(file_path, 'rb') as f:
            data = f.read()
        return st.download_button(
            label=f"Download {file_label}",
            data=data,
            file_name=file_path.split('/')[-1],
            mime='application/x-ipynb+json'
        )
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("#### An치lise Estat칤stica")
        st.markdown("Notebook contendo a an치lise estat칤stica dos resultados usando os testes de Friedman e Nemenyi.")
        get_binary_file_downloader_html('notebook_estatistica.ipynb', 'An치lise Estat칤stica')
    
    with col2:
        st.markdown("#### Experimentos")
        st.markdown("Notebook contendo os experimentos realizados com os diferentes classificadores.")
        get_binary_file_downloader_html('notebook_experimento.ipynb', 'Experimentos')
