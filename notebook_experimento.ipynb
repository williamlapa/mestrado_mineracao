{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fr1v1FVY3fYe"
      },
      "source": [
        "## Importação e Preparação da base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "YXIEaYpQXcOL",
        "outputId": "b5d85659-3194-40ee-db60-515b4f4e2d1f"
      },
      "outputs": [],
      "source": [
        "# %%capture\n",
        "# !pip install scikit-optimize\n",
        "# !pip install openml\n",
        "# !pip install optuna\n",
        "# !pip install neupy\n",
        "# !pip install --upgrade neupy\n",
        "# !pip install --upgrade theano\n",
        "# !pip install imbalanced-learn\n",
        "# !pip install memory_profiler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLZBpVrOpmlw",
        "outputId": "20a02143-0167-41fc-ffec-230c942de82e",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ambiente local detectado.\n",
            "'scikit-optimize' já está instalado: versão 0.10.2\n",
            "'xgboost' já está instalado: versão 2.1.3\n",
            "'openml' já está instalado: versão 0.15.0\n",
            "'optuna' já está instalado: versão 4.1.0\n",
            "'imbalanced-learn' já está instalado: versão 0.12.4\n",
            "'openpyxl' já está instalado: versão 3.1.5\n",
            "'memory_profiler' já está instalado: versão 0.61.0\n",
            "'openpyxl' já está instalado: versão 3.1.5\n",
            "'lightgbm' já está instalado: versão 4.5.0\n",
            "'GPUtil' já está instalado: versão 1.4.0\n",
            "'psutil' já está instalado: versão 6.1.0\n",
            "Instalando 'seaborn'...\n",
            "Atualizando 'neupy' e 'theano' no ambiente local...\n",
            "Requirement already satisfied: neupy in c:\\users\\willi\\documents\\projetos\\mestrado_mineracao\\venv\\lib\\site-packages (0.6.5)\n",
            "Collecting neupy\n",
            "  Obtaining dependency information for neupy from https://files.pythonhosted.org/packages/21/be/19082cbe9a6c76dd909255341587f0b487cd3e9d32d44debda013d2accd1/neupy-0.8.2-py2.py3-none-any.whl.metadata\n",
            "  Using cached neupy-0.8.2-py2.py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\willi\\documents\\projetos\\mestrado_mineracao\\venv\\lib\\site-packages (from neupy) (2.1.3)\n",
            "Requirement already satisfied: scipy>=0.19.0 in c:\\users\\willi\\documents\\projetos\\mestrado_mineracao\\venv\\lib\\site-packages (from neupy) (1.14.1)\n",
            "INFO: pip is looking at multiple versions of neupy to determine which version is compatible with other requirements. This could take a while.\n",
            "  Obtaining dependency information for neupy from https://files.pythonhosted.org/packages/c9/da/fec21f526864b850dea52a9d09e633d303c78588aca3af00a314e41960a4/neupy-0.8.1-py2.py3-none-any.whl.metadata\n",
            "  Using cached neupy-0.8.1-py2.py3-none-any.whl.metadata (1.1 kB)\n",
            "  Obtaining dependency information for neupy from https://files.pythonhosted.org/packages/9c/a2/4d8dc5d686adcdd3ed2c98c85ccf69370ef0675574b0f8dbb9b91abc978c/neupy-0.8.0-py2.py3-none-any.whl.metadata\n",
            "  Using cached neupy-0.8.0-py2.py3-none-any.whl.metadata (1.1 kB)\n",
            "  Obtaining dependency information for neupy from https://files.pythonhosted.org/packages/69/5e/13197fd26b5bf09cf3ae08e18c0bfb26407a96757c2f60651e4b52ede7ab/neupy-0.7.3-py2.py3-none-any.whl.metadata\n",
            "  Using cached neupy-0.7.3-py2.py3-none-any.whl.metadata (1.1 kB)\n",
            "  Obtaining dependency information for neupy from https://files.pythonhosted.org/packages/b1/1d/667a0ffc23441dbebdecadaa7076adc0544c09e9975b25b38d55e8d66fc4/neupy-0.7.2-py2.py3-none-any.whl.metadata\n",
            "  Using cached neupy-0.7.2-py2.py3-none-any.whl.metadata (1.1 kB)\n",
            "  Obtaining dependency information for neupy from https://files.pythonhosted.org/packages/80/d1/09c645feff9917d53889f2256207ba9fba11681b4fcb8326e95b776edc51/neupy-0.7.1-py2.py3-none-any.whl.metadata\n",
            "  Using cached neupy-0.7.1-py2.py3-none-any.whl.metadata (1.1 kB)\n",
            "  Obtaining dependency information for neupy from https://files.pythonhosted.org/packages/6a/9d/ccbe1f517596a7c91108ebb7dff84551a6f7c9ccf601c0569d3c2bd92136/neupy-0.7.0-py2.py3-none-any.whl.metadata\n",
            "  Using cached neupy-0.7.0-py2.py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting Theano==1.0.0 (from neupy)\n",
            "  Using cached Theano-1.0.0-py3-none-any.whl\n",
            "Requirement already satisfied: matplotlib>=1.5.1 in c:\\users\\willi\\documents\\projetos\\mestrado_mineracao\\venv\\lib\\site-packages (from neupy) (3.9.2)\n",
            "Requirement already satisfied: graphviz==0.5.1 in c:\\users\\willi\\documents\\projetos\\mestrado_mineracao\\venv\\lib\\site-packages (from neupy) (0.5.1)\n",
            "Requirement already satisfied: tableprint==0.7.1 in c:\\users\\willi\\documents\\projetos\\mestrado_mineracao\\venv\\lib\\site-packages (from neupy) (0.7.1)\n",
            "Requirement already satisfied: progressbar2==3.34.3 in c:\\users\\willi\\documents\\projetos\\mestrado_mineracao\\venv\\lib\\site-packages (from neupy) (3.34.3)\n",
            "Requirement already satisfied: python-utils>=2.1.0 in c:\\users\\willi\\documents\\projetos\\mestrado_mineracao\\venv\\lib\\site-packages (from progressbar2==3.34.3->neupy) (3.9.1)\n",
            "Requirement already satisfied: six in c:\\users\\willi\\documents\\projetos\\mestrado_mineracao\\venv\\lib\\site-packages (from tableprint==0.7.1->neupy) (1.16.0)\n",
            "Requirement already satisfied: future in c:\\users\\willi\\documents\\projetos\\mestrado_mineracao\\venv\\lib\\site-packages (from tableprint==0.7.1->neupy) (1.0.0)\n",
            "Requirement already satisfied: wcwidth in c:\\users\\willi\\documents\\projetos\\mestrado_mineracao\\venv\\lib\\site-packages (from tableprint==0.7.1->neupy) (0.2.13)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\willi\\documents\\projetos\\mestrado_mineracao\\venv\\lib\\site-packages (from matplotlib>=1.5.1->neupy) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\willi\\documents\\projetos\\mestrado_mineracao\\venv\\lib\\site-packages (from matplotlib>=1.5.1->neupy) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\willi\\documents\\projetos\\mestrado_mineracao\\venv\\lib\\site-packages (from matplotlib>=1.5.1->neupy) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\willi\\documents\\projetos\\mestrado_mineracao\\venv\\lib\\site-packages (from matplotlib>=1.5.1->neupy) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\willi\\documents\\projetos\\mestrado_mineracao\\venv\\lib\\site-packages (from matplotlib>=1.5.1->neupy) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in c:\\users\\willi\\documents\\projetos\\mestrado_mineracao\\venv\\lib\\site-packages (from matplotlib>=1.5.1->neupy) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\willi\\documents\\projetos\\mestrado_mineracao\\venv\\lib\\site-packages (from matplotlib>=1.5.1->neupy) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\willi\\documents\\projetos\\mestrado_mineracao\\venv\\lib\\site-packages (from matplotlib>=1.5.1->neupy) (2.9.0.post0)\n",
            "Requirement already satisfied: typing_extensions>3.10.0.2 in c:\\users\\willi\\documents\\projetos\\mestrado_mineracao\\venv\\lib\\site-packages (from python-utils>=2.1.0->progressbar2==3.34.3->neupy) (4.12.2)\n",
            "Installing collected packages: Theano\n",
            "  Attempting uninstall: Theano\n",
            "    Found existing installation: Theano 1.0.5\n",
            "    Uninstalling Theano-1.0.5:\n",
            "      Successfully uninstalled Theano-1.0.5\n",
            "Successfully installed Theano-1.0.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.2.1 -> 24.3.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: theano in c:\\users\\willi\\documents\\projetos\\mestrado_mineracao\\venv\\lib\\site-packages (1.0.0)\n",
            "Collecting theano\n",
            "  Using cached Theano-1.0.5-py3-none-any.whl\n",
            "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\willi\\documents\\projetos\\mestrado_mineracao\\venv\\lib\\site-packages (from theano) (2.1.3)\n",
            "Requirement already satisfied: scipy>=0.14 in c:\\users\\willi\\documents\\projetos\\mestrado_mineracao\\venv\\lib\\site-packages (from theano) (1.14.1)\n",
            "Requirement already satisfied: six>=1.9.0 in c:\\users\\willi\\documents\\projetos\\mestrado_mineracao\\venv\\lib\\site-packages (from theano) (1.16.0)\n",
            "Installing collected packages: theano\n",
            "  Attempting uninstall: theano\n",
            "    Found existing installation: Theano 1.0.0\n",
            "    Uninstalling Theano-1.0.0:\n",
            "      Successfully uninstalled Theano-1.0.0\n",
            "Successfully installed theano-1.0.5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "neupy 0.6.5 requires Theano==1.0.0, but you have theano 1.0.5 which is incompatible.\n",
            "\n",
            "[notice] A new release of pip is available: 23.2.1 -> 24.3.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "# Verificação de pacotes\n",
        "# %% capture\n",
        "import sys\n",
        "import subprocess\n",
        "import pkg_resources\n",
        "\n",
        "# Função para instalar pacotes, se necessário\n",
        "def install_package(package):\n",
        "    try:\n",
        "        # Verificar se o pacote já está instalado\n",
        "        dist = pkg_resources.get_distribution(package)\n",
        "        print(f\"'{package}' já está instalado: versão {dist.version}\")\n",
        "    except pkg_resources.DistributionNotFound:\n",
        "        # Instalar o pacote, se não estiver instalado\n",
        "        print(f\"Instalando '{package}'...\")\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
        "\n",
        "# Lista de pacotes necessários\n",
        "packages = [\n",
        "    \"scikit-optimize\",\n",
        "    \"xgboost\",\n",
        "    \"openml\",\n",
        "    \"optuna\",\n",
        "    \"imbalanced-learn\",\n",
        "    \"openpyxl\",\n",
        "    \"memory_profiler\",\n",
        "    \"openpyxl\",\n",
        "    \"lightgbm\",\n",
        "    \"GPUtil\",\n",
        "    \"psutil\",\n",
        "    \"seaborn\"\n",
        "]\n",
        "\n",
        "# Verificar se está no Google Colab\n",
        "try:\n",
        "    import google.colab\n",
        "    is_colab = True\n",
        "    print(\"Detectado ambiente Google Colab.\")\n",
        "except ImportError:\n",
        "    is_colab = False\n",
        "    print(\"Ambiente local detectado.\")\n",
        "\n",
        "# Instalar pacotes\n",
        "for package in packages:\n",
        "    if is_colab or package not in [\"neupy\", \"theano\"]:  # 'neupy' e 'theano' apenas em ambiente local\n",
        "        install_package(package)\n",
        "\n",
        "# Atualizar pacotes específicos\n",
        "if not is_colab:\n",
        "    print(\"Atualizando 'neupy' e 'theano' no ambiente local...\")\n",
        "    # Install the latest version of NeuPy#+\n",
        "    !pip install --upgrade neupy\n",
        "    # Install the required package\n",
        "    !pip install --upgrade theano"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLgev7DN7Fxj",
        "outputId": "8ea590a9-b498-4c23-a6a9-de54b6abb281"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "import pandas as pd\n",
        "from scipy.io import arff\n",
        "import openml\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "IVNblnZP60uV"
      },
      "outputs": [],
      "source": [
        "# Definir o ID do dataset no OpenML\n",
        "dataset_id = 722\n",
        "\n",
        "# Carregar o dataset diretamente do OpenML\n",
        "dataset = openml.datasets.get_dataset(dataset_id)\n",
        "data = dataset.get_data()[0]  # Pega o DataFrame completo\n",
        "\n",
        "# Remove colunas onde todos os valores são zero: [f10-f12] e [f34-f48]\n",
        "data = data.loc[:, (data != 0).any(axis=0)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_utNjnbIYd4",
        "outputId": "8efd3c8b-4ed8-4ea2-9ca4-e1a7ddce40f0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f13', 'f14',\n",
              "       'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24',\n",
              "       'f25', 'f26', 'f27', 'f28', 'f29', 'f30', 'f31', 'f32', 'f33',\n",
              "       'binaryClass'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "idmYjA7VORc2",
        "outputId": "50ef086b-05c0-42d4-b9e0-fdffa161398f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Número de features: 30\n"
          ]
        }
      ],
      "source": [
        "# prompt: quantidade de atributos\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming 'data' is your pandas DataFrame\n",
        "num_attributes = len(data.columns) - 1\n",
        "print(f\"Número de features: {num_attributes}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85poJhhVSYzF"
      },
      "source": [
        "## Utilizando ADASYN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "PDNh3_lUSb1E"
      },
      "outputs": [],
      "source": [
        "from sklearn.calibration import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.over_sampling import ADASYN\n",
        "import pandas as pd\n",
        "\n",
        "# Definir a variável alvo\n",
        "target_column = 'binaryClass'\n",
        "X = data.drop(columns=[target_column])\n",
        "y = data[target_column]\n",
        "\n",
        "# Supondo que y tenha as classes 'N' e 'P' como strings\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(y)  # Converte as classes para números (0 e 1)\n",
        "\n",
        "\n",
        "# Dividir os dados em treino e teste com estratificação\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "# Definir o StratifiedKFold com 10 folds para garantir a estratificação nas validações cruzadas\n",
        "stratified_kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# Identificar colunas numéricas e ajustar o tipo de dado para float64\n",
        "numeric_features = X_train.select_dtypes(include=['uint8']).columns\n",
        "X_train[numeric_features] = X_train[numeric_features].astype('float64')\n",
        "X_test[numeric_features] = X_test[numeric_features].astype('float64')\n",
        "\n",
        "# Substituir valores ausentes pela média em cada coluna numérica\n",
        "X_train[numeric_features] = X_train[numeric_features].fillna(X_train[numeric_features].mean())\n",
        "X_test[numeric_features] = X_test[numeric_features].fillna(X_train[numeric_features].mean())\n",
        "\n",
        "# Aplicar transformação (padronização) nas colunas numéricas\n",
        "scaler = StandardScaler()\n",
        "X_train[numeric_features] = scaler.fit_transform(X_train[numeric_features])\n",
        "X_test[numeric_features] = scaler.transform(X_test[numeric_features])\n",
        "\n",
        "# Aplicar ADASYN para balancear as classes no conjunto de treino\n",
        "adasyn = ADASYN(random_state=42)\n",
        "X_train_resampled, y_train_resampled = adasyn.fit_resample(X_train, y_train)\n",
        "\n",
        "# Agora X_train_resampled e y_train_resampled estão prontos para uso em modelos com 10-fold cross-validation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJD6QN8jntDk"
      },
      "source": [
        "## Comparativo ADASYN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1PBbW6Anwkk",
        "outputId": "5e533e41-da50-4ed8-ba0d-936b9527ae88"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "# Função para plotar a distribuição das classes\n",
        "def plot_class_distribution(y_before, y_after, labels=['Antes do ADASYN', 'Depois do ADASYN']):\n",
        "    \"\"\"\n",
        "    Plota a distribuição das classes antes e depois do balanceamento com ADASYN.\n",
        "    \"\"\"\n",
        "    # Contar as classes antes e depois\n",
        "    class_counts_before = pd.Series(y_before).value_counts().sort_index()\n",
        "    class_counts_after = pd.Series(y_after).value_counts().sort_index()\n",
        "\n",
        "    # Criar DataFrame para plotagem\n",
        "    df = pd.DataFrame({\n",
        "        'Classes': class_counts_before.index.tolist() + class_counts_after.index.tolist(),\n",
        "        'Frequência': class_counts_before.tolist() + class_counts_after.tolist(),\n",
        "        'Conjunto': [labels[0]] * len(class_counts_before) + [labels[1]] * len(class_counts_after)\n",
        "    })\n",
        "\n",
        "    # Plotar distribuição\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.barplot(x='Classes', y='Frequência', hue='Conjunto', data=df, palette='viridis')\n",
        "    plt.title('Distribuição das Classes Antes e Depois do ADASYN', fontsize=14)\n",
        "    plt.xlabel('Classes', fontsize=12)\n",
        "    plt.ylabel('Frequência', fontsize=12)\n",
        "    plt.legend(title='Conjunto', fontsize=10)\n",
        "    plt.xticks(fontsize=10)\n",
        "    plt.yticks(fontsize=10)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Save the plot to a PNG file\n",
        "plt.savefig('class_distribution.jpeg')\n",
        "\n",
        "# Comparar antes e depois do ADASYN\n",
        "plot_class_distribution(y_train, y_train_resampled)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jgg2SmPTPfVj"
      },
      "source": [
        "## Início experimento - Variáveis Básicas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "O-eiuwm5PiD5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\willi\\Documents\\Projetos\\mestrado_mineracao\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "# Realizando experimento já considerando X_train_resampled e y_train_resampled\n",
        "import numpy as np\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import optuna\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier, StackingClassifier, VotingClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.metrics import f1_score, recall_score, accuracy_score, confusion_matrix\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
        "from skopt import BayesSearchCV\n",
        "from skopt.space import Integer, Categorical, Real\n",
        "# from neupy import algorithms\n",
        "\n",
        "# Configurar K-Fold com estratificação\n",
        "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# Definição básica dos classificadores\n",
        "knn = KNeighborsClassifier()\n",
        "lvq = MLPClassifier(solver='sgd', learning_rate='constant', learning_rate_init=0.1, max_iter=100)\n",
        "tree = DecisionTreeClassifier()\n",
        "svm = SVC(probability=True)\n",
        "rf = RandomForestClassifier()\n",
        "mlp = MLPClassifier(max_iter=100, hidden_layer_sizes=(50,))\n",
        "xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
        "lgbm = LGBMClassifier(n_estimators=50, max_depth=3, verbose=-1) #verbose=-1 não mostra mensagens de alerta\n",
        "\n",
        "# Comitê de Redes Neurais Artificiais\n",
        "ann_ensemble = VotingClassifier(\n",
        "    estimators=[\n",
        "        ('mlp_relu', MLPClassifier(activation='relu', hidden_layer_sizes=(50, 20), max_iter=100)),\n",
        "        ('mlp_tanh', MLPClassifier(activation='tanh', hidden_layer_sizes=(50, 20), max_iter=100)),\n",
        "        ('mlp_logistic', MLPClassifier(activation='logistic', hidden_layer_sizes=(50, 20), max_iter=100))\n",
        "    ],\n",
        "    voting='soft',\n",
        "    n_jobs=-1  # Paralelização\n",
        ")\n",
        "\n",
        "# Comitê Heterogêneo (Stacking)\n",
        "stacking = StackingClassifier(\n",
        "    estimators=[\n",
        "        ('nb', GaussianNB()),  # Modelo rápido e leve\n",
        "        ('dt', DecisionTreeClassifier(max_depth=3)),  # Árvore de decisão rasa\n",
        "    ],\n",
        "    final_estimator=LogisticRegression(max_iter=100),  # Meta-modelo simples\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Dicionário de classificadores inicial:\n",
        "classifiers = {\n",
        "    'KNN': knn,             # Bayesian Search\n",
        "    'SVM': svm,\n",
        "    'Decision Tree': tree,  # Bayesian Search\n",
        "    'LVQ': lvq,\n",
        "    'MLP': mlp,\n",
        "    'Ensemble Neural Network': ann_ensemble,\n",
        "    'Stacking': stacking,\n",
        "    'Random Forest': rf,    #Optuna\n",
        "    'XGBoost': xgb,         #Optuna\n",
        "    'LightGBM': lgbm\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BAz_-U69MqPw",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "## Tunning Usando Bayesian e Optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3ngnvnnMtzQ",
        "outputId": "c78fc699-2f8d-47ee-efd7-5de16c4d4721"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Otimizando hiperparâmetros para KNN...\n",
            "Melhores parâmetros para KNN: OrderedDict([('n_neighbors', 1), ('p', 1), ('weights', 'uniform')])\n",
            "\n",
            "Otimizando hiperparâmetros para Decision Tree...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-29 19:48:03,197] A new study created in memory with name: no-name-826eff76-710c-478d-a669-0fbd49028c59\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Melhores parâmetros para Decision Tree: OrderedDict([('criterion', 'entropy'), ('max_depth', 23), ('min_samples_leaf', 1), ('min_samples_split', 2)])\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-29 19:48:17,452] Trial 0 finished with value: 0.8992910354614712 and parameters: {'n_estimators': 193, 'max_depth': 3}. Best is trial 0 with value: 0.8992910354614712.\n",
            "[I 2024-11-29 19:48:34,052] Trial 1 finished with value: 0.9163927932440276 and parameters: {'n_estimators': 184, 'max_depth': 4}. Best is trial 1 with value: 0.9163927932440276.\n",
            "[I 2024-11-29 19:48:37,421] Trial 2 finished with value: 0.9312780786479065 and parameters: {'n_estimators': 27, 'max_depth': 6}. Best is trial 2 with value: 0.9312780786479065.\n",
            "[I 2024-11-29 19:48:44,445] Trial 3 finished with value: 0.9151254463887959 and parameters: {'n_estimators': 77, 'max_depth': 4}. Best is trial 2 with value: 0.9312780786479065.\n",
            "[I 2024-11-29 19:48:53,656] Trial 4 finished with value: 0.9137323200337766 and parameters: {'n_estimators': 101, 'max_depth': 4}. Best is trial 2 with value: 0.9312780786479065.\n",
            "[I 2024-11-29 19:48:53,658] A new study created in memory with name: no-name-2c764674-3909-4499-9c1e-2380e8ef2342\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Melhores hiperparâmetros para Random Forest: {'n_estimators': 27, 'max_depth': 6}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-29 19:49:02,484] Trial 0 finished with value: 0.984354860330173 and parameters: {'learning_rate': 0.010109829632956214, 'n_estimators': 162, 'max_depth': 10}. Best is trial 0 with value: 0.984354860330173.\n",
            "[I 2024-11-29 19:49:08,434] Trial 1 finished with value: 0.9374208058717434 and parameters: {'learning_rate': 0.0010674513804083954, 'n_estimators': 273, 'max_depth': 5}. Best is trial 0 with value: 0.984354860330173.\n",
            "[I 2024-11-29 19:49:13,559] Trial 2 finished with value: 0.9248158859427964 and parameters: {'learning_rate': 0.006245154718456152, 'n_estimators': 327, 'max_depth': 3}. Best is trial 0 with value: 0.984354860330173.\n",
            "[I 2024-11-29 19:49:36,831] Trial 3 finished with value: 0.9728270527864533 and parameters: {'learning_rate': 0.0013207537282401275, 'n_estimators': 453, 'max_depth': 8}. Best is trial 0 with value: 0.984354860330173.\n",
            "[I 2024-11-29 19:49:40,389] Trial 4 finished with value: 0.9800475345371884 and parameters: {'learning_rate': 0.05372742901459394, 'n_estimators': 62, 'max_depth': 7}. Best is trial 0 with value: 0.984354860330173.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Melhores hiperparâmetros para XGBoost: {'learning_rate': 0.010109829632956214, 'n_estimators': 162, 'max_depth': 10}\n"
          ]
        }
      ],
      "source": [
        "# Usando BS e Optuna em dois classificadores diferentes:\n",
        "\n",
        "# Filtrar warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import logging\n",
        "logging.getLogger('sklearn').setLevel(logging.ERROR)\n",
        "\n",
        "# Configurações para os modelos que costumam gerar warnings\n",
        "import os\n",
        "os.environ['PYTHONWARNINGS'] = 'ignore'\n",
        "\n",
        "# Configurações específicas para XGBoost\n",
        "from xgboost import set_config\n",
        "set_config(verbosity=0)\n",
        "\n",
        "# Espaços de busca para Bayesian Search: KNN e Decision Tree\n",
        "param_spaces = {\n",
        "    'KNN': {\n",
        "        'n_neighbors': (1, 30),\n",
        "        'weights': ['uniform', 'distance'],\n",
        "        'p': (1, 2)\n",
        "    },\n",
        "    'Decision Tree': {\n",
        "        'max_depth': (1, 50),\n",
        "        'min_samples_split': (2, 20),\n",
        "        'min_samples_leaf': (1, 20),\n",
        "        'criterion': ['gini', 'entropy']\n",
        "    }\n",
        "\n",
        "}\n",
        "\n",
        "# Avaliar classificadores e buscar hiperparâmetros com BayesSearchCV\n",
        "results = {}\n",
        "best_params = {}\n",
        "\n",
        "for name, clf in classifiers.items():\n",
        "    if name in param_spaces:\n",
        "        print(f\"Otimizando hiperparâmetros para {name}...\")\n",
        "        bayes_search = BayesSearchCV(\n",
        "            estimator=clf,\n",
        "            search_spaces=param_spaces[name],\n",
        "            n_iter=50,\n",
        "            cv=kfold,\n",
        "            scoring='accuracy',\n",
        "            n_jobs=-1,\n",
        "            random_state=42\n",
        "        )\n",
        "\n",
        "        # Garante que X_train_resampled seja um DataFrame com os nomes de coluna corretos\n",
        "        X_train_resampled = pd.DataFrame(X_train_resampled, columns=X_train.columns)\n",
        "\n",
        "        bayes_search.fit(X_train_resampled, y_train_resampled)\n",
        "        best_params[name] = bayes_search.best_params_\n",
        "        clf = bayes_search.best_estimator_\n",
        "        print(f\"Melhores parâmetros para {name}: {bayes_search.best_params_}\\n\")\n",
        "\n",
        "#Optuna para RF e XGB\n",
        "\n",
        "# Funções de objetivo para Optuna\n",
        "def rf_objective(trial):\n",
        "    n_estimators = trial.suggest_int(\"n_estimators\", 10, 200)\n",
        "    max_depth = trial.suggest_int(\"max_depth\", 2, 32, log=True)\n",
        "    clf = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth)\n",
        "    return cross_val_score(clf, X_train_resampled, y_train_resampled, cv=kfold, scoring=\"accuracy\").mean()\n",
        "\n",
        "def xgb_objective(trial):\n",
        "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-3, 1e-1, log=True)\n",
        "    n_estimators = trial.suggest_int(\"n_estimators\", 50, 500)\n",
        "    max_depth = trial.suggest_int(\"max_depth\", 3, 10)\n",
        "\n",
        "    # Encode the target variable to numeric values\n",
        "    le = LabelEncoder()\n",
        "    y_train_resampled_encoded = le.fit_transform(y_train_resampled)\n",
        "\n",
        "    clf = XGBClassifier(learning_rate=learning_rate, n_estimators=n_estimators,\n",
        "                        max_depth=max_depth, use_label_encoder=False, eval_metric='logloss')\n",
        "    return cross_val_score(clf, X_train_resampled, y_train_resampled_encoded, cv=kfold, scoring=\"accuracy\").mean()\n",
        "\n",
        "# Otimização com Optuna\n",
        "rf_study = optuna.create_study(direction=\"maximize\")\n",
        "rf_study.optimize(rf_objective, n_trials=5)\n",
        "classifiers['Random Forest'] = RandomForestClassifier(**rf_study.best_trial.params)\n",
        "print(\"Melhores hiperparâmetros para Random Forest:\", rf_study.best_trial.params)\n",
        "\n",
        "xgb_study = optuna.create_study(direction=\"maximize\")\n",
        "xgb_study.optimize(xgb_objective, n_trials=5)\n",
        "classifiers['XGBoost'] = XGBClassifier(**xgb_study.best_trial.params, use_label_encoder=False, eval_metric='logloss')\n",
        "print(\"Melhores hiperparâmetros para XGBoost:\", xgb_study.best_trial.params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DNIIQajYi4I"
      },
      "source": [
        "## Resumo Melhores Parâmetros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "ULFB9uENYL2-"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parâmetros do XGBoost sem valores None:\n",
            "{'objective': 'binary:logistic', 'enable_categorical': False, 'eval_metric': 'logloss', 'learning_rate': 0.010109829632956214, 'max_depth': 10, 'missing': nan, 'n_estimators': 162, 'use_label_encoder': False}\n"
          ]
        }
      ],
      "source": [
        "# Obter os parâmetros do classificador e remover os que têm valor None\n",
        "xgb_clean_params = {k: v for k, v in classifiers['XGBoost'].get_params().items() if v is not None}\n",
        "\n",
        "# Criar um novo classificador com os parâmetros limpos\n",
        "cleaned_xgb = XGBClassifier(**xgb_clean_params)\n",
        "\n",
        "print(\"Parâmetros do XGBoost sem valores None:\")\n",
        "print(xgb_clean_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Y2Q3OKn7TAG9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classificadores com os melhores parâmetros:\n",
            "KNN: KNeighborsClassifier(n_neighbors=1, p=1)\n",
            "SVM: SVC(probability=True)\n",
            "Decision Tree: DecisionTreeClassifier(criterion='entropy', max_depth=36)\n",
            "LVQ: MLPClassifier(learning_rate_init=0.1, max_iter=100, solver='sgd')\n",
            "MLP: MLPClassifier(hidden_layer_sizes=(50,), max_iter=100)\n",
            "Ensemble Neural Network: VotingClassifier(estimators=[('mlp_relu',\n",
            "                              MLPClassifier(hidden_layer_sizes=(50, 20),\n",
            "                                            max_iter=100)),\n",
            "                             ('mlp_tanh',\n",
            "                              MLPClassifier(activation='tanh',\n",
            "                                            hidden_layer_sizes=(50, 20),\n",
            "                                            max_iter=100)),\n",
            "                             ('mlp_logistic',\n",
            "                              MLPClassifier(activation='logistic',\n",
            "                                            hidden_layer_sizes=(50, 20),\n",
            "                                            max_iter=100))],\n",
            "                 n_jobs=-1, voting='soft')\n",
            "Stacking: StackingClassifier(estimators=[('nb', GaussianNB()),\n",
            "                               ('dt', DecisionTreeClassifier(max_depth=3))],\n",
            "                   final_estimator=LogisticRegression(), n_jobs=-1)\n",
            "Random Forest: RandomForestClassifier(max_depth=28, n_estimators=97)\n",
            "XGBoost: XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
            "              colsample_bylevel=None, colsample_bynode=None,\n",
            "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
            "              enable_categorical=False, eval_metric='logloss',\n",
            "              feature_types=None, gamma=None, grow_policy=None,\n",
            "              importance_type=None, interaction_constraints=None,\n",
            "              learning_rate=0.09504317284612004, max_bin=None,\n",
            "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
            "              max_delta_step=None, max_depth=6, max_leaves=None,\n",
            "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
            "              multi_strategy=None, n_estimators=188, n_jobs=None,\n",
            "              num_parallel_tree=None, random_state=None, ...)\n",
            "LightGBM: LGBMClassifier(max_depth=3, n_estimators=50, verbose=-1)\n"
          ]
        }
      ],
      "source": [
        "# Converter parâmetros otimizados para inicializar os classificadores\n",
        "best_classifiers = {\n",
        "    'KNN': KNeighborsClassifier(n_neighbors=1, p=1, weights='uniform'), # Otimizado com Bayesian Search\n",
        "    'SVM': svm,  # Nenhuma otimização aplicada\n",
        "    'Decision Tree': DecisionTreeClassifier(criterion='entropy', max_depth=36, min_samples_leaf=1, min_samples_split=2), # Otimizado com Bayesian Search\n",
        "    'LVQ': lvq,  # Nenhuma otimização aplicada\n",
        "    'MLP': mlp,  # Nenhuma otimização aplicada\n",
        "    'Ensemble Neural Network': ann_ensemble,  # Nenhuma otimização aplicada\n",
        "    'Stacking': stacking,  # Nenhuma otimização aplicada\n",
        "    'Random Forest': RandomForestClassifier(max_depth=28, n_estimators=97), # Otimizado com Optuna\n",
        "    'XGBoost': XGBClassifier(objective='binary:logistic', enable_categorical=False, eval_metric='logloss',\n",
        "                             learning_rate=0.09504317284612004, max_depth=6, n_estimators=188),  # Otimizado com Optuna\n",
        "    'LightGBM': lgbm # Nenhuma otimização aplicada\n",
        "}\n",
        "\n",
        "# Mostrar os melhores parâmetros para os classificadores otimizados\n",
        "print(\"Classificadores com os melhores parâmetros:\")\n",
        "\n",
        "for name, model in best_classifiers.items():\n",
        "  print(f\"{name}: {model}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZsvC5TygOx46"
      },
      "source": [
        "## Avaliando os modelos após Tunning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JREgrxR2pm5B"
      },
      "source": [
        "\n",
        "\n",
        "*   Avalia os modelos após o tunning usando Optuna e Bayesian Search (dicionário anterior)\n",
        "*   Calcula o tempo de execução e consumo de memória para cada modelo.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "SjxnZ3mO_K-g"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "KNN - Accuracy: 0.9791, F1 Score: 0.9789, Recall: 0.9592, ACSA: 0.9793, Training Time (s): 4.1407, Memory Usage (MB): 35.9336, CPU Usage (%): 44.90, GPU Usage (%): 0.00\n",
            "Confusion Matrix:\n",
            "[[7821    0]\n",
            " [   0 7967]]\n",
            "\n",
            "SVM - Accuracy: 0.9680, F1 Score: 0.9673, Recall: 0.9386, ACSA: 0.9683, Training Time (s): 247.6872, Memory Usage (MB): 55.9961, CPU Usage (%): 28.25, GPU Usage (%): 0.00\n",
            "Confusion Matrix:\n",
            "[[7814    7]\n",
            " [ 461 7506]]\n",
            "\n",
            "Decision Tree - Accuracy: 0.9840, F1 Score: 0.9841, Recall: 0.9802, ACSA: 0.9840, Training Time (s): 1.7913, Memory Usage (MB): 2.5352, CPU Usage (%): 14.75, GPU Usage (%): 0.00\n",
            "Confusion Matrix:\n",
            "[[7821    0]\n",
            " [   0 7967]]\n",
            "\n",
            "LVQ - Accuracy: 0.9940, F1 Score: 0.9941, Recall: 0.9908, ACSA: 0.9941, Training Time (s): 92.5322, Memory Usage (MB): -47.8164, CPU Usage (%): 7.00, GPU Usage (%): 0.00\n",
            "Confusion Matrix:\n",
            "[[7816    5]\n",
            " [  20 7947]]\n",
            "\n",
            "MLP - Accuracy: 0.9903, F1 Score: 0.9903, Recall: 0.9847, ACSA: 0.9904, Training Time (s): 46.4567, Memory Usage (MB): 28.5820, CPU Usage (%): 20.85, GPU Usage (%): 0.00\n",
            "Confusion Matrix:\n",
            "[[7813    8]\n",
            " [  61 7906]]\n",
            "\n",
            "Ensemble Neural Network - Accuracy: 0.9942, F1 Score: 0.9943, Recall: 0.9903, ACSA: 0.9943, Training Time (s): 124.4698, Memory Usage (MB): -121.1172, CPU Usage (%): 21.70, GPU Usage (%): 0.00\n",
            "Confusion Matrix:\n",
            "[[7820    1]\n",
            " [  16 7951]]\n",
            "\n",
            "Stacking - Accuracy: 0.8867, F1 Score: 0.8892, Recall: 0.9030, ACSA: 0.8865, Training Time (s): 4.1239, Memory Usage (MB): -16.5156, CPU Usage (%): 27.70, GPU Usage (%): 0.00\n",
            "Confusion Matrix:\n",
            "[[6682 1139]\n",
            " [ 598 7369]]\n",
            "\n",
            "Random Forest - Accuracy: 0.9911, F1 Score: 0.9911, Recall: 0.9862, ACSA: 0.9911, Training Time (s): 22.5656, Memory Usage (MB): 59.7812, CPU Usage (%): 20.65, GPU Usage (%): 0.00\n",
            "Confusion Matrix:\n",
            "[[7821    0]\n",
            " [   0 7967]]\n",
            "\n",
            "XGBoost - Accuracy: 0.9908, F1 Score: 0.9908, Recall: 0.9853, ACSA: 0.9909, Training Time (s): 5.6625, Memory Usage (MB): 61.6406, CPU Usage (%): 54.05, GPU Usage (%): 0.00\n",
            "Confusion Matrix:\n",
            "[[7819    2]\n",
            " [  15 7952]]\n",
            "\n",
            "LightGBM - Accuracy: 0.9457, F1 Score: 0.9442, Recall: 0.9101, ACSA: 0.9461, Training Time (s): 1.1451, Memory Usage (MB): 1.0586, CPU Usage (%): 65.15, GPU Usage (%): 0.00\n",
            "Confusion Matrix:\n",
            "[[7712  109]\n",
            " [ 709 7258]]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "from memory_profiler import memory_usage\n",
        "import psutil\n",
        "import GPUtil\n",
        "import warnings\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, f1_score, recall_score, confusion_matrix\n",
        "from sklearn.model_selection import cross_validate\n",
        "\n",
        "# Filtrar warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Definindo os classificadores otimizados com os melhores parâmetros\n",
        "classifiers = best_classifiers\n",
        "\n",
        "def calculate_acsa(y_true, y_pred):\n",
        "    classes = np.unique(y_true)\n",
        "    class_accuracies = [\n",
        "        accuracy_score(y_true[y_true == c], y_pred[y_true == c]) for c in classes\n",
        "    ]\n",
        "    return np.mean(class_accuracies)\n",
        "\n",
        "def get_gpu_usage():\n",
        "    \"\"\"\n",
        "    Obtém o uso da GPU se disponível.\n",
        "    \"\"\"\n",
        "    gpus = GPUtil.getGPUs()\n",
        "    if not gpus:\n",
        "        return 0  # Sem GPU disponível\n",
        "    return sum([gpu.load for gpu in gpus]) / len(gpus) * 100  # Média de uso em %\n",
        "\n",
        "def evaluate_model(model, X, y, kfold):\n",
        "    \"\"\"\n",
        "    Avalia o modelo com métricas de desempenho e recursos computacionais (tempo, memória, CPU e GPU).\n",
        "    \"\"\"\n",
        "\n",
        "    # Converter para array numpy se for DataFrame/Series\n",
        "    X_numpy = X.values if hasattr(X, 'values') else X\n",
        "    y_numpy = y.values if hasattr(y, 'values') else y\n",
        "\n",
        "    # Iniciar medição de tempo, memória, CPU e GPU\n",
        "    start_time = time.time()\n",
        "    mem_usage_start = memory_usage()[0]\n",
        "    cpu_start = psutil.cpu_percent(interval=None)\n",
        "    gpu_start = get_gpu_usage()\n",
        "\n",
        "    # Usar cross_validate para calcular accuracy, f1 e recall em uma única chamada\n",
        "    scoring = ['accuracy', 'f1', 'recall']\n",
        "    scores = cross_validate(model, X_numpy, y_numpy, cv=kfold, scoring=scoring, return_estimator=True)\n",
        "\n",
        "    # Calcular tempo, memória, CPU e GPU após validação cruzada\n",
        "    training_time = time.time() - start_time\n",
        "    mem_usage_end = memory_usage()[0]\n",
        "    memory_consumed = mem_usage_end - mem_usage_start\n",
        "    cpu_end = psutil.cpu_percent(interval=None)\n",
        "    gpu_end = get_gpu_usage()\n",
        "\n",
        "    # Calcular média de uso de CPU e GPU\n",
        "    cpu_usage = (cpu_end + cpu_start) / 2\n",
        "    gpu_usage = (gpu_end + gpu_start) / 2\n",
        "\n",
        "    # Métricas médias da validação cruzada\n",
        "    accuracy = scores['test_accuracy'].mean()\n",
        "    f1 = scores['test_f1'].mean()\n",
        "    recall = scores['test_recall'].mean()\n",
        "\n",
        "    # Cálculo do ACSA manualmente\n",
        "    acsa_scores = []\n",
        "    for estimator, (train_idx, val_idx) in zip(scores['estimator'], kfold.split(X_numpy, y_numpy)):\n",
        "        X_val_fold = X_numpy[val_idx]\n",
        "        y_val_fold = y_numpy[val_idx]\n",
        "        y_pred_fold = estimator.predict(X_val_fold)\n",
        "        acsa_scores.append(calculate_acsa(y_val_fold, y_pred_fold))\n",
        "    acsa = np.mean(acsa_scores)\n",
        "\n",
        "    # Ajustar modelo nos dados completos e calcular a matriz de confusão\n",
        "    model.fit(X_numpy, y_numpy)\n",
        "    y_pred = model.predict(X_numpy)\n",
        "    conf_matrix = confusion_matrix(y_numpy, y_pred)\n",
        "\n",
        "    return accuracy, f1, recall, acsa, conf_matrix, training_time, memory_consumed, cpu_usage, gpu_usage\n",
        "\n",
        "# Uso do código\n",
        "results = {}\n",
        "for name, clf in best_classifiers.items():\n",
        "    # Avaliar desempenho do classificador\n",
        "    accuracy, f1, recall, acsa, conf_matrix, training_time, memory_consumed, cpu_usage, gpu_usage = evaluate_model(clf, X_train_resampled, y_train_resampled, kfold)\n",
        "\n",
        "    results[name] = {\n",
        "        'Accuracy': accuracy,\n",
        "        'F1 Score': f1,\n",
        "        'Recall': recall,\n",
        "        'ACSA': acsa,\n",
        "        'Training Time (s)': training_time,\n",
        "        'Memory Usage (MB)': memory_consumed,\n",
        "        'CPU Usage (%)': cpu_usage,\n",
        "        'GPU Usage (%)': gpu_usage,\n",
        "        'Confusion Matrix': conf_matrix\n",
        "    }\n",
        "\n",
        "    print(f\"{name} - Accuracy: {accuracy:.4f}, F1 Score: {f1:.4f}, Recall: {recall:.4f}, ACSA: {acsa:.4f}, Training Time (s): {training_time:.4f}, Memory Usage (MB): {memory_consumed:.4f}, CPU Usage (%): {cpu_usage:.2f}, GPU Usage (%): {gpu_usage:.2f}\")\n",
        "    print(f\"Confusion Matrix:\\n{conf_matrix}\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "1PwfWABKthgx"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Score</th>\n",
              "      <th>Recall</th>\n",
              "      <th>ACSA</th>\n",
              "      <th>Training Time (s)</th>\n",
              "      <th>Memory Usage (MB)</th>\n",
              "      <th>CPU Usage (%)</th>\n",
              "      <th>GPU Usage (%)</th>\n",
              "      <th>Confusion Matrix</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>KNN</th>\n",
              "      <td>0.979098</td>\n",
              "      <td>0.978856</td>\n",
              "      <td>0.959209</td>\n",
              "      <td>0.979285</td>\n",
              "      <td>4.140716</td>\n",
              "      <td>35.933594</td>\n",
              "      <td>44.90</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[[7821, 0], [0, 7967]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SVM</th>\n",
              "      <td>0.968014</td>\n",
              "      <td>0.967327</td>\n",
              "      <td>0.938623</td>\n",
              "      <td>0.968288</td>\n",
              "      <td>247.687245</td>\n",
              "      <td>55.996094</td>\n",
              "      <td>28.25</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[[7814, 7], [461, 7506]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Decision Tree</th>\n",
              "      <td>0.983975</td>\n",
              "      <td>0.984058</td>\n",
              "      <td>0.980167</td>\n",
              "      <td>0.984011</td>\n",
              "      <td>1.791338</td>\n",
              "      <td>2.535156</td>\n",
              "      <td>14.75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[[7821, 0], [0, 7967]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LVQ</th>\n",
              "      <td>0.994046</td>\n",
              "      <td>0.994080</td>\n",
              "      <td>0.990837</td>\n",
              "      <td>0.994076</td>\n",
              "      <td>92.532249</td>\n",
              "      <td>-47.816406</td>\n",
              "      <td>7.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[[7816, 5], [20, 7947]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MLP</th>\n",
              "      <td>0.990309</td>\n",
              "      <td>0.990342</td>\n",
              "      <td>0.984687</td>\n",
              "      <td>0.990362</td>\n",
              "      <td>46.456718</td>\n",
              "      <td>28.582031</td>\n",
              "      <td>20.85</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[[7813, 8], [61, 7906]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ensemble Neural Network</th>\n",
              "      <td>0.994236</td>\n",
              "      <td>0.994266</td>\n",
              "      <td>0.990336</td>\n",
              "      <td>0.994273</td>\n",
              "      <td>124.469784</td>\n",
              "      <td>-121.117188</td>\n",
              "      <td>21.70</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[[7820, 1], [16, 7951]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Stacking</th>\n",
              "      <td>0.886687</td>\n",
              "      <td>0.889236</td>\n",
              "      <td>0.902975</td>\n",
              "      <td>0.886532</td>\n",
              "      <td>4.123944</td>\n",
              "      <td>-16.515625</td>\n",
              "      <td>27.70</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[[6682, 1139], [598, 7369]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Random Forest</th>\n",
              "      <td>0.991069</td>\n",
              "      <td>0.991104</td>\n",
              "      <td>0.986192</td>\n",
              "      <td>0.991114</td>\n",
              "      <td>22.565561</td>\n",
              "      <td>59.781250</td>\n",
              "      <td>20.65</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[[7821, 0], [0, 7967]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>XGBoost</th>\n",
              "      <td>0.990816</td>\n",
              "      <td>0.990845</td>\n",
              "      <td>0.985313</td>\n",
              "      <td>0.990867</td>\n",
              "      <td>5.662494</td>\n",
              "      <td>61.640625</td>\n",
              "      <td>54.05</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[[7819, 2], [15, 7952]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LightGBM</th>\n",
              "      <td>0.945718</td>\n",
              "      <td>0.944180</td>\n",
              "      <td>0.910131</td>\n",
              "      <td>0.946052</td>\n",
              "      <td>1.145050</td>\n",
              "      <td>1.058594</td>\n",
              "      <td>65.15</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[[7712, 109], [709, 7258]]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                         Accuracy  F1 Score    Recall      ACSA  \\\n",
              "KNN                      0.979098  0.978856  0.959209  0.979285   \n",
              "SVM                      0.968014  0.967327  0.938623  0.968288   \n",
              "Decision Tree            0.983975  0.984058  0.980167  0.984011   \n",
              "LVQ                      0.994046  0.994080  0.990837  0.994076   \n",
              "MLP                      0.990309  0.990342  0.984687  0.990362   \n",
              "Ensemble Neural Network  0.994236  0.994266  0.990336  0.994273   \n",
              "Stacking                 0.886687  0.889236  0.902975  0.886532   \n",
              "Random Forest            0.991069  0.991104  0.986192  0.991114   \n",
              "XGBoost                  0.990816  0.990845  0.985313  0.990867   \n",
              "LightGBM                 0.945718  0.944180  0.910131  0.946052   \n",
              "\n",
              "                         Training Time (s)  Memory Usage (MB)  CPU Usage (%)  \\\n",
              "KNN                               4.140716          35.933594          44.90   \n",
              "SVM                             247.687245          55.996094          28.25   \n",
              "Decision Tree                     1.791338           2.535156          14.75   \n",
              "LVQ                              92.532249         -47.816406           7.00   \n",
              "MLP                              46.456718          28.582031          20.85   \n",
              "Ensemble Neural Network         124.469784        -121.117188          21.70   \n",
              "Stacking                          4.123944         -16.515625          27.70   \n",
              "Random Forest                    22.565561          59.781250          20.65   \n",
              "XGBoost                           5.662494          61.640625          54.05   \n",
              "LightGBM                          1.145050           1.058594          65.15   \n",
              "\n",
              "                         GPU Usage (%)             Confusion Matrix  \n",
              "KNN                                0.0       [[7821, 0], [0, 7967]]  \n",
              "SVM                                0.0     [[7814, 7], [461, 7506]]  \n",
              "Decision Tree                      0.0       [[7821, 0], [0, 7967]]  \n",
              "LVQ                                0.0      [[7816, 5], [20, 7947]]  \n",
              "MLP                                0.0      [[7813, 8], [61, 7906]]  \n",
              "Ensemble Neural Network            0.0      [[7820, 1], [16, 7951]]  \n",
              "Stacking                           0.0  [[6682, 1139], [598, 7369]]  \n",
              "Random Forest                      0.0       [[7821, 0], [0, 7967]]  \n",
              "XGBoost                            0.0      [[7819, 2], [15, 7952]]  \n",
              "LightGBM                           0.0   [[7712, 109], [709, 7258]]  "
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Exibir resultados\n",
        "import pandas as pd\n",
        "df_results = pd.DataFrame.from_dict(results, orient='index')\n",
        "\n",
        "# Salvar em Excel\n",
        "df_results.to_excel('results_with_cost_benefit.xlsx')\n",
        "\n",
        "# Apresentar\n",
        "df_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lroaa666bSO"
      },
      "source": [
        "## Comparando Antes e Depois ADASYN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "777Kseeu6ljM"
      },
      "source": [
        "Comparando os desempenhos do treinamento dos classificadores KNN e Árvore de Decisão antes e depois de aplicar o balanceamento de classes usando a técnica ADASYN."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "gSeHtMSE616z"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      Classifier   Phase  Accuracy  F1 Score    Recall      ACSA\n",
            "0            KNN   Antes  0.964083  0.972762  0.966113  0.963098\n",
            "1            KNN  Depois  0.979098  0.978856  0.959209  0.979285\n",
            "2  Decision Tree   Antes  0.978417  0.983753  0.983934  0.975728\n",
            "3  Decision Tree  Depois  0.984672  0.984749  0.980669  0.984709\n",
            "4            MLP   Antes  0.988333  0.991227  0.992720  0.986196\n",
            "5            MLP  Depois  0.990499  0.990528  0.984562  0.990555\n"
          ]
        }
      ],
      "source": [
        "# Classificadores após o Tunning\n",
        "\n",
        "adasyn_classifiers = {\n",
        "    'KNN': KNeighborsClassifier(n_neighbors=1, p=1, weights='uniform'), # Otimizado com Bayesian Search\n",
        "    'Decision Tree': DecisionTreeClassifier(criterion='entropy', max_depth=36, min_samples_leaf=1, min_samples_split=2), # Otimizado com Bayesian Search\n",
        "    'MLP': mlp  # Nenhuma otimização aplicada\n",
        "}\n",
        "\n",
        "# Dicionário para armazenar os resultados\n",
        "results_adasyn = {\n",
        "    'Classifier': [],\n",
        "    'Phase': [],  # 'Antes' ou 'Depois' o balanceamento\n",
        "    'Accuracy': [],\n",
        "    'F1 Score': [],\n",
        "    'Recall': [],\n",
        "    'ACSA': []\n",
        "}\n",
        "\n",
        "# Iterando no dicionário de classificadores\n",
        "for name, clf in adasyn_classifiers.items():\n",
        "    # Avaliação antes do balanceamento\n",
        "    accuracy, f1, recall, acsa, conf_matrix, training_time, memory_consumed, cpu_usage, gpu_usage = evaluate_model(clf, X_train, y_train, kfold)\n",
        "    results_adasyn['Classifier'].append(name)\n",
        "    results_adasyn['Phase'].append('Antes')\n",
        "    results_adasyn['Accuracy'].append(accuracy)\n",
        "    results_adasyn['F1 Score'].append(f1)\n",
        "    results_adasyn['Recall'].append(recall)\n",
        "    results_adasyn['ACSA'].append(acsa)\n",
        "\n",
        "    # Avaliação após o balanceamento\n",
        "    accuracy, f1, recall, acsa, conf_matrix, training_time, memory_consumed, cpu_usage, gpu_usage = evaluate_model(clf, X_train_resampled, y_train_resampled, kfold)\n",
        "    results_adasyn['Classifier'].append(name)\n",
        "    results_adasyn['Phase'].append('Depois')\n",
        "    results_adasyn['Accuracy'].append(accuracy)\n",
        "    results_adasyn['F1 Score'].append(f1)\n",
        "    results_adasyn['Recall'].append(recall)\n",
        "    results_adasyn['ACSA'].append(acsa)\n",
        "\n",
        "# Conversão para um DataFrame\n",
        "df_results_adasyn = pd.DataFrame(results_adasyn)\n",
        "\n",
        "# Exibição do DataFrame\n",
        "print(df_results_adasyn)\n",
        "\n",
        "# Salvar o DataFrame em um arquivo Excel\n",
        "df_results_adasyn.to_excel('results_adasyn_comparison.xlsx', index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ik5UYhwsLZEL"
      },
      "source": [
        "## Desempenho Treino e Teste após Tunning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "aHAjbN64Leno"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                 Classifier        Etapa  Accuracy  F1 Score    Recall  \\\n",
            "0                       KNN  Treinamento  0.979098  0.978856  0.959209   \n",
            "1                       KNN        Teste  0.942667  0.956500  0.950807   \n",
            "2                       SVM  Treinamento  0.968014  0.967327  0.938623   \n",
            "3                       SVM        Teste  0.948000  0.961662  0.980925   \n",
            "4             Decision Tree  Treinamento  0.984925  0.984993  0.980418   \n",
            "5             Decision Tree        Teste  0.962667  0.971903  0.972882   \n",
            "6                       LVQ  Treinamento  0.993729  0.993769  0.991339   \n",
            "7                       LVQ        Teste  0.977333  0.983044  0.988455   \n",
            "8                       MLP  Treinamento  0.990626  0.990655  0.984687   \n",
            "9                       MLP        Teste  0.972000  0.979104  0.986947   \n",
            "10  Ensemble Neural Network  Treinamento  0.994426  0.994458  0.991089   \n",
            "11  Ensemble Neural Network        Teste  0.971667  0.978885  0.987450   \n",
            "12                 Stacking  Treinamento  0.886687  0.889236  0.902975   \n",
            "13                 Stacking        Teste  0.921667  0.941995  0.957332   \n",
            "14            Random Forest  Treinamento  0.991449  0.991485  0.986569   \n",
            "15            Random Forest        Teste  0.970000  0.977722  0.989965   \n",
            "16                  XGBoost  Treinamento  0.990816  0.990845  0.985313   \n",
            "17                  XGBoost        Teste  0.977667  0.983267  0.987450   \n",
            "18                 LightGBM  Treinamento  0.945718  0.944180  0.910131   \n",
            "19                 LightGBM        Teste  0.952667  0.964626  0.971894   \n",
            "\n",
            "        ACSA  \n",
            "0   0.979285  \n",
            "1   0.938715  \n",
            "2   0.968288  \n",
            "3   0.931913  \n",
            "4   0.984967  \n",
            "5   0.957664  \n",
            "6   0.993752  \n",
            "7   0.971911  \n",
            "8   0.990681  \n",
            "9   0.964701  \n",
            "10  0.994457  \n",
            "11  0.963953  \n",
            "12  0.886532  \n",
            "13  0.904255  \n",
            "14  0.991495  \n",
            "15  0.960265  \n",
            "16  0.990867  \n",
            "17  0.972893  \n",
            "18  0.946052  \n",
            "19  0.943284  \n"
          ]
        }
      ],
      "source": [
        "# Converter parâmetros otimizados para inicializar os classificadores\n",
        "best_classifiers = {\n",
        "    'KNN': KNeighborsClassifier(n_neighbors=1, p=1, weights='uniform'), # Otimizado com Bayesian Search\n",
        "    'SVM': svm,  # Nenhuma otimização aplicada\n",
        "    'Decision Tree': DecisionTreeClassifier(criterion='entropy', max_depth=36, min_samples_leaf=1, min_samples_split=2), # Otimizado com Bayesian Search\n",
        "    'LVQ': lvq,  # Nenhuma otimização aplicada\n",
        "    'MLP': mlp,  # Nenhuma otimização aplicada\n",
        "    'Ensemble Neural Network': ann_ensemble,  # Nenhuma otimização aplicada\n",
        "    'Stacking': stacking,  # Nenhuma otimização aplicada\n",
        "    'Random Forest': RandomForestClassifier(max_depth=28, n_estimators=97), # Otimizado com Optuna\n",
        "    'XGBoost': XGBClassifier(objective='binary:logistic', enable_categorical=False, eval_metric='logloss',\n",
        "                             learning_rate=0.09504317284612004, max_depth=6, n_estimators=188),  # Otimizado com Optuna\n",
        "    'LightGBM': lgbm # Nenhuma otimização aplicada\n",
        "}\n",
        "\n",
        "# Configurar K-Fold com estratificação\n",
        "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# Dicionário para armazenar os resultados\n",
        "results_train_teste = {\n",
        "    'Classifier': [],\n",
        "    'Etapa': [],  # 'Antes' ou 'Depois' o balanceamento\n",
        "    'Accuracy': [],\n",
        "    'F1 Score': [],\n",
        "    'Recall': [],\n",
        "    'ACSA': []\n",
        "}\n",
        "\n",
        "# Iterando no dicionário de classificadores\n",
        "for name, clf in best_classifiers.items():\n",
        "    # Avaliação antes do balanceamento\n",
        "    accuracy, f1, recall, acsa, conf_matrix, training_time, memory_consumed, cpu_usage, gpu_usage = evaluate_model(clf, X_train_resampled, y_train_resampled, kfold)\n",
        "    results_train_teste['Classifier'].append(name)\n",
        "    results_train_teste['Etapa'].append('Treinamento')\n",
        "    results_train_teste['Accuracy'].append(accuracy)\n",
        "    results_train_teste['F1 Score'].append(f1)\n",
        "    results_train_teste['Recall'].append(recall)\n",
        "    results_train_teste['ACSA'].append(acsa)\n",
        "\n",
        "    # Avaliação após o balanceamento\n",
        "    accuracy, f1, recall, acsa, conf_matrix, training_time, memory_consumed, cpu_usage, gpu_usage = evaluate_model(clf, X_test, y_test, kfold)\n",
        "    results_train_teste['Classifier'].append(name)\n",
        "    results_train_teste['Etapa'].append('Teste')\n",
        "    results_train_teste['Accuracy'].append(accuracy)\n",
        "    results_train_teste['F1 Score'].append(f1)\n",
        "    results_train_teste['Recall'].append(recall)\n",
        "    results_train_teste['ACSA'].append(acsa)\n",
        "\n",
        "# Conversão para um DataFrame\n",
        "df_results_train_teste = pd.DataFrame(results_train_teste)\n",
        "\n",
        "# Exibição do DataFrame\n",
        "print(df_results_train_teste)\n",
        "\n",
        "# Salvar o DataFrame em um arquivo Excel\n",
        "df_results_train_teste.to_excel('results_train_teste_comparison.xlsx', index=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGeDInlGjm2L"
      },
      "source": [
        "## Amostra para análise Estatística"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "uTcxxjHKk6Oo",
        "outputId": "4b89cc82-d8e0-451c-d5a7-2abb6d4328fe"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'best_classifiers' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-63217dd0d10e>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Definindo os classificadores otimizados com os melhores parâmetros\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mclassifiers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_classifiers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcalculate_acsa\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'best_classifiers' is not defined"
          ]
        }
      ],
      "source": [
        "import warnings\n",
        "import logging\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, f1_score, recall_score, confusion_matrix\n",
        "from xgboost import set_config\n",
        "\n",
        "# Filtrar warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "logging.getLogger('sklearn').setLevel(logging.ERROR)\n",
        "os.environ['PYTHONWARNINGS'] = 'ignore'\n",
        "set_config(verbosity=0)\n",
        "\n",
        "# Definindo os classificadores otimizados com os melhores parâmetros\n",
        "classifiers = best_classifiers\n",
        "\n",
        "def calculate_acsa(y_true, y_pred):\n",
        "    \"\"\"Calcula o Average Class-Specific Accuracy (ACSA).\"\"\"\n",
        "    classes = np.unique(y_true)\n",
        "    class_accuracies = [\n",
        "        accuracy_score(y_true[y_true == c], y_pred[y_true == c]) for c in classes\n",
        "    ]\n",
        "    return np.mean(class_accuracies)\n",
        "\n",
        "def evaluate_model(model, X, y, kfold, n_samples=10):\n",
        "    \"\"\"\n",
        "    Avalia o modelo usando validação cruzada múltiplas vezes.\n",
        "    Args:\n",
        "    model: Modelo de classificação\n",
        "    X: Features (DataFrame ou array)\n",
        "    y: Target (Series ou array)\n",
        "    kfold: Objeto de validação cruzada\n",
        "    n_samples: Número de iterações de avaliação\n",
        "    \"\"\"\n",
        "    # Converter para numpy arrays se necessário\n",
        "    X_numpy = X.values if hasattr(X, 'values') else np.array(X)\n",
        "    y_numpy = y.values if hasattr(y, 'values') else np.array(y)\n",
        "    results = {\n",
        "        'Accuracy': [],\n",
        "        'F1 Score': [],\n",
        "        'Recall': [],\n",
        "        'ACSA': [],\n",
        "        'Confusion Matrix': []\n",
        "    }\n",
        "    for sample in range(n_samples):\n",
        "        try:\n",
        "            # Realizando a validação cruzada\n",
        "            scores = cross_validate(\n",
        "                model,\n",
        "                X_numpy,\n",
        "                y_numpy,\n",
        "                cv=kfold,\n",
        "                scoring=['accuracy', 'f1', 'recall'],\n",
        "                return_estimator=True,\n",
        "                n_jobs=-1 # Usar todos os cores disponíveis\n",
        "            )\n",
        "            # Métricas médias da validação cruzada\n",
        "            results['Accuracy'].append(scores['test_accuracy'].mean())\n",
        "            results['F1 Score'].append(scores['test_f1'].mean())\n",
        "            results['Recall'].append(scores['test_recall'].mean())\n",
        "            # Cálculo do ACSA\n",
        "            acsa_scores = []\n",
        "            for estimator, (_, val_idx) in zip(scores['estimator'], kfold.split(X_numpy, y_numpy)):\n",
        "                X_val = X_numpy[val_idx]\n",
        "                y_val = y_numpy[val_idx]\n",
        "                y_pred = estimator.predict(X_val)\n",
        "                acsa_scores.append(calculate_acsa(y_val, y_pred))\n",
        "            results['ACSA'].append(np.mean(acsa_scores))\n",
        "            # Matriz de confusão usando o último modelo ajustado\n",
        "            model.fit(X_numpy, y_numpy)\n",
        "            y_pred_final = model.predict(X_numpy)\n",
        "            results['Confusion Matrix'].append(confusion_matrix(y_numpy, y_pred_final))\n",
        "        except Exception as e:\n",
        "            print(f\"Erro na amostra {sample}: {str(e)}\")\n",
        "            continue\n",
        "    return results\n",
        "\n",
        "def print_results(results_dict):\n",
        "    \"\"\"Imprime os resultados de forma organizada e gera DataFrames.\"\"\"\n",
        "    metrics_dfs = {metric: pd.DataFrame() for metric in ['Accuracy', 'F1 Score', 'Recall', 'ACSA']}\n",
        "\n",
        "    for name, metrics in results_dict.items():\n",
        "        print(f\"\\n{'='*50}\")\n",
        "        print(f\"Resultados para {name}:\")\n",
        "        print(f\"{'='*50}\")\n",
        "        # Métricas numéricas\n",
        "        for metric in ['Accuracy', 'F1 Score', 'Recall', 'ACSA']:\n",
        "            values = metrics[metric]\n",
        "            if values: # Verifica se há valores\n",
        "                print(f\"\\n{metric}:\")\n",
        "                for value in values:\n",
        "                    print(f\" {value:.4f}\")\n",
        "                # Adiciona os resultados ao DataFrame correspondente\n",
        "                metrics_dfs[metric][name] = values\n",
        "\n",
        "    # Retorna os DataFrames\n",
        "    return metrics_dfs\n",
        "\n",
        "def save_to_excel(metrics_dfs, filename='metrics_results.xlsx'):\n",
        "    \"\"\"Salva os DataFrames em uma planilha Excel, com cada aba representando uma métrica distinta.\"\"\"\n",
        "    with pd.ExcelWriter(filename) as writer:\n",
        "        for metric, df in metrics_dfs.items():\n",
        "            df.to_excel(writer, sheet_name=metric)\n",
        "\n",
        "# Uso do código\n",
        "if __name__ == \"__main__\":\n",
        "    # Definindo a validação cruzada\n",
        "    kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=None)\n",
        "    # Inicializando resultados\n",
        "    results = {}\n",
        "    # Avaliando cada classificador\n",
        "    for name, clf in classifiers.items():\n",
        "        print(f\"\\nAvaliando {name}...\")\n",
        "        results[name] = evaluate_model(\n",
        "            clf,\n",
        "            X_train_resampled,\n",
        "            y_train_resampled,\n",
        "            kfold,\n",
        "            n_samples=10\n",
        "        )\n",
        "    # Imprimindo resultados e gerando DataFrames\n",
        "    metrics_dfs = print_results(results)\n",
        "\n",
        "    # Salvando os DataFrames em uma planilha Excel\n",
        "    save_to_excel(metrics_dfs)\n",
        "\n",
        "    # Exemplo de como acessar os DataFrames\n",
        "    accuracy_df = metrics_dfs['Accuracy']\n",
        "    f1_score_df = metrics_dfs['F1 Score']\n",
        "    recall_df = metrics_dfs['Recall']\n",
        "    acsa_df = metrics_dfs['ACSA']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0WVIGz29R7P_"
      },
      "outputs": [],
      "source": [
        "save_to_excel(metrics_dfs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOm8zAO4KJLA"
      },
      "source": [
        "## Teste de Estresse novos dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "hspEQcvVNI7l"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exemplo de dados sintéticos:\n",
            "         f1        f2        f3        f4        f5        f6        f7  \\\n",
            "0 -0.709034  1.821895 -0.428435 -1.080253 -1.533002 -2.477963  1.931523   \n",
            "1 -0.048399 -0.513274 -2.487549  0.015423 -0.109139  2.276844 -2.821041   \n",
            "2 -0.096361 -0.958079  1.451876  0.114233 -1.816267 -2.034018  0.377797   \n",
            "3  0.370614  1.172721 -0.012268 -0.869129 -1.175980 -2.386580  2.976942   \n",
            "4 -0.943470  0.489240  0.595528  0.775231  0.689383  2.549239  2.279363   \n",
            "\n",
            "         f8        f9       f13  ...       f24       f25       f26       f27  \\\n",
            "0 -1.748039 -5.764765 -1.108936  ...  0.849253 -0.882679 -1.612481 -0.956168   \n",
            "1 -1.065388  2.284075 -1.843787  ... -4.085409  2.466588  1.710018 -0.330585   \n",
            "2  0.136372 -2.372769  2.604354  ...  4.470797  0.735681  0.428566 -1.700121   \n",
            "3 -1.849548  2.355882  1.687067  ...  2.232197 -0.416594 -0.217226 -0.687524   \n",
            "4  0.427319 -0.125368 -0.890731  ...  0.389476 -0.849795 -0.580079 -0.159359   \n",
            "\n",
            "        f28       f29       f30       f31       f32       f33  \n",
            "0 -0.665010  1.414745 -0.858087  1.733917  1.134538  0.934802  \n",
            "1  2.657533 -0.854467 -1.545804  3.054836  0.539043 -1.182569  \n",
            "2 -0.427878 -0.166840  0.671026  0.693551  1.283739 -0.570194  \n",
            "3 -4.359169  0.759771  0.398868  2.574406 -0.172927  0.113494  \n",
            "4  1.879260 -0.371192 -1.966048  0.297168  1.722628  0.801129  \n",
            "\n",
            "[5 rows x 30 columns]\n",
            "\n",
            "Distribuição das classes:\n",
            "target\n",
            "1    504\n",
            "0    496\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Gerar Dados Sintéticos\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "def generate_synthetic_data(n_samples=100, n_features=30, n_informative=10, n_redundant=5, feature_names=None, random_state=42):\n",
        "    \"\"\"\n",
        "    Gera dados sintéticos para teste de estresse de classificadores.\n",
        "\n",
        "    Args:\n",
        "    n_samples (int): Número de amostras.\n",
        "    n_features (int): Número total de características.\n",
        "    n_informative (int): Número de características informativas.\n",
        "    n_redundant (int): Número de características redundantes.\n",
        "    feature_names (list): Lista de nomes para as colunas geradas.\n",
        "    random_state (int): Semente para reprodutibilidade.\n",
        "\n",
        "    Returns:\n",
        "    X_synthetic (DataFrame): Dados de entrada sintéticos.\n",
        "    y_synthetic (Series): Classes correspondentes.\n",
        "    \"\"\"\n",
        "    # Gerar dados\n",
        "    X, y = make_classification(\n",
        "        n_samples=n_samples,\n",
        "        n_features=n_features,\n",
        "        n_informative=n_informative,\n",
        "        n_redundant=n_redundant,\n",
        "        n_classes=2,\n",
        "        flip_y=0.1,  # Introduzir ruído\n",
        "        class_sep=0.8,  # Reduzir separação entre classes para maior desafio\n",
        "        random_state=random_state\n",
        "    )\n",
        "\n",
        "    # Converter para DataFrame\n",
        "    if feature_names is None:\n",
        "        feature_names = [f\"feature_{i}\" for i in range(1, n_features + 1)]\n",
        "    X_synthetic = pd.DataFrame(X, columns=feature_names)\n",
        "    y_synthetic = pd.Series(y, name=\"target\")\n",
        "\n",
        "    return X_synthetic, y_synthetic\n",
        "\n",
        "# Gerar dados sintéticos com os mesmos nomes de colunas dos dados de treinamento\n",
        "X_synthetic, y_synthetic = generate_synthetic_data(\n",
        "    n_samples=1000,\n",
        "    n_features=X_train_resampled.shape[1],\n",
        "    n_informative=10,\n",
        "    n_redundant=5,\n",
        "    feature_names=X_train_resampled.columns.tolist()\n",
        ")\n",
        "\n",
        "# Visualizar os dados gerados\n",
        "print(\"Exemplo de dados sintéticos:\")\n",
        "print(X_synthetic.head())\n",
        "print(\"\\nDistribuição das classes:\")\n",
        "print(y_synthetic.value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Resultados do teste de estresse:\n",
            "                    Modelo  Acurácia  Precisão  Recall  F1-Score  \\\n",
            "0                      KNN     100.0    100.00   100.0    100.00   \n",
            "1                      SVM      50.5     75.03    50.5     34.00   \n",
            "6                 Stacking      50.4     25.40    50.4     33.78   \n",
            "4                      MLP      49.3     48.74    49.3     45.46   \n",
            "7            Random Forest      48.5     43.25    48.5     36.97   \n",
            "9                 LightGBM      48.3     45.71    48.3     40.23   \n",
            "8                  XGBoost      48.0     45.80    48.0     41.18   \n",
            "2            Decision Tree      47.3     45.65    47.3     42.56   \n",
            "5  Ensemble Neural Network      46.1     45.11    46.1     43.68   \n",
            "3                      LVQ      45.2     43.13    45.2     41.15   \n",
            "\n",
            "   Precisão_Classe_0  Recall_Classe_0  F1_Classe_0  Amostras_Classe_0  \\\n",
            "0             100.00           100.00       100.00                496   \n",
            "1             100.00             0.20         0.40                496   \n",
            "6               0.00             0.00         0.00                496   \n",
            "4              47.66            22.58        30.64                496   \n",
            "7              36.99             5.44         9.49                496   \n",
            "9              42.11            11.29        17.81                496   \n",
            "8              42.50            13.71        20.73                496   \n",
            "2              42.72            18.35        25.67                496   \n",
            "5              42.66            25.20        31.69                496   \n",
            "3              39.08            18.75        25.34                496   \n",
            "\n",
            "   Precisão_Classe_1  Recall_Classe_1  F1_Classe_1  Amostras_Classe_1  \\\n",
            "0             100.00           100.00       100.00                504   \n",
            "1              50.45           100.00        67.07                504   \n",
            "6              50.40           100.00        67.02                504   \n",
            "4              49.80            75.60        60.05                504   \n",
            "7              49.41            90.87        64.01                504   \n",
            "9              49.25            84.72        62.29                504   \n",
            "8              49.05            81.75        61.31                504   \n",
            "2              48.54            75.79        59.18                504   \n",
            "5              47.52            66.67        55.49                504   \n",
            "3              47.11            71.23        56.71                504   \n",
            "\n",
            "   Total_Amostras  \n",
            "0            1000  \n",
            "1            1000  \n",
            "6            1000  \n",
            "4            1000  \n",
            "7            1000  \n",
            "9            1000  \n",
            "8            1000  \n",
            "2            1000  \n",
            "5            1000  \n",
            "3            1000  \n",
            "\n",
            "Distribuição das classes no conjunto de teste:\n",
            "Classe 0: 496 amostras\n",
            "Classe 1: 504 amostras\n"
          ]
        }
      ],
      "source": [
        "# Teste de Estresse\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "def stress_test_models(best_classifiers, X_synthetic, y_synthetic):\n",
        "    \"\"\"\n",
        "    Realiza testes de estresse nos modelos usando dados sintéticos, analisando cada classe separadamente.\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    best_classifiers : dict\n",
        "        Dicionário contendo os modelos treinados\n",
        "    X_synthetic : array-like\n",
        "        Dados sintéticos de features\n",
        "    y_synthetic : array-like\n",
        "        Labels sintéticos correspondentes\n",
        "    \n",
        "    Returns:\n",
        "    --------\n",
        "    pandas.DataFrame\n",
        "        DataFrame com as métricas de avaliação para cada modelo\n",
        "    \"\"\"\n",
        "    \n",
        "    # Dicionário para armazenar os resultados\n",
        "    results = {\n",
        "        'Modelo': [],\n",
        "        'Acurácia': [],\n",
        "        'Precisão': [],\n",
        "        'Recall': [],\n",
        "        'F1-Score': [],\n",
        "        # Métricas para Classe 0\n",
        "        'Precisão_Classe_0': [],\n",
        "        'Recall_Classe_0': [],\n",
        "        'F1_Classe_0': [],\n",
        "        'Amostras_Classe_0': [],\n",
        "        # Métricas para Classe 1\n",
        "        'Precisão_Classe_1': [],\n",
        "        'Recall_Classe_1': [],\n",
        "        'F1_Classe_1': [],\n",
        "        'Amostras_Classe_1': [],\n",
        "        # Contagens gerais\n",
        "        'Total_Amostras': []\n",
        "    }\n",
        "    \n",
        "    # Testar cada modelo\n",
        "    for nome_modelo, modelo in best_classifiers.items():\n",
        "        # Fazer predições\n",
        "        y_pred = modelo.predict(X_synthetic)\n",
        "        \n",
        "        # Calcular métricas gerais\n",
        "        accuracy = accuracy_score(y_synthetic, y_pred)\n",
        "        precision = precision_score(y_synthetic, y_pred, average='weighted')\n",
        "        recall = recall_score(y_synthetic, y_pred, average='weighted')\n",
        "        f1 = f1_score(y_synthetic, y_pred, average='weighted')\n",
        "        \n",
        "        # Calcular métricas por classe\n",
        "        precision_per_class = precision_score(y_synthetic, y_pred, average=None)\n",
        "        recall_per_class = recall_score(y_synthetic, y_pred, average=None)\n",
        "        f1_per_class = f1_score(y_synthetic, y_pred, average=None)\n",
        "        \n",
        "        # Contar amostras por classe\n",
        "        unique, counts = np.unique(y_synthetic, return_counts=True)\n",
        "        amostras_por_classe = dict(zip(unique, counts))\n",
        "        \n",
        "        # Armazenar resultados\n",
        "        results['Modelo'].append(nome_modelo)\n",
        "        results['Acurácia'].append(round(accuracy * 100, 2))\n",
        "        results['Precisão'].append(round(precision * 100, 2))\n",
        "        results['Recall'].append(round(recall * 100, 2))\n",
        "        results['F1-Score'].append(round(f1 * 100, 2))\n",
        "        \n",
        "        # Métricas Classe 0\n",
        "        results['Precisão_Classe_0'].append(round(precision_per_class[0] * 100, 2))\n",
        "        results['Recall_Classe_0'].append(round(recall_per_class[0] * 100, 2))\n",
        "        results['F1_Classe_0'].append(round(f1_per_class[0] * 100, 2))\n",
        "        results['Amostras_Classe_0'].append(amostras_por_classe.get(0, 0))\n",
        "        \n",
        "        # Métricas Classe 1\n",
        "        results['Precisão_Classe_1'].append(round(precision_per_class[1] * 100, 2))\n",
        "        results['Recall_Classe_1'].append(round(recall_per_class[1] * 100, 2))\n",
        "        results['F1_Classe_1'].append(round(f1_per_class[1] * 100, 2))\n",
        "        results['Amostras_Classe_1'].append(amostras_por_classe.get(1, 0))\n",
        "        \n",
        "        results['Total_Amostras'].append(len(y_synthetic))\n",
        "    \n",
        "    # Criar DataFrame com os resultados e ordenar por acurácia\n",
        "    df_results = pd.DataFrame(results)\n",
        "    df_results = df_results.sort_values('Acurácia', ascending=False)\n",
        "    \n",
        "    return df_results\n",
        "\n",
        "# Executar o teste de estresse\n",
        "resultados = stress_test_models(best_classifiers, X_synthetic, y_synthetic)\n",
        "\n",
        "print(\"\\nResultados do teste de estresse:\")\n",
        "print(resultados)\n",
        "\n",
        "# Análise das classes\n",
        "print(\"\\nDistribuição das classes no conjunto de teste:\")\n",
        "print(f\"Classe 0: {resultados['Amostras_Classe_0'].iloc[0]} amostras\")\n",
        "print(f\"Classe 1: {resultados['Amostras_Classe_1'].iloc[0]} amostras\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Os resultados foram exportados para o arquivo 'results_stress_test.xlsx'\n",
            "\n",
            "Resultados Gerais:\n",
            "                    Modelo  Acurácia  Precisão  Recall  F1-Score  \\\n",
            "0                      KNN     100.0    100.00   100.0    100.00   \n",
            "1                      SVM      50.5     75.03    50.5     34.00   \n",
            "6                 Stacking      50.4     25.40    50.4     33.78   \n",
            "4                      MLP      49.3     48.74    49.3     45.46   \n",
            "7            Random Forest      48.5     43.25    48.5     36.97   \n",
            "9                 LightGBM      48.3     45.71    48.3     40.23   \n",
            "8                  XGBoost      48.0     45.80    48.0     41.18   \n",
            "2            Decision Tree      47.3     45.65    47.3     42.56   \n",
            "5  Ensemble Neural Network      46.1     45.11    46.1     43.68   \n",
            "3                      LVQ      45.2     43.13    45.2     41.15   \n",
            "\n",
            "   Total_Amostras  \n",
            "0            1000  \n",
            "1            1000  \n",
            "6            1000  \n",
            "4            1000  \n",
            "7            1000  \n",
            "9            1000  \n",
            "8            1000  \n",
            "2            1000  \n",
            "5            1000  \n",
            "3            1000  \n",
            "\n",
            "Resultados Classe 0:\n",
            "                    Modelo  Precisão  Recall  F1-Score  Quantidade_Amostras  \\\n",
            "0                      KNN    100.00  100.00    100.00                  496   \n",
            "5  Ensemble Neural Network     42.66   25.20     31.69                  496   \n",
            "4                      MLP     47.66   22.58     30.64                  496   \n",
            "2            Decision Tree     42.72   18.35     25.67                  496   \n",
            "3                      LVQ     39.08   18.75     25.34                  496   \n",
            "8                  XGBoost     42.50   13.71     20.73                  496   \n",
            "9                 LightGBM     42.11   11.29     17.81                  496   \n",
            "7            Random Forest     36.99    5.44      9.49                  496   \n",
            "1                      SVM    100.00    0.20      0.40                  496   \n",
            "6                 Stacking      0.00    0.00      0.00                  496   \n",
            "\n",
            "   Proporção_Amostras  \n",
            "0                49.6  \n",
            "5                49.6  \n",
            "4                49.6  \n",
            "2                49.6  \n",
            "3                49.6  \n",
            "8                49.6  \n",
            "9                49.6  \n",
            "7                49.6  \n",
            "1                49.6  \n",
            "6                49.6  \n",
            "\n",
            "Resultados Classe 1:\n",
            "                    Modelo  Precisão  Recall  F1-Score  Quantidade_Amostras  \\\n",
            "0                      KNN    100.00  100.00    100.00                  504   \n",
            "1                      SVM     50.45  100.00     67.07                  504   \n",
            "6                 Stacking     50.40  100.00     67.02                  504   \n",
            "7            Random Forest     49.41   90.87     64.01                  504   \n",
            "9                 LightGBM     49.25   84.72     62.29                  504   \n",
            "8                  XGBoost     49.05   81.75     61.31                  504   \n",
            "4                      MLP     49.80   75.60     60.05                  504   \n",
            "2            Decision Tree     48.54   75.79     59.18                  504   \n",
            "3                      LVQ     47.11   71.23     56.71                  504   \n",
            "5  Ensemble Neural Network     47.52   66.67     55.49                  504   \n",
            "\n",
            "   Proporção_Amostras  \n",
            "0                50.4  \n",
            "1                50.4  \n",
            "6                50.4  \n",
            "7                50.4  \n",
            "9                50.4  \n",
            "8                50.4  \n",
            "4                50.4  \n",
            "2                50.4  \n",
            "3                50.4  \n",
            "5                50.4  \n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from datetime import datetime\n",
        "\n",
        "def stress_test_models(best_classifiers, X_synthetic, y_synthetic, export_excel=True):\n",
        "    \"\"\"\n",
        "    Realiza testes de estresse nos modelos e gera relatório em Excel com 3 abas.\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    best_classifiers : dict\n",
        "        Dicionário contendo os modelos treinados\n",
        "    X_synthetic : array-like\n",
        "        Dados sintéticos de features\n",
        "    y_synthetic : array-like\n",
        "        Labels sintéticos correspondentes\n",
        "    export_excel : bool, optional\n",
        "        Se True, exporta os resultados para um arquivo Excel\n",
        "    \"\"\"\n",
        "    \n",
        "    # Dicionários para cada aba\n",
        "    results_geral = {\n",
        "        'Modelo': [],\n",
        "        'Acurácia': [],\n",
        "        'Precisão': [],\n",
        "        'Recall': [],\n",
        "        'F1-Score': [],\n",
        "        'Total_Amostras': []\n",
        "    }\n",
        "    \n",
        "    results_classe_0 = {\n",
        "        'Modelo': [],\n",
        "        'Precisão': [],\n",
        "        'Recall': [],\n",
        "        'F1-Score': [],\n",
        "        'Quantidade_Amostras': [],\n",
        "        'Proporção_Amostras': []\n",
        "    }\n",
        "    \n",
        "    results_classe_1 = {\n",
        "        'Modelo': [],\n",
        "        'Precisão': [],\n",
        "        'Recall': [],\n",
        "        'F1-Score': [],\n",
        "        'Quantidade_Amostras': [],\n",
        "        'Proporção_Amostras': []\n",
        "    }\n",
        "    \n",
        "    # Testar cada modelo\n",
        "    for nome_modelo, modelo in best_classifiers.items():\n",
        "        # Fazer predições\n",
        "        y_pred = modelo.predict(X_synthetic)\n",
        "        \n",
        "        # Métricas gerais\n",
        "        accuracy = accuracy_score(y_synthetic, y_pred)\n",
        "        precision = precision_score(y_synthetic, y_pred, average='weighted')\n",
        "        recall = recall_score(y_synthetic, y_pred, average='weighted')\n",
        "        f1 = f1_score(y_synthetic, y_pred, average='weighted')\n",
        "        \n",
        "        # Métricas por classe\n",
        "        precision_per_class = precision_score(y_synthetic, y_pred, average=None)\n",
        "        recall_per_class = recall_score(y_synthetic, y_pred, average=None)\n",
        "        f1_per_class = f1_score(y_synthetic, y_pred, average=None)\n",
        "        \n",
        "        # Contagem de amostras por classe\n",
        "        unique, counts = np.unique(y_synthetic, return_counts=True)\n",
        "        amostras_por_classe = dict(zip(unique, counts))\n",
        "        total_amostras = len(y_synthetic)\n",
        "        \n",
        "        # Resultados gerais\n",
        "        results_geral['Modelo'].append(nome_modelo)\n",
        "        results_geral['Acurácia'].append(round(accuracy * 100, 2))\n",
        "        results_geral['Precisão'].append(round(precision * 100, 2))\n",
        "        results_geral['Recall'].append(round(recall * 100, 2))\n",
        "        results_geral['F1-Score'].append(round(f1 * 100, 2))\n",
        "        results_geral['Total_Amostras'].append(total_amostras)\n",
        "        \n",
        "        # Resultados Classe 0\n",
        "        results_classe_0['Modelo'].append(nome_modelo)\n",
        "        results_classe_0['Precisão'].append(round(precision_per_class[0] * 100, 2))\n",
        "        results_classe_0['Recall'].append(round(recall_per_class[0] * 100, 2))\n",
        "        results_classe_0['F1-Score'].append(round(f1_per_class[0] * 100, 2))\n",
        "        results_classe_0['Quantidade_Amostras'].append(amostras_por_classe.get(0, 0))\n",
        "        results_classe_0['Proporção_Amostras'].append(round(amostras_por_classe.get(0, 0) / total_amostras * 100, 2))\n",
        "        \n",
        "        # Resultados Classe 1\n",
        "        results_classe_1['Modelo'].append(nome_modelo)\n",
        "        results_classe_1['Precisão'].append(round(precision_per_class[1] * 100, 2))\n",
        "        results_classe_1['Recall'].append(round(recall_per_class[1] * 100, 2))\n",
        "        results_classe_1['F1-Score'].append(round(f1_per_class[1] * 100, 2))\n",
        "        results_classe_1['Quantidade_Amostras'].append(amostras_por_classe.get(1, 0))\n",
        "        results_classe_1['Proporção_Amostras'].append(round(amostras_por_classe.get(1, 0) / total_amostras * 100, 2))\n",
        "    \n",
        "    # Criar DataFrames\n",
        "    df_geral = pd.DataFrame(results_geral).sort_values('Acurácia', ascending=False)\n",
        "    df_classe_0 = pd.DataFrame(results_classe_0).sort_values('F1-Score', ascending=False)\n",
        "    df_classe_1 = pd.DataFrame(results_classe_1).sort_values('F1-Score', ascending=False)\n",
        "    \n",
        "        \n",
        "    return df_geral, df_classe_0, df_classe_1\n",
        "\n",
        "# Exemplo de uso\n",
        "\n",
        "# Teste de estresse\n",
        "resultados_geral, resultados_classe_0, resultados_classe_1 = stress_test_models(\n",
        "    best_classifiers, X_synthetic, y_synthetic\n",
        ")\n",
        "\n",
        "# Exportar para Excel usando openpyxl\n",
        "with pd.ExcelWriter('results_stress_test.xlsx', engine='openpyxl') as writer:\n",
        "    resultados_geral.to_excel(writer, sheet_name='Geral', index=False)\n",
        "    resultados_classe_0.to_excel(writer, sheet_name='Classe_0', index=False)\n",
        "    resultados_classe_1.to_excel(writer, sheet_name='Classe_1', index=False)\n",
        "\n",
        "print(\"Os resultados foram exportados para o arquivo 'results_stress_test.xlsx'\")\n",
        "\n",
        "print(\"\\nResultados Gerais:\")\n",
        "print(resultados_geral)\n",
        "print(\"\\nResultados Classe 0:\")\n",
        "print(resultados_classe_0)\n",
        "print(\"\\nResultados Classe 1:\")\n",
        "print(resultados_classe_1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ht5NaQt7eJ-C"
      },
      "source": [
        "# Roteiro"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBsbCN7EdMOY"
      },
      "source": [
        "- Registro dos resultados em **dataframe** (FEITO)\n",
        "- Visualização de Resultados: Gráficos de caixa (boxplot), barras, etc. (A FAZER)\n",
        "- Análise Estatística: Relatório de classificação e testes de significância estatística. (FEITO)\n",
        "- Aplicar o protocolo utilizado de comparação de classificadores de Janez Demsar.(FEITO)\n",
        "- Apresentar desempenhos de treinamento e teste para todos os modelos. (FEITO)\n",
        "- Análise de Custo-Benefício: Avaliar os recursos computacionais utilizados por cada modelo (tempo de processamento e memória) em relação ao desempenho alcançado. (FEITO)\n",
        "- Teste de Estresse dos Modelos: Realizar testes com dados novos e desconhecidos para avaliar a robustez dos modelos.\n",
        "- Métricas de Complexidade do Modelo: Avaliar a complexidade dos modelos, como número de parâmetros e tempo de inferência.\n",
        "- Explainable AI (XAI): Explicar as previsões de pelo menos dois dos modelos utilizando ferramentas de XAI, como SHAP ou LIME, para aumentar a compreensão sobre os fatores que influenciam as decisões dos modelos. Escolher o melhor modelo a partir da comparação estatística realizada para aplicar o XAI."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0c70u2REOBdF"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "wJD6QN8jntDk",
        "5lroaa666bSO",
        "RGeDInlGjm2L"
      ],
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
