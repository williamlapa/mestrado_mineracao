{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fr1v1FVY3fYe"
      },
      "source": [
        "## Importação e Preparação da base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "YXIEaYpQXcOL",
        "outputId": "b5d85659-3194-40ee-db60-515b4f4e2d1f"
      },
      "outputs": [],
      "source": [
        "# %%capture\n",
        "# !pip install scikit-optimize\n",
        "# !pip install openml\n",
        "# !pip install optuna\n",
        "# !pip install neupy\n",
        "# !pip install --upgrade neupy\n",
        "# !pip install --upgrade theano\n",
        "# !pip install imbalanced-learn\n",
        "# !pip install memory_profiler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ambiente local detectado.\n",
            "Instalando pacotes base...\n",
            "'numpy==1.24' já está instalado: versão 1.24.0\n",
            "Instalando 'numba==0.57.1'...\n",
            "Instalando outros pacotes...\n",
            "'scikit-optimize' já está instalado: versão 0.10.2\n",
            "'xgboost' já está instalado: versão 2.1.3\n",
            "'openml' já está instalado: versão 0.15.0\n",
            "'optuna' já está instalado: versão 4.1.0\n",
            "'imbalanced-learn' já está instalado: versão 0.12.4\n",
            "'openpyxl' já está instalado: versão 3.1.5\n",
            "'memory_profiler' já está instalado: versão 0.61.0\n",
            "'lightgbm' já está instalado: versão 4.5.0\n",
            "'GPUtil' já está instalado: versão 1.4.0\n",
            "'psutil' já está instalado: versão 6.1.0\n",
            "'seaborn' já está instalado: versão 0.13.2\n",
            "'shap' já está instalado: versão 0.46.0\n",
            "'lime' já está instalado: versão 0.2.0.1\n",
            "Atualizando 'neupy' e 'theano' no ambiente local...\n"
          ]
        }
      ],
      "source": [
        "# Verificação de pacotes\n",
        "import sys\n",
        "import subprocess\n",
        "import pkg_resources\n",
        "\n",
        "# Função para instalar pacotes, se necessário\n",
        "def install_package(package):\n",
        "    try:\n",
        "        # Verificar se o pacote já está instalado\n",
        "        dist = pkg_resources.get_distribution(package)\n",
        "        print(f\"'{package}' já está instalado: versão {dist.version}\")\n",
        "    except pkg_resources.DistributionNotFound:\n",
        "        # Instalar o pacote, se não estiver instalado\n",
        "        print(f\"Instalando '{package}'...\")\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
        "\n",
        "# Lista de pacotes necessários\n",
        "# Nota: NumPy é forçado para uma versão compatível antes de outras dependências\n",
        "base_packages = [\n",
        "    \"numpy==1.24\",\n",
        "    \"numba==0.57.1\"  # Forçar versão compatível com SHAP e Numba\n",
        "]\n",
        "other_packages = [\n",
        "    \"scikit-optimize\",\n",
        "    \"xgboost\",\n",
        "    \"openml\",\n",
        "    \"optuna\",\n",
        "    \"imbalanced-learn\",\n",
        "    \"openpyxl\",\n",
        "    \"memory_profiler\",\n",
        "    \"lightgbm\",\n",
        "    \"GPUtil\",\n",
        "    \"psutil\",\n",
        "    \"seaborn\",\n",
        "    \"shap\",\n",
        "    \"lime\",\n",
        "]\n",
        "\n",
        "# Verificar se está no Google Colab\n",
        "try:\n",
        "    import google.colab\n",
        "    is_colab = True\n",
        "    print(\"Detectado ambiente Google Colab.\")\n",
        "except ImportError:\n",
        "    is_colab = False\n",
        "    print(\"Ambiente local detectado.\")\n",
        "\n",
        "# Instalar pacotes de base primeiro (para evitar conflitos)\n",
        "print(\"Instalando pacotes base...\")\n",
        "for package in base_packages:\n",
        "    install_package(package)\n",
        "\n",
        "# Instalar outros pacotes\n",
        "print(\"Instalando outros pacotes...\")\n",
        "for package in other_packages:\n",
        "    if is_colab or package not in [\"neupy\", \"theano\"]:  # 'neupy' e 'theano' apenas em ambiente local\n",
        "        install_package(package)\n",
        "\n",
        "# Atualizar pacotes específicos\n",
        "if not is_colab:\n",
        "    print(\"Atualizando 'neupy' e 'theano' no ambiente local...\")\n",
        "    # Atualizar NeuPy\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--upgrade\", \"neupy\"])\n",
        "    # Atualizar Theano\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--upgrade\", \"theano\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLgev7DN7Fxj",
        "outputId": "8ea590a9-b498-4c23-a6a9-de54b6abb281"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "import pandas as pd\n",
        "from scipy.io import arff\n",
        "import openml\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "IVNblnZP60uV"
      },
      "outputs": [],
      "source": [
        "# Definir o ID do dataset no OpenML\n",
        "dataset_id = 722\n",
        "\n",
        "# Carregar o dataset diretamente do OpenML\n",
        "dataset = openml.datasets.get_dataset(dataset_id)\n",
        "data = dataset.get_data()[0]  # Pega o DataFrame completo\n",
        "\n",
        "# Remove colunas onde todos os valores são zero: [f10-f12] e [f34-f48]\n",
        "data = data.loc[:, (data != 0).any(axis=0)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_utNjnbIYd4",
        "outputId": "8efd3c8b-4ed8-4ea2-9ca4-e1a7ddce40f0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f13', 'f14',\n",
              "       'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24',\n",
              "       'f25', 'f26', 'f27', 'f28', 'f29', 'f30', 'f31', 'f32', 'f33',\n",
              "       'binaryClass'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "idmYjA7VORc2",
        "outputId": "50ef086b-05c0-42d4-b9e0-fdffa161398f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Número de features: 30\n"
          ]
        }
      ],
      "source": [
        "# prompt: quantidade de atributos\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming 'data' is your pandas DataFrame\n",
        "num_attributes = len(data.columns) - 1\n",
        "print(f\"Número de features: {num_attributes}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85poJhhVSYzF"
      },
      "source": [
        "## Utilizando ADASYN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "PDNh3_lUSb1E"
      },
      "outputs": [],
      "source": [
        "from sklearn.calibration import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.over_sampling import ADASYN\n",
        "import pandas as pd\n",
        "\n",
        "# Definir a variável alvo\n",
        "target_column = 'binaryClass'\n",
        "X = data.drop(columns=[target_column])\n",
        "y = data[target_column]\n",
        "\n",
        "# Supondo que y tenha as classes 'N' e 'P' como strings\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(y)  # Converte as classes para números (0 e 1)\n",
        "\n",
        "\n",
        "# Dividir os dados em treino e teste com estratificação\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "# Definir o StratifiedKFold com 10 folds para garantir a estratificação nas validações cruzadas\n",
        "stratified_kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# Identificar colunas numéricas e ajustar o tipo de dado para float64\n",
        "numeric_features = X_train.select_dtypes(include=['uint8']).columns\n",
        "X_train[numeric_features] = X_train[numeric_features].astype('float64')\n",
        "X_test[numeric_features] = X_test[numeric_features].astype('float64')\n",
        "\n",
        "# Substituir valores ausentes pela média em cada coluna numérica\n",
        "X_train[numeric_features] = X_train[numeric_features].fillna(X_train[numeric_features].mean())\n",
        "X_test[numeric_features] = X_test[numeric_features].fillna(X_train[numeric_features].mean())\n",
        "\n",
        "# Aplicar transformação (padronização) nas colunas numéricas\n",
        "scaler = StandardScaler()\n",
        "X_train[numeric_features] = scaler.fit_transform(X_train[numeric_features])\n",
        "X_test[numeric_features] = scaler.transform(X_test[numeric_features])\n",
        "\n",
        "# Aplicar ADASYN para balancear as classes no conjunto de treino\n",
        "adasyn = ADASYN(random_state=42)\n",
        "X_train_resampled, y_train_resampled = adasyn.fit_resample(X_train, y_train)\n",
        "\n",
        "# Agora X_train_resampled e y_train_resampled estão prontos para uso em modelos com 10-fold cross-validation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJD6QN8jntDk"
      },
      "source": [
        "## Comparativo ADASYN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1PBbW6Anwkk",
        "outputId": "5e533e41-da50-4ed8-ba0d-936b9527ae88"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA90AAAJOCAYAAACqS2TfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB8r0lEQVR4nOzdd3yN9///8efJTnASQhZBascsWlIzpEJDqdBStUdpqNFS+ilFB1VqlGq1IbTVVpc9a7bErj1qRCkSaiRoJSTX7w+/nK8jQ0hOEzzut9u5tee6Xud9va7LcY7nuZbJMAxDAAAAAAAgx9nldgMAAAAAADysCN0AAAAAANgIoRsAAAAAABshdAMAAAAAYCOEbgAAAAAAbITQDQAAAACAjRC6AQAAAACwEUI3AAAAAAA2QugGAAAAAMBGCN0A8ox169bJZDJp5MiRubL8kiVLqmTJklbTRo4cKZPJpHXr1tlsuQ0bNpTJZMrWGL/88ot8fX1VrFgxTZw4UadOnZLZbNaCBQtyqMt7ExUVJZPJpKioqFxZfnacOHFCJpNJXbp0ye1WgDzDZDKpYcOG/9ny+HsI4GFC6AaQo1L/oXT7w83NTX5+fmrcuLFGjBihY8eO2WTZORFeH1Rvv/22ihYtqtDQUA0fPlzFixeXj4+PQkJCcru1POHSpUt69913FRQUJE9PTzk6OqpIkSIKCQnRxx9/rKtXr+Z2i3let27dZDKZ5OnpqcTExBwbt0uXLjKZTDpx4kSOjZkXpP6IePsjf/788vf3V7NmzTR27FidOXMmt9uEpGvXrslsNstkMikiIiLDupz6fvvzzz9lb28vk8mkDz/8MNPaCxcuaOjQoapYsaLc3Nzk5uamEiVKqHHjxho1apTi4uIkSZMmTZLJZFLXrl0zHGvdunWys7PTE088oZs3b0qSZT0qVqyo5OTkNK+JjY39z39wAR5GDrndAICHU6lSpfTSSy9JkhITE3Xu3Dlt3bpV77zzjt5//30NGTJE7733nlVIfvLJJ3Xw4EEVLlw4V3pevXp1rix3zpw5+ueff7I1xmeffSZvb28VKVJEU6ZM0YkTJ1SqVCm5uLjkUJcPrtWrV+v555/XxYsXVaFCBbVt21aenp66cOGCNmzYoFdffVWTJk2y2Y9BD4MrV65o3rx5MplMunjxoubPn68XXnght9t6INSoUUPNmzeXJP3zzz+KjY3Vpk2btHz5co0aNUrjxo1Tv379crnLuzt48KDc3Nxyuw2bmDdvnq5cuSKTyaS5c+dqwoQJmX523s/32+1mzpyplJQUmUwmzZw5U4MHD0637q+//tJTTz2lU6dOqVq1auratas8PDx09uxZbdq0SSNHjlSdOnXk7e2t/v37a8GCBYqKilLr1q3VokULq7GuXr2qrl27ytnZWXPmzJGDg3UEOHDggKKiotS9e/d72XQAssoAgBwUExNjSDJCQ0PTnf/rr78aJUuWNCQZb731Vo4uu0GDBkZOf6y9/fbbhiRj7dq1OTruw27WrFmGJGPWrFm52seuXbsMV1dXw9XV1fjqq6/SrVm7dq1Ru3Zty/PU93Dnzp3/oy7zvs8//9yQZAwaNMiws7Mznn766Rwbu3PnzoYkIyYmJsfGzAvWrl1rSDJefvnldOfPnz/f8PT0NCQZkZGR/3F3ed9/+fewTp06hoODgzFgwABDkvH1119n2lN2vt+Sk5ON4sWLG4ULFza6dOliSDI2btyYbm23bt0MScbo0aPTnb9nzx7j5MmTlucnTpwwzGaz4e3tbfz9999Wtb169TIkGRMnTrSaLsnw8vIy8ufPbxQrVsz4999/reafPXvWkGQ0aNAg3R4AZA2HlwP4T9WtW1fLly+Xs7Ozxo0bp1OnTlnmZXRO95EjR9S1a1cFBATI2dlZhQoVUtWqVTVgwAAZhiHp1iFy69evt/x/6iP1fMDbzw88ePCgnnvuOXl6elod1preOd23i4yMVOXKleXi4qKiRYtq4MCBunLlilVNZuelZ3SOYmaHxS9YsEBNmjSRp6enXFxcVLJkSXXs2FH79u2z1Bw9elRvvPGGqlevbqkrW7ashg4dmuFh03/++ae6d++uokWLysnJScWKFVP37t118uTJDNc/PRcvXlTv3r3l7e0tNzc3PfHEE/r5558zrJ85c6ZatmypkiVLysXFRYUKFVJoaKjWrl2bbv2PP/6oBg0ayMvLSy4uLvLz81NISIh+/PHHLPX36quv6t9//9XHH3+sDh06pFvTsGHDLJ2zv2PHDvXt21eVKlWSu7u7XF1dVblyZY0dO1Y3btxIU5+V960knT17Vv3791eZMmXk6uoqDw8PVahQQb1791Z8fLzVmElJSfroo49UvXp15cuXTwUKFFC9evW0cOHCNMuPj4/XiBEjFBgYqPz588tsNqt06dLq3Lmz/vzzz7uu7+0iIyPl4OCgIUOGKDg4WKtXr85wjNS/R1evXlX//v3l5+cnZ2dnValSRT/88EOa2tmzZ0uSAgICLH9v7zyUNSYmRj169FDx4sXl7OwsX19fdenSJd0edu7cqTZt2lhqixQpoieeeELvvfdeltf3Xrbz/WrZsqVle7zxxhu6du2a1XzDMDRz5kzVqVNHZrNZbm5uqlmzpmbOnJlmrNuvPZGVz6lUixYtUnBwsOX9XLVqVX300UeWQ49vl96fS068x5KTk/XBBx+odOnScnFxUenSpTVmzBilpKRk+Jp9+/bp+eefl5eXl5ydnRUQEKABAwbowoULWVrm7Q4fPqyNGzeqadOmGjhwoEwmkyIjI+95HCnz77dUq1at0smTJ9WuXTvLXuWMlhcdHS1JGR4JUblyZfn7+1uelyhRQpMmTVJcXJz69Oljmb5ixQrNmDFDwcHB6t+/f5pxChYsqNdee01//fWXJk+enPUVBpB1uRz6ATxk7rYnIFXHjh0NScaUKVMs01L3DL399tuWaadPnzY8PDwMR0dHo1WrVsYbb7xh9O3b1wgNDTUcHR2NGzduGIZxa490iRIlLK9Pffz8889WfdWpU8cwm81GnTp1jEGDBhmdO3c2Tp8+bRiGYZQoUcIoUaKEVZ+pe7pbtGhhuLm5GV27djXeeOMNo0aNGoYko3bt2kZSUlKm63Dntrlzz01Ge+gHDRpkSDIKFSpkdOvWzRg6dKjRoUMHw8fHx2pvxYcffmh4eHgY4eHhxsCBA43+/fsbtWrVSrc/wzCMw4cPG0WKFLGs19ChQ43mzZsbkowiRYoYhw8fzuiPzcq1a9eMypUrG5KMoKAgS3+Ojo5GWFhYunu6XVxcjFq1ahndu3c3hg4danTs2NEoUKCAYWdnZ8yfP9+q9pNPPjEkGb6+vkavXr2MYcOGGV27djUqVqxodOjQ4a79HTlyxJBk+Pv7G8nJyVlaJ8PI+M/p5ZdfNvz8/Ix27doZgwcPNiIiIoyKFSsakozWrVtb1Wb1fXvt2jUjICDAMJlMRmhoqDF48GCjf//+xrPPPmu4ubkZR44csYx5/fp1o2HDhoYko1q1aka/fv2M3r17G/7+/oYk4+OPP7bUpqSkWN4DderUMQYOHGi89tprRps2bQwPDw9j1apVWd4e+/fvNyQZzzzzjGEYhjF79uwM3+OGcevvkZ+fnxEUFGSUL1/e6Nu3r9GtWzfDzc3NMJlMxooVKyy1EydONKpWrWpIMvr372/5e3v7+2bz5s2Gu7u74eDgYLRq1coYPHiw0bZtW8PBwcHw8vIyjh07Zqn9/fffDWdnZ8PNzc1o3769MXToUKN3795G/fr1jeLFi2dpfe9lO2fmbnu6U9WrV8+QZCxcuNAyLSUlxWjfvr0hyShTpozx8ssvG/369TPKly9vSDJee+01qzHu9XPKMAxjwoQJls+X3r17G6+99ppRpkwZQ5LRqlUrIyUlxaped+ztzKn3WOre3ICAAGPQoEHGK6+8YhQuXNjymXTn38Nff/3VcHNzMxwcHIx27doZQ4cOtXyGlipVyjh//nyWlptq8ODBhiRj3rx5hmEYRnBwsGEymYzjx4+nqc3O91uqtm3bGpKMrVu3GoZhGI899piRP39+48qVK2lq69ata0gytmzZck/r9OyzzxqSjLlz5xqXLl0yihUrZpjNZuPEiRNpaiUZ5cqVM65cuWJ4eXkZHh4exoULFyzz2dMN5AxCN4AcldV/lERGRhqSjI4dO1qmpRdYp0yZYkgyJk2alGaM2/9hYBiZH16e2pckY8SIEenWZBa6nZycjN27d1ump6SkGC+++KIhyRg/fnym63BnD1kJ3YsWLTIkGZUrV05zmOCNGzeM2NhYy/PTp08b169fT7O8UaNGGZLSHFYdHBxsSDI+++wzq+nTpk0zJBmNGjVKM1Z6UrdNz549raYvX77csq3vDN3p/UP2zJkzhp+fn1GmTBmr6dWrVzecnJyMuLi4NK+5c5ukJyoqypBkvPTSS1lYm/+T0Z/Tn3/+ady8edNqWkpKiiU0/Pbbb5bpWX3fLly40JBkDBgwIE3dlStXrP5c33zzTUOSMXz4cKtAlJCQYNSsWdNwcnKy/IC0Z88eS3i60/Xr19P9B35GUn/8+eabbyx95cuXzyhevHi6P2ak/vjVsmVLIzEx0TL9l19+SfezIbPDy5OSkoySJUsaBQoUMHbu3Gk179dffzXs7e2N5s2bp+n1zh9wDCNr7xnDuLftnJmshu7hw4dblpdqxowZhiSja9euVmE5MTHRaNGihSHJ2L59u2X6vX5OHT161PKjxe2HJ1+/ft0S9ObMmWPV553BKyfeY6nbqGrVqsbVq1ct0//66y+jcOHCaf4eJicnG6VKlTIkGcuXL7caKzU8d+vW7a7LTXXjxg3D29vb8PDwsBxWPXPmzAwPD8/O95th3HoPOjk5GeXLl7dMGzFihCHJ+OKLL9KMk/o54uXlZYwYMcJYu3atER8ff9f1io2NNQoXLmwULFjQaNmypSHJmDlzZrq1qaHbMAxj6tSpaX7UIXQDOYPDywHkCj8/P0nS33//naV6V1fXNNMKFSp0z8v18fHR//73v3t+XadOnVSlShXLc5PJpPfff1/29vY2uS3WJ598IkmaPHmyPD09reY5ODjI29vb8jz18N079e3bV9Kt24mlOnnypNauXavAwED17NnTqr53794qX7681qxZk+5hkXeaM2eOnJycNHr0aKvpoaGhaty4cbqvCQgISDPN19dX4eHhOnLkSJpDUh0dHeXo6JjmNXduk/TExsZKkooVK3bX2qwoXry47O3trabdfrXj27dzqqy+b9Ory58/v+XPNSUlRdOnT1epUqU0atQoq9MRChQooBEjRigpKUk//fTTXcd1dnZW/vz501vFNG7cuKEvv/xSZrNZrVq1svT13HPP6eTJk+muc6qJEyfKycnJ8rxx48YqUaKEtm3blqVlS9LixYt14sQJDR48WI8//rjVvLp166ply5ZaunSpEhISrOalt95Zec/c73bOjvQ+C6dOnap8+fJp2rRpVu9/Jycny2Hy33zzTZqxsvo5NXfuXN28eVOvvfaa1eHJzs7O+uCDDyQpy59r2XmPzZkzR5I0YsQI5cuXzzK9aNGi6R4GvXHjRh07dkzNmjVTaGio1bwRI0aoUKFCmjt3rpKSkrLU++LFixUXF6e2bdtaLpzWpk0bubm5KSoqKtND3DOT0ffbl19+qaSkJHXs2NEyrVOnTpLSP8S8b9++Gjx4sC5fvqzRo0crODhYHh4eqlixooYOHaqzZ8+mu3xvb2999tlnunTpkhYsWKBnn30206uap+rVq5dKly6tadOmZek7AEDWcfVyAHlaixYtNGzYMEVERGj16tVq2rSpGjRooMcee+y+xqtatapVEMiqevXqpZlWokQJ+fv7a//+/UpKSrqvcTOydetWOTs7q0GDBnetNQxDs2bNUlRUlPbt26f4+HirfyzefluiXbt2SZIaNGiQ5jxyOzs71a9fX4cOHdKuXbus/jF+p4SEBMXExCgwMFA+Pj5p5terVy/dq8EfP35cY8aM0Zo1a3T69Ok0t546c+aMSpQoIUlq166dhgwZokqVKunFF19UcHCw6tatK7PZfNdtYgtJSUmaOnWqvv32Wx06dEhXr161Ojf79u2c1fdt/fr15evrq7Fjx2r37t1q3ry5GjRooAoVKlj9+Rw+fFiXLl2Sn5+fRo0alaa38+fPS5IOHTokSapQoYKqVKmib775Rn/99ZdatWqlhg0bqlq1arKzy/rv7QsWLND58+fVvXt3q6s5d+rUSV999ZUiIyPVpEmTNK/z8PBI9weWYsWKWc5TzYrNmzdLurX+6V0nITY2VikpKfrjjz9Us2ZNPf/885o0aZKee+45vfDCC3r66adVv359FS1aNEvLu9ftbAv//POP9u7dKz8/P0sAvl3q9QPS6yGrn1O///67JKV7G6igoCC5uLhYPisykhPvsd27d2fYd3rTMus7f/78qlmzplauXKnDhw+rcuXKd13+F198Ien/gq9068eVVq1aae7cuVqxYoWaNWuWpXXJisjISJlMJsuVz6VbV0J/6qmntGnTJh08eFAVKlSwzDOZTBo3bpyGDBmipUuXavPmzdq+fbt27NihAwcO6LPPPtPy5ctVq1atNMtq3bq1nnzySW3dulVjx47NUn+Ojo5699131a5dOw0fPtwmPygDjypCN4BckRpQihQpkmldyZIltXnzZo0cOVJLly7VvHnzJEnly5fX6NGj1bZt23ta7u17iHPidd7e3jpx4oSuXLmSpT1pWRUfH6+iRYtm6R+vr776qqZOnSp/f389++yz8vX1tewhHTVqlFWwTd0jmNH6+Pr6WtVlJHW+l5dXuvPTG//o0aN68sknlZCQoODgYLVo0UJms1l2dnZat26d1q9fb9Xr66+/Lk9PT02fPl0TJkzQ+PHj5eDgoLCwME2cODHdUHe71B8DTp8+nWldVrVp00aLFi1S2bJl9cILL8jLy0uOjo66fPmyJk+ebNV7Vt+37u7u2rx5s0aMGKFFixZp6dKlkiR/f38NHTpUr7zyiqRbF6yTpP3792v//v0Z9ph6MS4HBwetWbNGI0eO1I8//qjXXntN0q2/b3379tX//ve/NHvt05O69+32UCLd2mtdtGhRLViwQBcvXkyz997d3T3d8RwcHO5p72Hqen/99deZ1qWud61atbRu3Tq9//77mjt3rmbNmiVJeuKJJ/TBBx8oODg4S8vL6nbOCXd+Fl66dEmGYej06dPpBv/Mesjq51RmnwMmk0ne3t53/XuTE++x+Ph42dnZpXubyPR6y6nPL+nWdl++fLkee+wx1a1b12pep06dNHfuXM2cOfO+Qnd6329btmzRvn37FBwcrOLFi6dZ3qZNmzRz5sx079tduHBhderUyfL3MDY2Vn379tWPP/6oXr16WX68uFPqUQjpHY2Qkeeff17jx4/Xl19+qddee+2u39EAsobDywHkitSrRT/xxBN3ra1UqZJ++OEHXbx4UdHR0RoxYoRiY2P1wgsvaOPGjfe03IyuEn43cXFxGU43mUwqUKCAJFlCcnpX/73zStSZ8fDwsOzFy8y5c+c0bdo0ValSRYcOHVJUVJTGjBmjkSNHqnfv3mnqU/cSZ7Q+qYdk321vcur8c+fOpTs/vfEnTpyoS5cuKSoqSqtWrdKkSZM0evRojRw5UuXLl09TbzKZ1K1bN23btk3nz5/Xzz//rNatW2vBggVq3ry5kpOTM+2xTp06km691+73MNFU27Zt06JFixQaGqoDBw7o888/13vvvaeRI0eqXbt26b4mq+/b4sWLKyoqSufPn9fvv/+uDz74QCkpKYqIiLAcQpy6vcPDw2Xcuh5Luo/UkCndOpz6448/1unTp3XgwAFNnTpVhQoV0ttvv61x48bddZ1PnTqllStXSvq/IyNSH/b29pYjFb766qv73q53k7reixYtynS9bz8ipF69elq2bJkuXbqktWvXatCgQdq7d6/CwsJ0/PjxLC3vXrZzdt35WZjaQ40aNTLtIb0r/mf1cyqzzwHDMBQXF5elI0qy+x5zd3dXSkpKuqcZpddbTn1+SbcOn09OTtbx48et3tsmk0lNmzaVJC1cuDDLp0DdLr3vt9QfsNauXZtmeamf1XPmzEn3Tgh38vHx0ZdffilnZ2ft2bPnvq7anhGTyWT5DBo6dGiOjQs86gjdAP5zf/zxh+bNmydnZ2c999xzWX6do6OjateurVGjRmnKlCkyDEOLFy+2zE/dq3K3MHY/fv311zTT/vzzT506dUoVK1a0HFpesGBBSenvXU09NDIrnnzySSUmJlpug5aR48ePyzAMhYSEyM3N7a49V6tWTZK0YcMGq0OjpVv/2N6wYYNVXUbMZrMCAgJ09OhRyz9077bsY8eOSbp1q6Q7l3u3H088PT3VqlUrfffdd2rUqJEOHDigo0ePZvqa0qVLq379+jp16pTltlQZufMw94x6DwsLS7P3Lr11vd3d3rep7OzsVK1aNQ0ZMsQStlNvUVWhQgWZzWZt3749S/8ov53JZFKFChUUERGhVatWWY2bmdRzWuvWravu3buneXTu3FlSxrc7yqrM/t6mHjZ7L4ekp3J1dVXDhg01YcIEvfnmm/r3338t65+R7Gzn+7F+/Xr9+uuv8vLyUqNGjSTdOry5QoUKOnjwoC5fvnxP42X1cyr1/Pj0bpW3ZcsWXb9+/a6fAbe73/dY1apVM+w7vWmZ9X3t2jVt375drq6uKleuXKbLNf7/7dgkqUuXLum+v5966iklJSXpyy+/vOt63C6977dr167p22+/lZubW7rL6t69u6pUqaJz586l+9mQHmdn53Svd5ETGjVqpNDQUC1dutTynQAgewjdAP5TGzduVGhoqBITEzV06NC7nmu5Y8eOdA8VTN3Tcft5pqmHuNriAjBz5szRnj17LM8Nw9Cbb76p5ORkq/tulytXTgUKFNDChQsth6qm9vvuu+9meXmpF+fq37+/1TjSrb3oqeufev7zpk2brPbm/vXXXxo2bFiacYsXL67g4GDt378/zf1+Z8yYoYMHD6pRo0aZns+dqmPHjkpKStKIESOspq9cuTLd87lTe/3tt9+spo8dO9bqvuOp1q1bl+aHgRs3bli2x+1/9hmZPHmyXF1d1bdvX3333Xfp1vz666+WwJORjHrfv3+/xowZk6Y+q+/b/fv3p7vX7s46BwcH9enTR3/++adef/31dAPhvn37LEcenDhxwnL/+czGzUjq3lyTyaTZs2friy++SPOIiopSUFCQ9uzZo+3bt2c6XmYy+3vbsmVLFS9eXB999FG6//i/ceOG1Z9JdHS0rl+/nqYuq+t9r9s5OxYtWqTw8HBJ0gcffGD1o9mrr76qf/75Rz179kz3MPKYmJh0/3yz+jn14osvysHBQR999JHVtQiSkpL0xhtvSJJVfXqy+x6TZLmg2OjRo63W8/Tp0+neL7pOnToqVaqUli1bluYifu+++64uXLig9u3b3/X6GuvXr9exY8dUv359zZo1K933d+rn4738qJTR99v333+vK1euqE2bNuku64svvrAcVn778iZMmJDh9QOmTp2qq1evqnz58jl6alOqsWPHymQy6c0338zxsYFHEed0A7CJo0ePWi58lJSUpHPnzmnr1q3au3ev7O3t9dZbb+ntt9++6zhffvmlPvvsM9WvX1+lSpWS2WzWgQMHtHTpUhUqVMjqiqyNGjXSDz/8oPDwcDVr1kwuLi6qWrWqWrRoke31CQ0NVVBQkNq1a6ciRYpo9erV2r59u2rXrq1+/fpZ6pycnNSvXz+9//77ql69ulq2bKkrV65o0aJFatCggWWP6d0888wzev311zV+/HiVKVNGzz33nLy8vHT69GmtXr1ar7/+ugYMGGC58vePP/6omjVrqnHjxoqLi9PixYvVuHHjdJc3ffp01a1bVz179tSiRYsUGBio/fv3a+HChSpSpIimT5+epR6HDBmin376SZ9//rn2799v2as8b948hYWFacmSJVb1vXv31qxZsxQeHq7nn39enp6e2rx5s3bu3JlufatWrWQ2m1W7dm2VKFFCN27c0KpVq3TgwAG1adPGEoQzU61aNS1atEjPP/+82rVrp9GjR6t+/foqVKiQLl68qI0bN2rv3r0qXbp0puM8+eSTevLJJzVv3jydPXtWtWvX1smTJ7Vw4UKFhYXphx9+sKrP6vt21apVGjx4sOrUqaOyZcvK09NTx48f18KFC+Xi4mL58UW6dX7+zp07NWXKFC1ZskT169e3vCf27t2r3bt3Kzo6Wl5eXtq1a5flQkqpF7s7ffq05s+fLzs7Ow0cODDT9V2zZo1iYmLuetHCrl27Kjo6WpGRkapZs+bd/jjS1ahRI40fP169evVSeHi48uXLpxIlSqhjx45ydnbWDz/8oGbNmqlBgwZq1KiRKleuLJPJpD///FO//vqrPD09LcHkgw8+0Nq1a1W/fn0FBATIxcVFO3fu1OrVq/XYY49l6ciae9nOWbF9+3bLZ+H169d19uxZbdq0SUePHpWrq6umTZuWJuC+/PLL2rx5s2bPnq2NGzcqJCREfn5+iouL06FDh7RlyxbNnTtXJUuWtHpdVj+nSpUqpQ8++ECvvfaaqlSpoueff1758uXTokWLdPjwYbVs2dLqYl/pye57TJKCg4PVtWtXzZo1S5UrV9Zzzz2nxMREfffdd6pdu3aavb52dnaKiopSaGionnnmGbVt21YlSpRQdHS01q1bp1KlSmXpomGpwTazK3qXK1fOcoGzLVu2WF2s7F6/37KyvJCQEBUrVkzLly/XmTNn5Ofnpy+//FKvv/66KleurFq1asnLy0uXL1+2fG66urpm+fP6XlWrVk0vvvjiXa+nACCLbHQrMgCPqNvvh536cHV1NXx9fY3g4GBj+PDhxtGjR9N9bXr3uN68ebPx8ssvG5UqVTI8PDwMV1dXo0yZMkbfvn2NP//80+r1N27cMIYMGWIUL17ccHBwsLrHa0b3Xr5dZvfpXrt2rfH5558bFStWNJydnQ1fX1+jf//+RkJCQppxkpOTjZEjRxr+/v6Gk5OTUbZsWWPy5MnG8ePHs3yf7lQ//vijERwcbDg5ORmSDH9/f6Njx47Gvn37LDVXrlwxXnvtNaNkyZKGs7OzUaZMGeOdd94xkpKSMry/6okTJ4yuXbsavr6+hoODg+Hr62t07drVOHHiRIbbJz0XLlwwevXqZRQpUsRwcXExatSoYfz000/GrFmz0r1P99q1a406deoYBQoUMDw8PIxnnnnG2LFjh9V2TvXJJ58Yzz77rFGiRAnDxcXF8PT0NJ588klj+vTpVvcuzmqf77zzjlG7dm2jYMGChoODg+Hp6Wk0bNjQmDJlitU9gjN6r5w7d87o1q2b4efnZ7i4uBiVK1c2pk2blu6fa1bftwcOHDD69+9vPP7444anp6fh7OxsPPbYY0bnzp2N/fv3p1mPmzdvGp999plRp04dw2w2G87Ozkbx4sWNpk2bGtOnT7esx6lTp4yhQ4catWvXNry8vAwnJyejePHiRuvWrY3o6Oi7bq/27dun++d3p/j4eMPV1dVwd3c3/vnnH8Mw0v97lCqj9/q4ceOMMmXKGI6Ojum+Z//66y+jf//+RpkyZQxnZ2fDbDYbFSpUMHr06GGsXr3aUrd8+XKjU6dORrly5YwCBQoY+fPnNwIDA40333zTOH/+/F3XO1VWt3NmUj/Pbn+4ubkZxYoVM0JDQ42xY8caZ86cyXSM7777zggJCTEKFixoODo6GkWLFjUaNmxoTJgwwWp97udzyjAMY8GCBUaDBg2MAgUKGM7OzkblypWNCRMmGDdu3EhTe+efS3bfY6lu3rxpjBkzxnjssccMJycn47HHHjPef/994+jRoxl+Zu/Zs8do06aNUbhwYcPR0dEoUaKE0b9//yz9GV++fNlwdXU18uXLd9d7iX/++eeGJKNnz56GYdzf99uhQ4cMSUZAQIDVfd/T87///c+QZLz33nuGYRjGzp07jVGjRhkNGjSwfJ+4uroa5cuXN/r06WP88ccfmY6X+vctJiYmwxrddp/uO8XExFi+e7hPN5A9JsO449g9AECe1LBhQz3zzDMaMmRIbrcCIA8ZOXKkRo0apbVr16Z7Oy0AQO7inG4AeEC0bt063fMcAQAAkHdxTjcA5HHdunWTj4+P5s2bp6SkpNxuBwAAAPeA0A0Aedy+ffv09ddfq0iRIpo0aVJutwMAAIB7wDndAAAAAADYCOd0AwAAAABgI4RuAAAAAABshHO671NKSorOnDmjAgUKyGQy5XY7AAAAAID/kGEYunLlivz8/GRnl/H+bEL3fTpz5oz8/f1zuw0AAAAAQC46deqUihUrluF8Qvd9KlCggKRbG9hsNudyNwAAAACA/1JCQoL8/f0t2TAjhO77lHpIudlsJnQDAAAAwCPqbqcbcyE1AAAAAABshNANAAAAAICNELoBAAAAALARzum2seTkZN24cSO32wDum6Ojo+zt7XO7DQAAAOCBROi2EcMwFBsbq8uXL+d2K0C2eXh4yMfHh3vSAwAAAPeI0G0jqYHby8tLbm5uhBU8kAzD0D///KNz585Jknx9fXO5IwAAAODBQui2geTkZEvg9vT0zO12gGxxdXWVJJ07d05eXl4cag4AAADcAy6kZgOp53C7ubnlcidAzkh9L3N9AgAAAODeELptiEPK8bDgvQwAAADcH0I3AAAAAAA2QujGA6dLly5q1apVbrcBAAAAAHdF6EaOio2NVb9+/fTYY4/J2dlZ/v7+atGihVavXp1jy5g8ebKioqJybDxJWrdunUwmE7d4AwAAAJCjuHo5csyJEydUp04deXh46MMPP1TlypV148YNrVixQhERETp06FCOLMfd3T1HxgEAAAAAW2NPN3LMK6+8IpPJpK1btyo8PFxly5ZVxYoVNWjQIG3evFmSdPLkSbVs2VL58+eX2WzW888/r7i4OMsYI0eOVLVq1fTll1+qZMmScnd3V7t27XTlyhVLzZ2Hl5csWVKTJk2y6qVatWoaOXKk5bnJZNIXX3yh5557Tm5ubipTpowWLlwo6daPBcHBwZKkggULymQyqUuXLpKkxMREvfrqq/Ly8pKLi4vq1q2rbdu25eBWAwAAAPAwI3QjR1y8eFHLly9XRESE8uXLl2a+h4eHUlJS1LJlS128eFHr16/XqlWrdPz4cb3wwgtWtceOHdP8+fO1ePFiLV68WOvXr9fYsWOz3eOoUaP0/PPPa8+ePXrmmWfUoUMHXbx4Uf7+/vrxxx8lSYcPH9bZs2c1efJkSdKQIUP0448/avbs2dq5c6dKly6t0NBQXbx4Mdv9AAAAAHj45anQnZycrOHDhysgIECurq4qVaqU3nnnHRmGYakxDEMjRoyQr6+vXF1dFRISoiNHjliNc/HiRXXo0EFms1keHh7q3r27rl69alWzZ88e1atXTy4uLvL399e4ceP+k3V8WB09elSGYah8+fIZ1qxevVp79+7V3LlzVaNGDdWqVUtz5szR+vXrrfYep6SkKCoqSpUqVVK9evXUsWPHHDknvEuXLmrfvr1Kly6t999/X1evXtXWrVtlb2+vQoUKSZK8vLzk4+Mjd3d3Xbt2TdOnT9eHH36oZs2aKTAwUJ9//rlcXV0VGRmZ7X4AAAAAPPzyVOj+4IMPNH36dE2dOlUHDx7UBx98oHHjxunjjz+21IwbN05TpkzRp59+qi1btihfvnwKDQ3V9evXLTUdOnTQ/v37tWrVKi1evFgbNmxQr169LPMTEhLUpEkTlShRQjt27NCHH36okSNHasaMGf/p+j5Mbv9hJCMHDx6Uv7+//P39LdMCAwPl4eGhgwcPWqaVLFlSBQoUsDz39fXVuXPnst1jlSpVLP+fL18+mc3mTMc9duyYbty4oTp16limOTo66sknn7TqFwAAAAAykqcupLZp0ya1bNlSYWFhkm6Fr2+++UZbt26VdCvYTZo0SW+99ZZatmwpSZozZ468vb01f/58tWvXTgcPHtTy5cu1bds21axZU5L08ccf65lnntH48ePl5+enr7/+WklJSZo5c6acnJxUsWJF7dq1Sx999JFVOEfWlSlTRiaTKUculubo6Gj13GQyKSUlJcN6Ozu7NKH/xo0b2R4XAAAAALIrT+3pfuqpp7R69Wr98ccfkqTdu3frt99+U7NmzSRJMTExio2NVUhIiOU17u7uqlWrlqKjoyVJ0dHR8vDwsARuSQoJCZGdnZ22bNliqalfv76cnJwsNaGhoTp8+LAuXbqUbm+JiYlKSEiweuD/FCpUSKGhoZo2bZquXbuWZv7ly5dVoUIFnTp1SqdOnbJMP3DggC5fvqzAwMD7XnaRIkV09uxZy/OEhATFxMTc0xip74Xk5GTLtFKlSsnJyUkbN260TLtx44a2bduWrX4BAAAAPDryVOgeOnSo2rVrp/Lly8vR0VGPP/64BgwYoA4dOki6dQ9oSfL29rZ6nbe3t2VebGysvLy8rOY7ODioUKFCVjXpjXH7Mu40ZswYubu7Wx63HyKNW6ZNm6bk5GQ9+eST+vHHH3XkyBEdPHhQU6ZMUVBQkEJCQlS5cmV16NBBO3fu1NatW9WpUyc1aNDA6keSe9WoUSN9+eWX+vXXX7V371517txZ9vb29zRGiRIlZDKZtHjxYp0/f15Xr15Vvnz51KdPHw0ePFjLly/XgQMH1LNnT/3zzz/q3r37ffcLAAAA4NGRp0L3vHnz9PXXX2vu3LnauXOnZs+erfHjx2v27Nm53ZqGDRum+Ph4y+P2vbW45bHHHtPOnTsVHBys1157TZUqVdLTTz+t1atXa/r06TKZTFqwYIEKFiyo+vXrKyQkRI899pi+++67bC132LBhatCggZo3b66wsDC1atVKpUqVuqcxihYtqlGjRmno0KHy9vZW3759JUljx45VeHi4OnbsqOrVq+vo0aNasWKFChYsmK2eAQAAADwaTEZWroD1H/H399fQoUMVERFhmfbuu+/qq6++0qFDh3T8+HGVKlVKv//+u6pVq2apadCggapVq6bJkydr5syZeu2116wOE79586ZcXFz0/fff67nnnlOnTp2UkJCg+fPnW2rWrl2rRo0a6eLFi1kKVAkJCXJ3d1d8fLzMZrPVvOvXrysmJkYBAQFycXG5/w2CdLVv31729vb66quvcruVRwbvaQAPk3ovv5PbLQA5xjX4n9xuAcgxK9uNye0W7klmmfB2eWpP9z///CM7O+uW7O3tLRe7CggIkI+Pj9XtoxISErRlyxYFBQVJkoKCgnT58mXt2LHDUrNmzRqlpKSoVq1alpoNGzZYXWxr1apVKleuHHsw87CbN2/qwIEDio6OVsWKFXO7HQAAAAC4qzwVulu0aKH33ntPS5Ys0YkTJ/Tzzz/ro48+0nPPPSfp1tWmBwwYoHfffVcLFy7U3r171alTJ/n5+alVq1aSpAoVKqhp06bq2bOntm7dqo0bN6pv375q166d/Pz8JEkvvviinJyc1L17d+3fv1/fffedJk+erEGDBuXWqiML9u3bp5o1a6pixYrq3bt3brcDAAAAAHeVp24Z9vHHH2v48OF65ZVXdO7cOfn5+enll1/WiBEjLDVDhgzRtWvX1KtXL12+fFl169bV8uXLrQ55/frrr9W3b181btxYdnZ2Cg8P15QpUyzz3d3dtXLlSkVERKhGjRoqXLiwRowYwe3C8rhq1arpn384hAoAAADAgyNPndP9IOGcbjxKeE8DeJhwTjceJpzTjYcJ53QDAAAAAIB7QugGAAAAAMBGCN0AAAAAANgIoRsAAAAAABvJU1cvB4B70eTbYbndApBjHrSLxwAAgKxhTzceKiaTSfPnz8/tNgAAAABAEnu6/1P/9S1Kfv1s+H29Ljo6WnXr1lXTpk21ZMmSe379yJEjNX/+fO3ateu+lp9XhIaG6pdfftHmzZv1xBNPWM3r0qWLZs+eLUlycHBQoUKFVKVKFbVv315dunSRnV3a37MyG+/8+fMaMWKElixZori4OBUsWFBVq1bViBEjVK5cOVWqVEmvvvqq3nzzTavXPf/88zp58qQ2btyod955R6NGjdLLL7+sTz/91FKza9cuPf7444qJiVHJkiVzaOsAAAAAyAr2dCONyMhI9evXTxs2bNCZM2dyu51ccfLkSW3atEl9+/bVzJkz061p2rSpzp49qxMnTmjZsmUKDg5W//791bx5c928efOexgsPD9fvv/+u2bNn648//tDChQvVsGFDXbhwQYULF9aMGTM0atQo7d271/Ka77//XosXL9bs2bNlb28vSXJxcVFkZKSOHDmSg1sDAAAAwP0idMPK1atX9d1336lPnz4KCwtTVFSU1fx169bJZDJp9erVqlmzptzc3PTUU0/p8OHDkqSoqCiNGjVKu3fvlslkkslksoxx+fJl9ejRQ0WKFJHZbFajRo20e/duy9i7d+9WcHCwChQoILPZrBo1amj79u0Z9nrkyBHVr19fLi4uCgwM1KpVq9LU7N27V40aNZKrq6s8PT3Vq1cvXb169a7bYdasWWrevLn69Omjb775Rv/++2+aGmdnZ/n4+Kho0aKqXr263nzzTS1YsEDLli1Ls90yG+/y5cv69ddf9cEHHyg4OFglSpTQk08+qWHDhunZZ5+VJD377LN68cUX1blzZ924cUPnz59XRESExo4dq3LlylnGKleunIKDg/W///3vrusIAAAAwPYI3bAyb948lS9fXuXKldNLL72kmTNnyjCMNHX/+9//NGHCBG3fvl0ODg7q1q2bJOmFF17Qa6+9pooVK+rs2bM6e/asXnjhBUlS27Ztde7cOS1btkw7duxQ9erV1bhxY128eFGS1KFDBxUrVkzbtm3Tjh07NHToUDk6OqbbZ0pKilq3bi0nJydt2bJFn376qd544w2rmmvXrik0NFQFCxbUtm3b9P333+uXX35R3759M90GhmFo1qxZeumll1S+fHmVLl1aP/zwQ5a2X6NGjVS1alX99NNPWR4vf/78yp8/v+bPn6/ExMQMx548ebIuXLigd955R6+88ooqVaqkfv36pakbO3asfvzxx0x/sAAAAADw3yB0w0pkZKReeuklSbcOn46Pj9f69evT1L333ntq0KCBAgMDNXToUG3atEnXr1+Xq6ur8ufPLwcHB/n4+MjHx0eurq767bfftHXrVn3//feqWbOmypQpo/Hjx8vDw8MSQE+ePKmQkBCVL19eZcqUUdu2bVW1atV0+/zll1906NAhzZkzR1WrVlX9+vX1/vvvW9XMnTtX169f15w5c1SpUiU1atRIU6dO1Zdffqm4uLgMt8Evv/yif/75R6GhoZKkl156SZGRkVnehuXLl9eJEyeyPJ6Dg4OioqI0e/ZseXh4qE6dOnrzzTe1Z88eq3HNZrNmzZql999/XytXrtSsWbNkMpnSLL969ep6/vnn0/wIAQAAAOC/R+iGxeHDh7V161a1b99e0q0w+MILL6QbOKtUqWL5f19fX0nSuXPnMhx79+7dunr1qjw9PS17dvPnz6+YmBgdO3ZMkjRo0CD16NFDISEhGjt2rGV6eg4ePCh/f3/5+flZpgUFBaWpqVq1qvLly2eZVqdOHaWkpFgOh0/PzJkz9cILL8jB4dZ1Btu3b6+NGzdm2s/tDMOwCsNZGS88PFxnzpzRwoUL1bRpU61bt07Vq1dPc5h6o0aNVLt2bXXs2FElSpTIsId3331Xv/76q1auXJmlngEAAADYBqEbFpGRkbp586b8/Pzk4OAgBwcHTZ8+XT/++KPi4+Otam8/7Ds1YKakpGQ49tWrV+Xr66tdu3ZZPQ4fPqzBgwdLunXV8/379yssLExr1qxRYGCgfv75ZxusacYuXryon3/+WZ988ollGxQtWlQ3b97M8IJqdzp48KACAgLueTwXFxc9/fTTGj58uDZt2qQuXbro7bffTjN+6jiZKVWqlHr27KmhQ4eme3oAAAAAgP8GoRuSpJs3b2rOnDmaMGGCVSjevXu3/Pz89M0332R5LCcnJyUnJ1tNq169umJjY+Xg4KDSpUtbPQoXLmypK1u2rAYOHKiVK1eqdevWmjVrVrrLqFChgk6dOqWzZ89apm3evDlNze7du3Xt2jXLtI0bN8rOzs7q4mO3+/rrr1WsWDHt3r3bajtMmDBBUVFRadbrTmvWrNHevXsVHh6e7fECAwOter9XI0aM0B9//KFvv/32vscAAAAAkD2EbkiSFi9erEuXLql79+6qVKmS1SM8PPyezmkuWbKkYmJitGvXLv39999KTExUSEiIgoKC1KpVK61cuVInTpzQpk2b9L///U/bt2/Xv//+q759+2rdunX6888/tXHjRm3btk0VKlRIdxkhISEqW7asOnfurN27d+vXX39Nc8XuDh06yMXFRZ07d9a+ffu0du1a9evXTx07dpS3t3e640ZGRqpNmzZptkH37t31999/a/ny5ZbaxMRExcbG6vTp09q5c6fef/99tWzZUs2bN1enTp2yPN6FCxfUqFEjffXVV9qzZ49iYmL0/fffa9y4cWrZsmWWt/udvL29NWjQIE2ZMuW+xwAAAACQPYRuSLoVDkNCQuTu7p5mXnh4uLZv357mwl4ZCQ8PV9OmTRUcHKwiRYrom2++kclk0tKlS1W/fn117dpVZcuWVbt27fTnn3/K29tb9vb2unDhgjp16qSyZcvq+eefV7NmzTRq1Kh0l2FnZ6eff/5Z//77r5588kn16NFD7733nlWNm5ubVqxYoYsXL+qJJ55QmzZt1LhxY02dOjXdMXfs2KHdu3db9lLfzt3dXY0bN7b68WH58uXy9fVVyZIl1bRpU61du1ZTpkzRggULZG9vn+Xx8ufPr1q1amnixImqX7++KlWqpOHDh6tnz54Z9ppVr7/+uvLnz5+tMQAAAADcP5PBCZ/3JSEhQe7u7oqPj5fZbLaad/36dcXExCggIEAuLi651CGQc/Lqe7rJt8NyuwUgx6xsNya3W3hk1Hv5ndxuAcgxrsH/5HYLQI550L4LM8uEt2NPNwAAAAAANkLoBgAAAADARgjdAAAAAADYCKEbAAAAAAAbIXQDAAAAAGAjhG4AAAAAAGyE0A0AAAAAgI0QugEAAAAAsBFCNwAAAAAANkLoRp514sQJmUwm7dq1K8fGbNiwoQYMGJBj4wEAAABAZhxyu4FHSZNvh/2ny1vZbsw91Xfp0kWzZ8+WJDk4OKhQoUKqUqWK2rdvry5dusjO7r/9jcbf319nz55V4cKF/9PlZtWYMWP01ltvaezYsRo8eLDVvKioKHXt2lWSZGdnJ7PZrLJlyyosLEz9+/eXu7v7PY2XnJysDz/8UFFRUfrzzz/l6uqqMmXKqGfPnurevbuefvpp2dvba8WKFVav++STT/Tmm29q3759Onr0qIKDgxUYGKg9e/bI3t7eUufh4aFJkyapS5cuObR1AAAAAEjs6cYdmjZtqrNnz+rEiRNatmyZgoOD1b9/fzVv3lw3b978T3uxt7eXj4+PHBzy5m9DM2fO1JAhQzRz5sx055vNZp09e1Z//fWXNm3apF69emnOnDmqVq2azpw5c0/jjRo1ShMnTtQ777yjAwcOaO3aterVq5cuX74sk8mkWbNmacuWLfrss88sr4mJidGQIUP08ccfq1ixYpbpx48f15w5c3JgCwAAAAC4G0I3rDg7O8vHx0dFixZV9erV9eabb2rBggVatmyZoqKiLHWXL19Wjx49VKRIEZnNZjVq1Ei7d++2zB85cqSqVaumzz77TP7+/nJzc9Pzzz+v+Ph4S01KSopGjx6tYsWKydnZWdWqVdPy5cst8+88vPzSpUvq0KGDihQpYtnTO2vWrAzX5dq1a+rUqZPy588vX19fTZgwIU3NpUuX1KlTJxUsWFBubm5q1qyZjhw5ctfttH79ev37778aPXq0EhIStGnTpjQ1JpNJPj4+8vX1VYUKFdS9e3dt2rRJV69e1ZAhQ+5pvIULF+qVV15R27ZtFRAQoKpVq6p79+56/fXXJd06KmDy5Ml6/fXXFRMTI8Mw1L17dzVp0kQdO3a0Gqtfv356++23lZiYeNf1BAAAAJA9hG7cVaNGjVS1alX99NNPlmlt27bVuXPntGzZMu3YsUPVq1dX48aNdfHiRUvN0aNHNW/ePC1atEjLly/X77//rldeecUyf/LkyZowYYLGjx+vPXv2KDQ0VM8++2yGoXf48OE6cOCAli1bpoMHD2r69OmZHno+ePBgrV+/XgsWLNDKlSu1bt067dy506qmS5cu2r59uxYuXKjo6GgZhqFnnnlGN27cyHSbREZGqn379nJ0dFT79u0VGRmZaX0qLy8vdejQQQsXLlRycnKWx/Px8dGaNWt0/vz5DMfu3LmzGjdurG7dumnq1Knat2+f1Z7vVAMGDNDNmzf18ccfZ6lnAAAAAPeP0I0sKV++vE6cOCFJ+u2337R161Z9//33qlmzpsqUKaPx48fLw8NDP/zwg+U1169ftxxOXb9+fX388cf69ttvFRsbK0kaP3683njjDbVr107lypXTBx98oGrVqmnSpEnp9nDy5Ek9/vjjqlmzpkqWLKmQkBC1aNEi3dqrV68qMjJS48ePV+PGjVW5cmXNnj3b6hD5I0eOaOHChfriiy9Ur149Va1aVV9//bVOnz6t+fPnZ7gtEhIS9MMPP+ill16SJL300kuaN2+erl69muVteeXKFV24cCHL43300Uc6f/68fHx8VKVKFfXu3VvLli1LM/aMGTO0b98+DRgwQDNmzFCRIkXS1Li5uentt9/WmDFjrI48AAAAAJDzCN3IEsMwZDKZJEm7d+/W1atX5enpqfz581seMTExOnbsmOU1xYsXV9GiRS3Pg4KClJKSosOHDyshIUFnzpxRnTp1rJZTp04dHTx4MN0e+vTpo2+//VbVqlXTkCFD0j2kO9WxY8eUlJSkWrVqWaYVKlRI5cqVszw/ePCgHBwcrGo8PT1Vrly5DHuQpG+++UalSpVS1apVJUnVqlVTiRIl9N1332X4mtsZhiFJlu2ZlfECAwO1b98+bd68Wd26ddO5c+fUokUL9ejRw2psLy8vvfzyy6pQoYJatWqVYQ/du3eXp6enPvjggyz1DAAAAOD+ELqRJQcPHlRAQICkW3uRfX19tWvXLqvH4cOH01x1Oyc1a9ZMf/75pwYOHKgzZ86ocePGlnOa/0uRkZHav3+/HBwcLI8DBw5keEG1Ox08eFBms1menp73NJ6dnZ2eeOIJDRgwQD/99JOioqIUGRmpmJgYq7rUMTLj4OCg9957T5MnT073om4AAAAAcgahG3e1Zs0a7d27V+Hh4ZKk6tWrKzY2Vg4ODipdurTV4/ZzrE+ePGkV6DZv3iw7OzuVK1dOZrNZfn5+2rhxo9WyNm7cqMDAwAx7KVKkiDp37qyvvvpKkyZN0owZM9KtK1WqlBwdHbVlyxbLtEuXLumPP/6wPK9QoYJu3rxpVXPhwgUdPnw4wx727t2r7du3a926dVY/OKxbt07R0dE6dOhQhr1L0rlz5zR37ly1atVKdnZ22Rovtcdr165lusyMtG3bVhUrVtSoUaPu6/UAAAAA7i5v3osJuSYxMVGxsbFKTk5WXFycli9frjFjxqh58+bq1KmTJCkkJERBQUFq1aqVxo0bp7Jly+rMmTNasmSJnnvuOdWsWVOS5OLios6dO2v8+PFKSEjQq6++queff14+Pj6Sbl3o7O2331apUqVUrVo1zZo1S7t27dLXX3+dbm8jRoxQjRo1VLFiRSUmJmrx4sWqUKFCurX58+dX9+7dNXjwYHl6esrLy0v/+9//rO41XqZMGbVs2VI9e/bUZ599pgIFCmjo0KEqWrSoWrZsme64kZGRevLJJ1W/fv0085544glFRkbqww8/lHTrMPLY2FgZhqHLly8rOjpa77//vtzd3TV27Nh7Gq9NmzaqU6eOnnrqKfn4+CgmJkbDhg1T2bJlVb58+XR7zYqxY8cqNDT0vl8PAAAAIHPs6YaV5cuXy9fXVyVLllTTpk21du1aTZkyRQsWLJC9vb2kW+ciL126VPXr11fXrl1VtmxZtWvXTn/++ae8vb0tY5UuXVqtW7fWM888oyZNmqhKlSr65JNPLPNfffVVDRo0SK+99poqV66s5cuXa+HChSpTpky6vTk5OWnYsGGqUqWK6tevL3t7e3377bcZrsuHH36oevXqqUWLFgoJCVHdunVVo0YNq5pZs2apRo0aat68uYKCgmQYhpYuXSpHR8c04yUlJemrr76y7PG/U3h4uObMmWO58nlCQoJ8fX1VtGhRBQUF6bPPPlPnzp31+++/y9fX957GCw0N1aJFi9SiRQuVLVtWnTt3Vvny5bVy5cps3ce8UaNGatSo0X9+D3YAAADgUWEyUq/qhHuSkJAgd3d3xcfHy2w2W827fv26YmJiFBAQIBcXl1zqMHeNHDlS8+fPt9xjGw+2vPqebvLtsNxuAcgxK9uNye0WHhn1Xn4nt1sAcoxr8D+53QKQYx6078LMMuHt2NMNAAAAAICNELoBAAAAALARQjdsYuTIkRxaDgAAAOCRR+gGAAAAAMBGCN0AAAAAANgIoduGUlJScrsFIEfwXgYAAADuz/3f4BcZcnJykp2dnc6cOaMiRYrIyclJJpMpt9sC7plhGEpKStL58+dlZ2cnJyen3G4JAAAAeKAQum3Azs5OAQEBOnv2rM6cOZPb7QDZ5ubmpuLFi8vOjoNjAAAAgHtB6LYRJycnFS9eXDdv3lRycnJutwPcN3t7ezk4OHC0BgAAAHAfCN02ZDKZ5OjoKEdHx9xuBQAAAACQC/LUsaIlS5aUyWRK84iIiJAkXb9+XREREfL09FT+/PkVHh6uuLg4qzFOnjypsLAwubm5ycvLS4MHD9bNmzetatatW6fq1avL2dlZpUuXVlRU1H+1igAAAACAR0ieCt3btm3T2bNnLY9Vq1ZJktq2bStJGjhwoBYtWqTvv/9e69ev15kzZ9S6dWvL65OTkxUWFqakpCRt2rRJs2fPVlRUlEaMGGGpiYmJUVhYmIKDg7Vr1y4NGDBAPXr00IoVK/7blQUAAAAAPPTy1OHlRYoUsXo+duxYlSpVSg0aNFB8fLwiIyM1d+5cNWrUSJI0a9YsVahQQZs3b1bt2rW1cuVKHThwQL/88ou8vb1VrVo1vfPOO3rjjTc0cuRIOTk56dNPP1VAQIAmTJggSapQoYJ+++03TZw4UaGhof/5OgMAAAAAHl55ak/37ZKSkvTVV1+pW7duMplM2rFjh27cuKGQkBBLTfny5VW8eHFFR0dLkqKjo1W5cmV5e3tbakJDQ5WQkKD9+/dbam4fI7UmdQwAAAAAAHJKntrTfbv58+fr8uXL6tKliyQpNjZWTk5O8vDwsKrz9vZWbGyspeb2wJ06P3VeZjUJCQn6999/5erqmm4/iYmJSkxMtDxPSEi473UDAAAAADwa8uye7sjISDVr1kx+fn653YokacyYMXJ3d7c8/P39c7slAAAAAEAelydD959//qlffvlFPXr0sEzz8fFRUlKSLl++bFUbFxcnHx8fS82dVzNPfX63GrPZnOFebkkaNmyY4uPjLY9Tp07d9/oBAAAAAB4NeTJ0z5o1S15eXgoLC7NMq1GjhhwdHbV69WrLtMOHD+vkyZMKCgqSJAUFBWnv3r06d+6cpWbVqlUym80KDAy01Nw+RmpN6hgZcXZ2ltlstnoAAAAAAJCZPBe6U1JSNGvWLHXu3FkODv93yrm7u7u6d++uQYMGae3atdqxY4e6du2qoKAg1a5dW5LUpEkTBQYGqmPHjtq9e7dWrFiht956SxEREXJ2dpYk9e7dW8ePH9eQIUN06NAhffLJJ5o3b54GDhyYK+sLAAAAAHh45bkLqf3yyy86efKkunXrlmbexIkTZWdnp/DwcCUmJio0NFSffPKJZb69vb0WL16sPn36KCgoSPny5VPnzp01evRoS01AQICWLFmigQMHavLkySpWrJi++OILbhcGAAAAAMhxeS50N2nSRIZhpDvPxcVF06ZN07Rp0zJ8fYkSJbR06dJMl9GwYUP9/vvv2eoTAAAAAIC7yXOHlwMAAAAA8LAgdAMAAAAAYCOEbgAAAAAAbITQDQAAAACAjRC6AQAAAACwEUI3AAAAAAA2QugGAAAAAMBGCN0AAAAAANgIoRsAAAAAABshdAMAAAAAYCOEbgAAAAAAbITQDQAAAACAjRC6AQAAAACwEUI3AAAAAAA2QugGAAAAAMBGCN0AAAAAANgIoRsAAAAAABshdAMAAAAAYCOEbgAAAAAAbITQDQAAAACAjRC6AQAAAACwEUI3AAAAAAA2QugGAAAAAMBGCN0AAAAAANgIoRsAAAAAABshdAMAAAAAYCOEbgAAAAAAbITQDQAAAACAjRC6AQAAAACwEUI3AAAAAAA2QugGAAAAAMBGCN0AAAAAANgIoRsAAAAAABshdAMAAAAAYCOEbgAAAAAAbITQDQAAAACAjRC6AQAAAACwEUI3AAAAAAA2QugGAAAAAMBGCN0AAAAAANgIoRsAAAAAABshdAMAAAAAYCOEbgAAAAAAbITQDQAAAACAjRC6AQAAAACwEUI3AAAAAAA2QugGAAAAAMBGCN0AAAAAANgIoRsAAAAAABvJc6H79OnTeumll+Tp6SlXV1dVrlxZ27dvt8w3DEMjRoyQr6+vXF1dFRISoiNHjliNcfHiRXXo0EFms1keHh7q3r27rl69alWzZ88e1atXTy4uLvL399e4ceP+k/UDAAAAADw68lTovnTpkurUqSNHR0ctW7ZMBw4c0IQJE1SwYEFLzbhx4zRlyhR9+umn2rJli/Lly6fQ0FBdv37dUtOhQwft379fq1at0uLFi7Vhwwb16tXLMj8hIUFNmjRRiRIltGPHDn344YcaOXKkZsyY8Z+uLwAAAADg4eaQ2w3c7oMPPpC/v79mzZplmRYQEGD5f8MwNGnSJL311ltq2bKlJGnOnDny9vbW/Pnz1a5dOx08eFDLly/Xtm3bVLNmTUnSxx9/rGeeeUbjx4+Xn5+fvv76ayUlJWnmzJlycnJSxYoVtWvXLn300UdW4RwAAAAAgOzIU3u6Fy5cqJo1a6pt27by8vLS448/rs8//9wyPyYmRrGxsQoJCbFMc3d3V61atRQdHS1Jio6OloeHhyVwS1JISIjs7Oy0ZcsWS039+vXl5ORkqQkNDdXhw4d16dIlW68mAAAAAOARkadC9/HjxzV9+nSVKVNGK1asUJ8+ffTqq69q9uzZkqTY2FhJkre3t9XrvL29LfNiY2Pl5eVlNd/BwUGFChWyqklvjNuXcafExEQlJCRYPQAAAAAAyEyeOrw8JSVFNWvW1Pvvvy9Jevzxx7Vv3z59+umn6ty5c672NmbMGI0aNSpXewAAAAAAPFjy1J5uX19fBQYGWk2rUKGCTp48KUny8fGRJMXFxVnVxMXFWeb5+Pjo3LlzVvNv3rypixcvWtWkN8bty7jTsGHDFB8fb3mcOnXqflYRAAAAAPAIyVOhu06dOjp8+LDVtD/++EMlSpSQdOuiaj4+Plq9erVlfkJCgrZs2aKgoCBJUlBQkC5fvqwdO3ZYatasWaOUlBTVqlXLUrNhwwbduHHDUrNq1SqVK1fO6krpt3N2dpbZbLZ6AAAAAACQmTwVugcOHKjNmzfr/fff19GjRzV37lzNmDFDERERkiSTyaQBAwbo3Xff1cKFC7V371516tRJfn5+atWqlaRbe8abNm2qnj17auvWrdq4caP69u2rdu3ayc/PT5L04osvysnJSd27d9f+/fv13XffafLkyRo0aFBurToAAAAA4CGUp87pfuKJJ/Tzzz9r2LBhGj16tAICAjRp0iR16NDBUjNkyBBdu3ZNvXr10uXLl1W3bl0tX75cLi4ulpqvv/5affv2VePGjWVnZ6fw8HBNmTLFMt/d3V0rV65URESEatSoocKFC2vEiBHcLgwAAAAAkKNMhmEYud3EgyghIUHu7u6Kj4/nUHMglzT5dlhutwDkmJXtxuR2C4+Mei+/k9stADnGNfif3G4ByDEP2ndhVjNhnjq8HAAAAACAhwmhGwAAAAAAGyF0AwAAAABgI4RuAAAAAABshNANAAAAAICNELoBAAAAALARQjcAAAAAADZC6AYAAAAAwEYI3QAAAAAA2AihGwAAAAAAGyF0AwAAAABgI4RuAAAAAABshNANAAAAAICNELoBAAAAALARQjcAAAAAADZC6AYAAAAAwEYI3QAAAAAA2AihGwAAAAAAGyF0AwAAAABgI4RuAAAAAABshNANAAAAAICNELoBAAAAALARQjcAAAAAADZC6AYAAAAAwEYI3QAAAAAA2AihGwAAAAAAGyF0AwAAAABgI4RuAAAAAABshNANAAAAAICNELoBAAAAALARQjcAAAAAADZC6AYAAAAAwEYI3QAAAAAA2AihGwAAAAAAGyF0AwAAAABgI4RuAAAAAABshNANAAAAAICNELoBAAAAALARQjcAAAAAADZC6AYAAAAAwEYI3QAAAAAA2AihGwAAAAAAGyF0AwAAAABgI4RuAAAAAABshNANAAAAAICNELoBAAAAALARQjcAAAAAADZC6AYAAAAAwEYI3QAAAAAA2EieCt0jR46UyWSyepQvX94y//r164qIiJCnp6fy58+v8PBwxcXFWY1x8uRJhYWFyc3NTV5eXho8eLBu3rxpVbNu3TpVr15dzs7OKl26tKKiov6L1QMAAAAAPGLyVOiWpIoVK+rs2bOWx2+//WaZN3DgQC1atEjff/+91q9frzNnzqh169aW+cnJyQoLC1NSUpI2bdqk2bNnKyoqSiNGjLDUxMTEKCwsTMHBwdq1a5cGDBigHj16aMWKFf/pegIAAAAAHn4Oud3AnRwcHOTj45Nmenx8vCIjIzV37lw1atRIkjRr1ixVqFBBmzdvVu3atbVy5UodOHBAv/zyi7y9vVWtWjW98847euONNzRy5Eg5OTnp008/VUBAgCZMmCBJqlChgn777TdNnDhRoaGh/+m6AgAAAAAebnluT/eRI0fk5+enxx57TB06dNDJkyclSTt27NCNGzcUEhJiqS1fvryKFy+u6OhoSVJ0dLQqV64sb29vS01oaKgSEhK0f/9+S83tY6TWpI6RkcTERCUkJFg9AAAAAADITJ4K3bVq1VJUVJSWL1+u6dOnKyYmRvXq1dOVK1cUGxsrJycneXh4WL3G29tbsbGxkqTY2FirwJ06P3VeZjUJCQn6999/M+xtzJgxcnd3tzz8/f2zu7oAAAAAgIdcnjq8vFmzZpb/r1KlimrVqqUSJUpo3rx5cnV1zcXOpGHDhmnQoEGW5wkJCQRvAAAAAECm8tSe7jt5eHiobNmyOnr0qHx8fJSUlKTLly9b1cTFxVnOAffx8UlzNfPU53erMZvNmQZ7Z2dnmc1mqwcAAAAAAJnJ06H76tWrOnbsmHx9fVWjRg05Ojpq9erVlvmHDx/WyZMnFRQUJEkKCgrS3r17de7cOUvNqlWrZDabFRgYaKm5fYzUmtQxAAAAAADIKXkqdL/++utav369Tpw4oU2bNum5556Tvb292rdvL3d3d3Xv3l2DBg3S2rVrtWPHDnXt2lVBQUGqXbu2JKlJkyYKDAxUx44dtXv3bq1YsUJvvfWWIiIi5OzsLEnq3bu3jh8/riFDhujQoUP65JNPNG/ePA0cODA3Vx0AAAAA8BDKU+d0//XXX2rfvr0uXLigIkWKqG7dutq8ebOKFCkiSZo4caLs7OwUHh6uxMREhYaG6pNPPrG83t7eXosXL1afPn0UFBSkfPnyqXPnzho9erSlJiAgQEuWLNHAgQM1efJkFStWTF988QW3CwMAAAAA5DiTYRhGbjfxIEpISJC7u7vi4+M5vxvIJU2+HZbbLQA5ZmW7MbndwiOj3svv5HYLQI5xDf4nt1sAcsyD9l2Y1UyYY3u6r1y5ovj4eKWkpKSZV7x48ZxaDAAAAAAAD4xsh+7p06fro48+0vHjxzOsSU5Ozu5iAAAAAAB44GTrQmqffvqpIiIiVLp0ab377rsyDEMDBgzQ0KFD5ePjo6pVqyoyMjKnegUAAAAA4IGSrdD98ccfKzQ0VMuWLVOvXr0kSWFhYXrvvfd04MABXblyRRcuXMiRRgEAAAAAeNBkK3QfO3ZMLVq0kCQ5OjpKkpKSkiRJ7u7u6tGjh9XVxQEAAAAAeJRkK3S7u7vr5s2bkiSz2Sw3NzedOnXKMr9AgQKKjY3NXocAAAAAADygshW6K1WqpN27d1ue165dW9OnT9fp06d16tQpffbZZypbtmy2mwQAAAAA4EGUrauXv/TSS/r000+VmJgoZ2dnjRo1SiEhIZZbhDk6OurHH3/MkUYBAAAAAHjQZCt0d+3aVV27drU8r1Onjvbv369FixbJ3t5eTZo0YU83AAAAAOCRle37dN/pscceU//+/XN6WAAAAAAAHjjZOqcbAAAAAABk7J72dNvZ2cnOzk7//POPnJycZGdnJ5PJlOlrTCaT5QrnAAAAAAA8Su4pdI8YMUImk0kODg5WzwEAAAAAQFr3FLpHjhyZ6XMAAAAAAPB/OKcbAAAAAAAbyVbonjJlikJDQzOc36xZM02fPj07iwAAAAAA4IGVrdAdGRmpwMDADOcHBgZqxowZ2VkEAAAAAAAPrGyF7mPHjqlChQoZzi9fvryOHTuWnUUAAAAAAPDAylbodnJyUmxsbIbzz549Kzs7ThsHAAAAADyaspWIa9euraioKF25ciXNvPj4eM2aNUu1a9fOziIAAAAAAHhg3dMtw+709ttvq0GDBqpWrZoGDBigihUrSpL27dunSZMm6ezZs5o7d26ONAoAAAAAwIMmW6G7Vq1aWrRokV5++WX1799fJpNJkmQYhgICArRw4UIFBQXlSKMAAAAAADxoshW6Jenpp5/W0aNH9fvvv1sumlaqVClVr17dEsIBAAAAAHgUZTt0S5KdnZ1q1KihGjVq5MRwAAAAAAA8FHIkdB84cEDHjx/XpUuXZBhGmvmdOnXKicUAAAAAAPBAyVboPnbsmF566SVt3bo13bAtSSaTidANAAAAAHgkZSt0v/zyy9q7d68mTZqkevXqqWDBgjnVFwAAAAAAD7xshe6NGzfqzTffVL9+/XKqHwAAAAAAHhp22Xlx4cKF5e7unlO9AAAAAADwUMlW6O7du7e++uorJScn51Q/AAAAAAA8NLJ1eHnZsmWVnJysqlWrqlu3bvL395e9vX2autatW2dnMQAAAAAAPJCyFbpfeOEFy/+//vrr6daYTCb2hAMAAAAAHknZCt1r167NqT4AAAAAAHjoZCt0N2jQIKf6AAAAAADgoZOt0J0qMTFRO3fu1Llz51SnTh0VLlw4J4YFAAAAAOCBlq2rl0vSlClT5Ovrq7p166p169bas2ePJOnvv/9W4cKFNXPmzGw3CQAAAADAg+ieQ/eRI0e0ePFiSdKsWbM0YMAANW3aVJGRkTIMw1JXuHBhNWrUSN9++23OdQsAAAAAwAMky6HbMAyNHz9e9evXl5ubmyRpwoQJatmypebOnasWLVqkeU2NGjW0f//+nOsWAAAAAIAHSJZD94cffqgZM2Zo48aNatSokSTp6NGjatasWYavKVSokC5cuJD9LgEAAAAAeABlOXRXrVpVFy9e1DfffGOZ5uHhob///jvD1xw4cEA+Pj7Z6xAAAAAAgAdUlkN3aGiodu3apU2bNmnChAmSpGeeeUYzZszQ5cuX09Tv379fn3/+uZ599tkcaxYAAAAAgAfJPd0yrFixYlqyZInOnDkjSXr33XdVq1YtVapUSS1atJDJZNLs2bM1c+ZM/fjjj/L19dWIESNs0jgAAAAAAHndfd0yzM/Pz/LfHTt2qGnTpvruu+9kGIa+/PJLLVq0SO3bt9fmzZu5ZzcAAAAA4JF1T3u60+Pl5aUvvvhCX3zxhc6fP6+UlBQVKVJEdnbZvgU4AAAAAAAPtGyH7tsVKVIkJ4cDAAAAAOCBlq3QPXr06LvWmEwmDR8+PDuLAQAAAADggZSt0D1y5MgM55lMJhmGQegGAAAAADyysnXidUpKSprHzZs3dezYMQ0cOFA1a9bUuXPncqpXAAAAAAAeKDl+tTM7OzsFBARo/PjxKlOmjPr163ffY40dO1Ymk0kDBgywTLt+/boiIiLk6emp/PnzKzw8XHFxcVavO3nypMLCwuTm5iYvLy8NHjxYN2/etKpZt26dqlevLmdnZ5UuXVpRUVH33ScAAAAAAOmx6SXG69evr6VLl97Xa7dt26bPPvtMVapUsZo+cOBALVq0SN9//73Wr1+vM2fOqHXr1pb5ycnJCgsLU1JSkjZt2qTZs2crKirK6n7hMTExCgsLU3BwsHbt2qUBAwaoR48eWrFixf2tKAAAAAAA6bBp6N6+fft93Trs6tWr6tChgz7//HMVLFjQMj0+Pl6RkZH66KOP1KhRI9WoUUOzZs3Spk2btHnzZknSypUrdeDAAX311VeqVq2amjVrpnfeeUfTpk1TUlKSJOnTTz9VQECAJkyYoAoVKqhv375q06aNJk6cmDMrDgAAAACAsnkhtTlz5qQ7/fLly9qwYYN++ukn9ejR457HjYiIUFhYmEJCQvTuu+9apu/YsUM3btxQSEiIZVr58uVVvHhxRUdHq3bt2oqOjlblypXl7e1tqQkNDVWfPn20f/9+Pf7444qOjrYaI7Xm9sPYH1b1Xn4nt1sAcoxrcG53AAAAAGQuW6G7S5cuGc4rXLiwhg4danVYd1Z8++232rlzp7Zt25ZmXmxsrJycnOTh4WE13dvbW7GxsZaa2wN36vzUeZnVJCQk6N9//5Wrq2uaZScmJioxMdHyPCEh4Z7WCwAAAADw6MlW6I6JiUkzzWQyqWDBgipQoMA9j3fq1Cn1799fq1atkouLS3Zay3FjxozRqFGjcrsNAAAAAMADJFuhu0SJEjnVh6Rbh4+fO3dO1atXt0xLTk7Whg0bNHXqVK1YsUJJSUm6fPmy1d7uuLg4+fj4SJJ8fHy0detWq3FTr25+e82dVzyPi4uT2WxOdy+3JA0bNkyDBg2yPE9ISJC/v//9rywAAAAA4KFn0wup3avGjRtr79692rVrl+VRs2ZNdejQwfL/jo6OWr16teU1hw8f1smTJxUUFCRJCgoK0t69e63uD75q1SqZzWYFBgZaam4fI7UmdYz0ODs7y2w2Wz0AAAAAAMhMtvZ029nZyWQy3dNrTCZTmntmpypQoIAqVapkNS1fvnzy9PS0TO/evbsGDRqkQoUKyWw2q1+/fgoKClLt2rUlSU2aNFFgYKA6duyocePGKTY2Vm+99ZYiIiLk7OwsSerdu7emTp2qIUOGqFu3blqzZo3mzZunJUuW3OsmAAAAAAAgQ9kK3SNGjND8+fO1f/9+hYaGqly5cpKkQ4cOaeXKlapUqZJatWqVE31aTJw4UXZ2dgoPD1diYqJCQ0P1ySefWObb29tr8eLF6tOnj4KCgpQvXz517txZo0ePttQEBARoyZIlGjhwoCZPnqxixYrpiy++UGhoaI72CgAAAAB4tGUrdPv5+encuXPat2+fJXCnOnjwoBo1aiQ/Pz/17Nnzvpexbt06q+cuLi6aNm2apk2bluFrSpQooaVLl2Y6bsOGDfX777/fd18AAAAAANxNts7p/vDDD9W3b980gVuSKlSooL59+2rcuHHZWQQAAAAAAA+sbIXuv/76S46OjhnOd3R01F9//ZWdRQAAAAAA8MDKVuiuVKmSPvnkE50+fTrNvL/++kuffPKJKleunJ1FAAAAAADwwMrWOd0TJ05UaGioypYtq+eee06lS5eWJB05ckTz58+XYRj66quvcqRRAAAAAAAeNNkK3XXr1tWWLVs0fPhw/fzzz/r3338lSa6urgoNDdWoUaPY0w0AAAAAeGRlK3RLtw4x//nnn5WSkqLz589LkooUKSI7u2wduQ4AAAAAwAMv26E7lZ2dnVxcXJQ/f34CNwAAAAAAyuaF1CRp+/btatq0qdzc3OTp6an169dLkv7++2+1bNkyzX22AQAAAAB4VGQrdG/atEl169bVkSNH9NJLLyklJcUyr3DhwoqPj9dnn32W7SYBAAAAAHgQZSt0v/nmm6pQoYIOHDig999/P8384OBgbdmyJTuLAAAAAADggZWt0L1t2zZ17dpVzs7OMplMaeYXLVpUsbGx2VkEAAAAAAAPrGyFbkdHR6tDyu90+vRp5c+fPzuLAAAAAADggZWt0F27dm398MMP6c67du2aZs2apQYNGmRnEQAAAAAAPLCyFbpHjRql7du3KywsTMuWLZMk7d69W1988YVq1Kih8+fPa/jw4TnSKAAAAAAAD5ps3ae7Vq1aWrp0qfr06aNOnTpJkl577TVJUqlSpbR06VJVqVIl+10CAAAAAPAAuu/QbRiGrly5oqeeekqHDx/Wrl27dOTIEaWkpKhUqVKqUaNGuhdXAwAAAADgUXHfoTspKUmFChXS+++/ryFDhqhatWqqVq1aDrYGAAAAAMCD7b7P6XZ2dpaPj4+cnZ1zsh8AAAAAAB4a2bqQWpcuXTRnzhwlJSXlVD8AAAAAADw0snUhtcqVK2v+/PmqWLGiunTpopIlS8rV1TVNXevWrbOzGAAAAAAAHkjZCt3t27e3/H9GtwYzmUxKTk7OzmIAAAAAAHgg3XPofvPNN9WuXTtVqVJFa9eutUVPAAAAAAA8FO45dI8dO1aVKlVSlSpV1KBBA124cEFeXl5atWqVGjVqZIseAQAAAAB4IGXrQmqpDMPIiWEAAAAAAHio5EjoBgAAAAAAaRG6AQAAAACwkfu6evmJEye0c+dOSVJ8fLwk6ciRI/Lw8Ei3vnr16vfXHQAAAAAAD7D7Ct3Dhw9Pc4uwV155JU2dYRjcMgwAAAAA8Mi659A9a9YsW/QBAAAAAMBD555Dd+fOnW3RBwAAAAAADx0upAYAAAAAgI0QugEAAAAAsBFCNwAAAAAANkLoBgAAAADARgjdAAAAAADYCKEbAAAAAAAbIXQDAAAAAGAjhG4AAAAAAGyE0A0AAAAAgI0QugEAAAAAsBFCNwAAAAAANkLoBgAAAADARgjdAAAAAADYCKEbAAAAAAAbIXQDAAAAAGAjhG4AAAAAAGyE0A0AAAAAgI0QugEAAAAAsBFCNwAAAAAANpKnQvf06dNVpUoVmc1mmc1mBQUFadmyZZb5169fV0REhDw9PZU/f36Fh4crLi7OaoyTJ08qLCxMbm5u8vLy0uDBg3Xz5k2rmnXr1ql69epydnZW6dKlFRUV9V+sHgAAAADgEZOnQnexYsU0duxY7dixQ9u3b1ejRo3UsmVL7d+/X5I0cOBALVq0SN9//73Wr1+vM2fOqHXr1pbXJycnKywsTElJSdq0aZNmz56tqKgojRgxwlITExOjsLAwBQcHa9euXRowYIB69OihFStW/OfrCwAAAAB4uJkMwzByu4nMFCpUSB9++KHatGmjIkWKaO7cuWrTpo0k6dChQ6pQoYKio6NVu3ZtLVu2TM2bN9eZM2fk7e0tSfr000/1xhtv6Pz583JyctIbb7yhJUuWaN++fZZltGvXTpcvX9by5cuz3FdCQoLc3d0VHx8vs9mcsyttQ/Vefie3WwByjGvwP7ndApBjVrYbk9stPDL4LsTDhO9CPEwetO/CrGbCPLWn+3bJycn69ttvde3aNQUFBWnHjh26ceOGQkJCLDXly5dX8eLFFR0dLUmKjo5W5cqVLYFbkkJDQ5WQkGDZWx4dHW01RmpN6hgAAAAAAOQUh9xu4E579+5VUFCQrl+/rvz58+vnn39WYGCgdu3aJScnJ3l4eFjVe3t7KzY2VpIUGxtrFbhT56fOy6wmISFB//77r1xdXdPtKzExUYmJiZbnCQkJ2VpPAAAAAMDDL8/t6S5Xrpx27dqlLVu2qE+fPurcubMOHDiQ221pzJgxcnd3tzz8/f1zuyUAAAAAQB6X50K3k5OTSpcurRo1amjMmDGqWrWqJk+eLB8fHyUlJeny5ctW9XFxcfLx8ZEk+fj4pLmaeerzu9WYzeYM93JL0rBhwxQfH295nDp1KrurCgAAAAB4yOW50H2nlJQUJSYmqkaNGnJ0dNTq1ast8w4fPqyTJ08qKChIkhQUFKS9e/fq3LlzlppVq1bJbDYrMDDQUnP7GKk1qWNkxNnZ2XIrs9QHAAAAAACZyVPndA8bNkzNmjVT8eLFdeXKFc2dO1fr1q3TihUr5O7uru7du2vQoEEqVKiQzGaz+vXrp6CgINWuXVuS1KRJEwUGBqpjx44aN26cYmNj9dZbbykiIkLOzs6SpN69e2vq1KkaMmSIunXrpjVr1mjevHlasmRJbq46AAAAAOAhlKdC97lz59SpUyedPXtW7u7uqlKlilasWKGnn35akjRx4kTZ2dkpPDxciYmJCg0N1SeffGJ5vb29vRYvXqw+ffooKChI+fLlU+fOnTV69GhLTUBAgJYsWaKBAwdq8uTJKlasmL744guFhob+5+sLAAAAAHi45anQHRkZmel8FxcXTZs2TdOmTcuwpkSJElq6dGmm4zRs2FC///77ffUIAAAAAEBW5flzugEAAAAAeFARugEAAAAAsBFCNwAAAAAANkLoBgAAAADARgjdAAAAAADYCKEbAAAAAAAbIXQDAAAAAGAjhG4AAAAAAGyE0A0AAAAAgI0QugEAAAAAsBFCNwAAAAAANkLoBgAAAADARgjdAAAAAADYCKEbAAAAAAAbIXQDAAAAAGAjhG4AAAAAAGyE0A0AAAAAgI0QugEAAAAAsBFCNwAAAAAANkLoBgAAAADARgjdAAAAAADYCKEbAAAAAAAbIXQDAAAAAGAjhG4AAAAAAGyE0A0AAAAAgI0QugEAAAAAsBFCNwAAAAAANkLoBgAAAADARgjdAAAAAADYCKEbAAAAAAAbIXQDAAAAAGAjhG4AAAAAAGyE0A0AAAAAgI0QugEAAAAAsBFCNwAAAAAANkLoBgAAAADARgjdAAAAAADYCKEbAAAAAAAbIXQDAAAAAGAjhG4AAAAAAGyE0A0AAAAAgI0QugEAAAAAsBFCNwAAAAAANkLoBgAAAADARgjdAAAAAADYCKEbAAAAAAAbIXQDAAAAAGAjhG4AAAAAAGyE0A0AAAAAgI3kqdA9ZswYPfHEEypQoIC8vLzUqlUrHT582Krm+vXrioiIkKenp/Lnz6/w8HDFxcVZ1Zw8eVJhYWFyc3OTl5eXBg8erJs3b1rVrFu3TtWrV5ezs7NKly6tqKgoW68eAAAAAOARk6dC9/r16xUREaHNmzdr1apVunHjhpo0aaJr165ZagYOHKhFixbp+++/1/r163XmzBm1bt3aMj85OVlhYWFKSkrSpk2bNHv2bEVFRWnEiBGWmpiYGIWFhSk4OFi7du3SgAED1KNHD61YseI/XV8AAAAAwMPNZBiGkdtNZOT8+fPy8vLS+vXrVb9+fcXHx6tIkSKaO3eu2rRpI0k6dOiQKlSooOjoaNWuXVvLli1T8+bNdebMGXl7e0uSPv30U73xxhs6f/68nJyc9MYbb2jJkiXat2+fZVnt2rXT5cuXtXz58iz1lpCQIHd3d8XHx8tsNuf8yttIvZffye0WgBzjGvxPbrcA5JiV7cbkdguPDL4L8TDhuxAPkwftuzCrmTBP7em+U3x8vCSpUKFCkqQdO3boxo0bCgkJsdSUL19exYsXV3R0tCQpOjpalStXtgRuSQoNDVVCQoL2799vqbl9jNSa1DHSk5iYqISEBKsHAAAAAACZybOhOyUlRQMGDFCdOnVUqVIlSVJsbKycnJzk4eFhVevt7a3Y2FhLze2BO3V+6rzMahISEvTvv/+m28+YMWPk7u5uefj7+2d7HQEAAAAAD7c8G7ojIiK0b98+ffvtt7ndiiRp2LBhio+PtzxOnTqV2y0BAAAAAPI4h9xuID19+/bV4sWLtWHDBhUrVswy3cfHR0lJSbp8+bLV3u64uDj5+PhYarZu3Wo1XurVzW+vufOK53FxcTKbzXJ1dU23J2dnZzk7O2d73QAAAAAAj448tafbMAz17dtXP//8s9asWaOAgACr+TVq1JCjo6NWr15tmXb48GGdPHlSQUFBkqSgoCDt3btX586ds9SsWrVKZrNZgYGBlprbx0itSR0DAAAAAICckKf2dEdERGju3LlasGCBChQoYDkH293dXa6urnJ3d1f37t01aNAgFSpUSGazWf369VNQUJBq164tSWrSpIkCAwPVsWNHjRs3TrGxsXrrrbcUERFh2VPdu3dvTZ06VUOGDFG3bt20Zs0azZs3T0uWLMm1dQcAAAAAPHzy1J7u6dOnKz4+Xg0bNpSvr6/l8d1331lqJk6cqObNmys8PFz169eXj4+PfvrpJ8t8e3t7LV68WPb29goKCtJLL72kTp06afTo0ZaagIAALVmyRKtWrVLVqlU1YcIEffHFFwoNDf1P1xcAAAAA8HDLU3u6s3LLcBcXF02bNk3Tpk3LsKZEiRJaunRppuM0bNhQv//++z33CAAAAABAVuWpPd0AAAAAADxMCN0AAAAAANgIoRsAAAAAABshdAMAAAAAYCOEbgAAAAAAbITQDQAAAACAjRC6AQAAAACwEUI3AAAAAAA2QugGAAAAAMBGCN0AAAAAANgIoRsAAAAAABshdAMAAAAAYCOEbgAAAAAAbITQDQAAAACAjRC6AQAAAACwEUI3AAAAAAA2QugGAAAAAMBGCN0AAAAAANgIoRsAAAAAABshdAMAAAAAYCOEbgAAAAAAbITQDQAAAACAjRC6AQAAAACwEUI3AAAAAAA2QugGAAAAAMBGCN0AAAAAANgIoRsAAAAAABshdAMAAAAAYCOEbgAAAAAAbITQDQAAAACAjRC6AQAAAACwEUI3AAAAAAA2QugGAAAAAMBGCN0AAAAAANgIoRsAAAAAABshdAMAAAAAYCOEbgAAAAAAbITQDQAAAACAjRC6AQAAAACwEUI3AAAAAAA2QugGAAAAAMBGCN0AAAAAANgIoRsAAAAAABshdAMAAAAAYCOEbgAAAAAAbITQDQAAAACAjRC6AQAAAACwEUI3AAAAAAA2QugGAAAAAMBG8lzo3rBhg1q0aCE/Pz+ZTCbNnz/far5hGBoxYoR8fX3l6uqqkJAQHTlyxKrm4sWL6tChg8xmszw8PNS9e3ddvXrVqmbPnj2qV6+eXFxc5O/vr3Hjxtl61QAAAAAAj5g8F7qvXbumqlWratq0aenOHzdunKZMmaJPP/1UW7ZsUb58+RQaGqrr169bajp06KD9+/dr1apVWrx4sTZs2KBevXpZ5ickJKhJkyYqUaKEduzYoQ8//FAjR47UjBkzbL5+AAAAAIBHh0NuN3CnZs2aqVmzZunOMwxDkyZN0ltvvaWWLVtKkubMmSNvb2/Nnz9f7dq108GDB7V8+XJt27ZNNWvWlCR9/PHHeuaZZzR+/Hj5+fnp66+/VlJSkmbOnCknJydVrFhRu3bt0kcffWQVzgEAAAAAyI48t6c7MzExMYqNjVVISIhlmru7u2rVqqXo6GhJUnR0tDw8PCyBW5JCQkJkZ2enLVu2WGrq168vJycnS01oaKgOHz6sS5cupbvsxMREJSQkWD0AAAAAAMjMAxW6Y2NjJUne3t5W0729vS3zYmNj5eXlZTXfwcFBhQoVsqpJb4zbl3GnMWPGyN3d3fLw9/fP/goBAAAAAB5qD1Tozk3Dhg1TfHy85XHq1KncbgkAAAAAkMc9UKHbx8dHkhQXF2c1PS4uzjLPx8dH586ds5p/8+ZNXbx40aomvTFuX8adnJ2dZTabrR4AAAAAAGTmgQrdAQEB8vHx0erVqy3TEhIStGXLFgUFBUmSgoKCdPnyZe3YscNSs2bNGqWkpKhWrVqWmg0bNujGjRuWmlWrVqlcuXIqWLDgf7Q2AAAAAICHXZ4L3VevXtWuXbu0a9cuSbcunrZr1y6dPHlSJpNJAwYM0LvvvquFCxdq79696tSpk/z8/NSqVStJUoUKFdS0aVP17NlTW7du1caNG9W3b1+1a9dOfn5+kqQXX3xRTk5O6t69u/bv36/vvvtOkydP1qBBg3JprQEAAAAAD6M8d8uw7du3Kzg42PI8NQh37txZUVFRGjJkiK5du6ZevXrp8uXLqlu3rpYvXy4XFxfLa77++mv17dtXjRs3lp2dncLDwzVlyhTLfHd3d61cuVIRERGqUaOGChcurBEjRnC7MAAAAABAjspzobthw4YyDCPD+SaTSaNHj9bo0aMzrClUqJDmzp2b6XKqVKmiX3/99b77BAAAAADgbvLc4eUAAAAAADwsCN0AAAAAANgIoRsAAAAAABshdAMAAAAAYCOEbgAAAAAAbITQDQAAAACAjRC6AQAAAACwEUI3AAAAAAA2QugGAAAAAMBGCN0AAAAAANgIoRsAAAAAABshdAMAAAAAYCOEbgAAAAAAbITQDQAAAACAjRC6AQAAAACwEUI3AAAAAAA2QugGAAAAAMBGCN0AAAAAANgIoRsAAAAAABshdAMAAAAAYCOEbgAAAAAAbITQDQAAAACAjRC6AQAAAACwEUI3AAAAAAA2QugGAAAAAMBGCN0AAAAAANgIoRsAAAAAABshdAMAAAAAYCOEbgAAAAAAbITQDQAAAACAjRC6AQAAAACwEUI3AAAAAAA2QugGAAAAAMBGCN0AAAAAANgIoRsAAAAAABshdAMAAAAAYCOEbgAAAAAAbITQDQAAAACAjRC6AQAAAACwEUI3AAAAAAA2QugGAAAAAMBGCN0AAAAAANgIoRsAAAAAABshdAMAAAAAYCOEbgAAAAAAbITQDQAAAACAjRC6AQAAAACwEUI3AAAAAAA28kiH7mnTpqlkyZJycXFRrVq1tHXr1txuCQAAAADwEHlkQ/d3332nQYMG6e2339bOnTtVtWpVhYaG6ty5c7ndGgAAAADgIfHIhu6PPvpIPXv2VNeuXRUYGKhPP/1Ubm5umjlzZm63BgAAAAB4SDySoTspKUk7duxQSEiIZZqdnZ1CQkIUHR2di50BAAAAAB4mDrndQG74+++/lZycLG9vb6vp3t7eOnToULqvSUxMVGJiouV5fHy8JCkhIcF2jdrAzaTrud0CkGNu/pN49yLgAfGgfZ88yPguxMOE70I8TB6078LUfg3DyLTukQzd92PMmDEaNWpUmun+/v650A0ASVJUbjcA5Bz37hNzuwUAD6Ko3G4AyDkP6nfhlStX5O7unuH8RzJ0Fy5cWPb29oqLi7OaHhcXJx8fn3RfM2zYMA0aNMjyPCUlRRcvXpSnp6dMJpNN+wWQVkJCgvz9/XXq1CmZzebcbgcAgP8c34VA7jIMQ1euXJGfn1+mdY9k6HZyclKNGjW0evVqtWrVStKtEL169Wr17ds33dc4OzvL2dnZapqHh4eNOwVwN2azmX9oAAAeaXwXArknsz3cqR7J0C1JgwYNUufOnVWzZk09+eSTmjRpkq5du6auXbvmdmsAAAAAgIfEIxu6X3jhBZ0/f14jRoxQbGysqlWrpuXLl6e5uBoAAAAAAPfrkQ3dktS3b98MDycHkLc5Ozvr7bffTnPaBwAAjwq+C4EHg8m42/XNAQAAAADAfbHL7QYAAAAAAHhYEboBAAAAALARQjcAAAAAADZC6AbwQJo2bZpKliwpFxcX1apVS1u3bs3tlgAA+E9s2LBBLVq0kJ+fn0wmk+bPn5/bLQHIBKEbwAPnu+++06BBg/T2229r586dqlq1qkJDQ3Xu3Lncbg0AAJu7du2aqlatqmnTpuV2KwCygKuXA3jg1KpVS0888YSmTp0qSUpJSZG/v7/69eunoUOH5nJ3AAD8d0wmk37++We1atUqt1sBkAH2dAN4oCQlJWnHjh0KCQmxTLOzs1NISIiio6NzsTMAAAAgLUI3gAfK33//reTkZHl7e1tN9/b2VmxsbC51BQAAAKSP0A0AAAAAgI0QugE8UAoXLix7e3vFxcVZTY+Li5OPj08udQUAAACkj9AN4IHi5OSkGjVqaPXq1ZZpKSkpWr16tYKCgnKxMwAAACAth9xuAADu1aBBg9S5c2fVrFlTTz75pCZNmqRr166pa9euud0aAAA2d/XqVR09etTyPCYmRrt27VKhQoVUvHjxXOwMQHq4ZRiAB9LUqVP14YcfKjY2VtWqVdOUKVNUq1at3G4LAACbW7dunYKDg9NM79y5s6Kiov77hgBkitANAAAAAICNcE43AAAAAAA2QugGAAAAAMBGCN0AAAAAANgIoRsAAAAAABshdAMAAAAAYCOEbgAAAAAAbITQDQAAAACAjRC6AQAAAACwEUI3AACPmJIlS6pLly653QYAAI8EQjcAAA+RY8eO6eWXX9Zjjz0mFxcXmc1m1alTR5MnT9a///6b2+0BAPDIccjtBgAAQM5YsmSJ2rZtK2dnZ3Xq1EmVKlVSUlKSfvvtNw0ePFj79+/XjBkzcrtNAAAeKYRuAAAeAjExMWrXrp1KlCihNWvWyNfX1zIvIiJCR48e1ZIlS3KxQwAAHk0cXg4AwENg3Lhxunr1qiIjI60Cd6rSpUurf//+6b724sWLev3111W5cmXlz59fZrNZzZo10+7du9PUfvzxx6pYsaLc3NxUsGBB1axZU3PnzrXMv3LligYMGKCSJUvK2dlZXl5eevrpp7Vz506rcbZs2aKmTZvK3d1dbm5uatCggTZu3GhVk9WxAADIy9jTDQDAQ2DRokV67LHH9NRTT93za48fP6758+erbdu2CggIUFxcnD777DM1aNBABw4ckJ+fnyTp888/16uvvqo2bdqof//+un79uvbs2aMtW7boxRdflCT17t1bP/zwg/r27avAwEBduHBBv/32mw4ePKjq1atLktasWaNmzZqpRo0aevvtt2VnZ6dZs2apUaNG+vXXX/Xkk09meSwAAPI6k2EYRm43AQAA7l9CQoLc3d3VsmVLzZ8//671JUuWVMOGDRUVFSVJSkxMlKOjo+zs/u8AuBMnTqh8+fL63//+p+HDh0uSWrVqpaNHj2rfvn0Zju3h4aGXXnpJU6dOTXe+YRgqV66cHvt/7d1PSNN/HMfxZ0ataA4RLckFoZMoo8RgUR2CokDqJEF/DpVRjejSqYIs+ndKI4IuiVclEOpQoMzoHyHELtIfOqw8pWE5sJqEC9fv8AP5Tf39rGDwmzwfsMP2eX/e++z4Gu8P36oquru7mTdvHgDfv3+ntraWSCRCPB7/pV6SJBUCx8slSSpwX79+BaC4uPiP9gcCgcnAPTExQSqVIhgMsmrVqpxR7pKSEj58+EAikfjXXiUlJbx48YKhoaEZ1/v7+0kmkxw4cIBUKsXIyAgjIyOMjY2xfft2nj17Rjab/aVekiQVAkO3JEkFLhQKAX/fgf4T2WyWGzduUFNTQyAQoKysjPLycl6+fMmXL18m686cOUMwGCQajVJTU8PJkyen3cO+du0ar1+/ZsWKFUSjUS5evMjAwMDkejKZBODQoUOUl5fnvNrb2xkfH5/8ztl6SZJUCBwvlyRpDqisrGTx4sW8e/du1tqp4+VXr17l/PnzHDlyhB07dlBaWkpRURGnTp2irKyMJ0+eTO4dGxvjwYMH9PT00N3dzfDwMBcuXODSpUuTNR8/fuTevXvE43F6e3vJZrPcvXuXhoYG7ty5w/79+2lpaaGurm7G823dupUFCxbM2kuSpEJg6JYkaQ6IxWK0tbXR19fHpk2b/rN2auiuq6ujtLSUR48e5dSFw2EikUhO6P6nTCZDY2MjPT09pNNpFi1aNK3m06dP1NfXs3LlSp4/f04ikSAajXL79m2OHz/+W79xai9JkgqB4+WSJM0Bp0+fZsmSJRw9epTh4eFp6+/fv+fmzZsz7p0/fz5T/4Pv6upicHAw57NUKpXzfuHChaxZs4afP3/y48cPJiYmcsbRAZYuXcry5csZHx8HYMOGDVRXV9Pa2ko6nZ52ls+fPwP8Ui9JkgqBjwyTJGkOqK6uprOzk71797J69WoOHjzI2rVryWQy9PX10dXVxeHDh2fcu3v3bi5fvkxTUxObN2/m1atXdHR0UFVVlVO3c+dOKioq2LJlC8uWLePt27fcunWLXbt2UVxczOjoKOFwmD179rB+/XqCwSAPHz4kkUhw/fp1AIqKimhvb6ehoYHa2lqampqorKxkcHCQx48fEwqFuH//Pt++fZu1lyRJhcDxckmS5pBkMklLSwu9vb0MDQ0RCARYt24d+/bt49ixYwQCgRkfGXbu3Dk6OzsZHR2lvr6e1tZWzp49CzA5Xt7W1kZHRwdv3rwhnU4TDodpbGykubmZUChEJpOhubmZeDzOwMAA2WyWSCRCLBbjxIkTOefs7+/nypUrPH36lHQ6TUVFBRs3biQWi7Ft27bf6iVJ0v+ZoVuSJEmSpDzxTrckSZIkSXli6JYkSZIkKU8M3ZIkSZIk5YmhW5IkSZKkPDF0S5IkSZKUJ4ZuSZIkSZLyxNAtSZIkSVKeGLolSZIkScoTQ7ckSZIkSXli6JYkSZIkKU8M3ZIkSZIk5YmhW5IkSZKkPDF0S5IkSZKUJ38BOPOcwyT+GaMAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "# Função para plotar a distribuição das classes\n",
        "def plot_class_distribution(y_before, y_after, labels=['Antes do ADASYN', 'Depois do ADASYN']):\n",
        "    \"\"\"\n",
        "    Plota a distribuição das classes antes e depois do balanceamento com ADASYN.\n",
        "    \"\"\"\n",
        "    # Contar as classes antes e depois\n",
        "    class_counts_before = pd.Series(y_before).value_counts().sort_index()\n",
        "    class_counts_after = pd.Series(y_after).value_counts().sort_index()\n",
        "\n",
        "    # Criar DataFrame para plotagem\n",
        "    df = pd.DataFrame({\n",
        "        'Classes': class_counts_before.index.tolist() + class_counts_after.index.tolist(),\n",
        "        'Frequência': class_counts_before.tolist() + class_counts_after.tolist(),\n",
        "        'Conjunto': [labels[0]] * len(class_counts_before) + [labels[1]] * len(class_counts_after)\n",
        "    })\n",
        "\n",
        "    # Plotar distribuição\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.barplot(x='Classes', y='Frequência', hue='Conjunto', data=df, palette='viridis')\n",
        "    plt.title('Distribuição das Classes Antes e Depois do ADASYN', fontsize=14)\n",
        "    plt.xlabel('Classes', fontsize=12)\n",
        "    plt.ylabel('Frequência', fontsize=12)\n",
        "    plt.legend(title='Conjunto', fontsize=10)\n",
        "    plt.xticks(fontsize=10)\n",
        "    plt.yticks(fontsize=10)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Save the plot to a PNG file\n",
        "plt.savefig('class_distribution.jpeg')\n",
        "\n",
        "# Comparar antes e depois do ADASYN\n",
        "plot_class_distribution(y_train, y_train_resampled)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jgg2SmPTPfVj"
      },
      "source": [
        "## Início experimento - Variáveis Básicas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "O-eiuwm5PiD5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\willi\\Documents\\Projetos\\mestrado_mineracao\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "# Realizando experimento já considerando X_train_resampled e y_train_resampled\n",
        "import numpy as np\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import optuna\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier, StackingClassifier, VotingClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.metrics import f1_score, recall_score, accuracy_score, confusion_matrix\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
        "from skopt import BayesSearchCV\n",
        "from skopt.space import Integer, Categorical, Real\n",
        "# from neupy import algorithms\n",
        "\n",
        "# Configurar K-Fold com estratificação\n",
        "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# Definição básica dos classificadores\n",
        "knn = KNeighborsClassifier()\n",
        "lvq = MLPClassifier(solver='sgd', learning_rate='constant', learning_rate_init=0.1, max_iter=100)\n",
        "tree = DecisionTreeClassifier()\n",
        "svm = SVC(probability=True)\n",
        "rf = RandomForestClassifier()\n",
        "mlp = MLPClassifier(max_iter=100, hidden_layer_sizes=(50,))\n",
        "xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
        "lgbm = LGBMClassifier(n_estimators=50, max_depth=3, verbose=-1) #verbose=-1 não mostra mensagens de alerta\n",
        "\n",
        "# Comitê de Redes Neurais Artificiais\n",
        "ann_ensemble = VotingClassifier(\n",
        "    estimators=[\n",
        "        ('mlp_relu', MLPClassifier(activation='relu', hidden_layer_sizes=(50, 20), max_iter=100)),\n",
        "        ('mlp_tanh', MLPClassifier(activation='tanh', hidden_layer_sizes=(50, 20), max_iter=100)),\n",
        "        ('mlp_logistic', MLPClassifier(activation='logistic', hidden_layer_sizes=(50, 20), max_iter=100))\n",
        "    ],\n",
        "    voting='soft',\n",
        "    n_jobs=-1  # Paralelização\n",
        ")\n",
        "\n",
        "# Comitê Heterogêneo (Stacking)\n",
        "stacking = StackingClassifier(\n",
        "    estimators=[\n",
        "        ('nb', GaussianNB()),  # Modelo rápido e leve\n",
        "        ('dt', DecisionTreeClassifier(max_depth=3)),  # Árvore de decisão rasa\n",
        "    ],\n",
        "    final_estimator=LogisticRegression(max_iter=100),  # Meta-modelo simples\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Dicionário de classificadores inicial:\n",
        "classifiers = {\n",
        "    'KNN': knn,             # Bayesian Search\n",
        "    'SVM': svm,\n",
        "    'Decision Tree': tree,  # Bayesian Search\n",
        "    'LVQ': lvq,\n",
        "    'MLP': mlp,\n",
        "    'Ensemble Neural Network': ann_ensemble,\n",
        "    'Stacking': stacking,\n",
        "    'Random Forest': rf,    #Optuna\n",
        "    'XGBoost': xgb,         #Optuna\n",
        "    'LightGBM': lgbm\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BAz_-U69MqPw",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "## Tunning Usando Bayesian e Optuna"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Demora em torno de 20 minutos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3ngnvnnMtzQ",
        "outputId": "c78fc699-2f8d-47ee-efd7-5de16c4d4721"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Otimizando hiperparâmetros para KNN...\n",
            "Melhores parâmetros para KNN: OrderedDict([('n_neighbors', 1), ('p', 1), ('weights', 'uniform')])\n",
            "\n",
            "Otimizando hiperparâmetros para Decision Tree...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-29 19:48:03,197] A new study created in memory with name: no-name-826eff76-710c-478d-a669-0fbd49028c59\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Melhores parâmetros para Decision Tree: OrderedDict([('criterion', 'entropy'), ('max_depth', 23), ('min_samples_leaf', 1), ('min_samples_split', 2)])\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-29 19:48:17,452] Trial 0 finished with value: 0.8992910354614712 and parameters: {'n_estimators': 193, 'max_depth': 3}. Best is trial 0 with value: 0.8992910354614712.\n",
            "[I 2024-11-29 19:48:34,052] Trial 1 finished with value: 0.9163927932440276 and parameters: {'n_estimators': 184, 'max_depth': 4}. Best is trial 1 with value: 0.9163927932440276.\n",
            "[I 2024-11-29 19:48:37,421] Trial 2 finished with value: 0.9312780786479065 and parameters: {'n_estimators': 27, 'max_depth': 6}. Best is trial 2 with value: 0.9312780786479065.\n",
            "[I 2024-11-29 19:48:44,445] Trial 3 finished with value: 0.9151254463887959 and parameters: {'n_estimators': 77, 'max_depth': 4}. Best is trial 2 with value: 0.9312780786479065.\n",
            "[I 2024-11-29 19:48:53,656] Trial 4 finished with value: 0.9137323200337766 and parameters: {'n_estimators': 101, 'max_depth': 4}. Best is trial 2 with value: 0.9312780786479065.\n",
            "[I 2024-11-29 19:48:53,658] A new study created in memory with name: no-name-2c764674-3909-4499-9c1e-2380e8ef2342\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Melhores hiperparâmetros para Random Forest: {'n_estimators': 27, 'max_depth': 6}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-29 19:49:02,484] Trial 0 finished with value: 0.984354860330173 and parameters: {'learning_rate': 0.010109829632956214, 'n_estimators': 162, 'max_depth': 10}. Best is trial 0 with value: 0.984354860330173.\n",
            "[I 2024-11-29 19:49:08,434] Trial 1 finished with value: 0.9374208058717434 and parameters: {'learning_rate': 0.0010674513804083954, 'n_estimators': 273, 'max_depth': 5}. Best is trial 0 with value: 0.984354860330173.\n",
            "[I 2024-11-29 19:49:13,559] Trial 2 finished with value: 0.9248158859427964 and parameters: {'learning_rate': 0.006245154718456152, 'n_estimators': 327, 'max_depth': 3}. Best is trial 0 with value: 0.984354860330173.\n",
            "[I 2024-11-29 19:49:36,831] Trial 3 finished with value: 0.9728270527864533 and parameters: {'learning_rate': 0.0013207537282401275, 'n_estimators': 453, 'max_depth': 8}. Best is trial 0 with value: 0.984354860330173.\n",
            "[I 2024-11-29 19:49:40,389] Trial 4 finished with value: 0.9800475345371884 and parameters: {'learning_rate': 0.05372742901459394, 'n_estimators': 62, 'max_depth': 7}. Best is trial 0 with value: 0.984354860330173.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Melhores hiperparâmetros para XGBoost: {'learning_rate': 0.010109829632956214, 'n_estimators': 162, 'max_depth': 10}\n"
          ]
        }
      ],
      "source": [
        "# Usando BS e Optuna em dois classificadores diferentes:\n",
        "\n",
        "# Filtrar warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import logging\n",
        "logging.getLogger('sklearn').setLevel(logging.ERROR)\n",
        "\n",
        "# Configurações para os modelos que costumam gerar warnings\n",
        "import os\n",
        "os.environ['PYTHONWARNINGS'] = 'ignore'\n",
        "\n",
        "# Configurações específicas para XGBoost\n",
        "from xgboost import set_config\n",
        "set_config(verbosity=0)\n",
        "\n",
        "# Espaços de busca para Bayesian Search: KNN e Decision Tree\n",
        "param_spaces = {\n",
        "    'KNN': {\n",
        "        'n_neighbors': (1, 30),\n",
        "        'weights': ['uniform', 'distance'],\n",
        "        'p': (1, 2)\n",
        "    },\n",
        "    'Decision Tree': {\n",
        "        'max_depth': (1, 50),\n",
        "        'min_samples_split': (2, 20),\n",
        "        'min_samples_leaf': (1, 20),\n",
        "        'criterion': ['gini', 'entropy']\n",
        "    }\n",
        "\n",
        "}\n",
        "\n",
        "# Avaliar classificadores e buscar hiperparâmetros com BayesSearchCV\n",
        "results = {}\n",
        "best_params = {}\n",
        "\n",
        "for name, clf in classifiers.items():\n",
        "    if name in param_spaces:\n",
        "        print(f\"Otimizando hiperparâmetros para {name}...\")\n",
        "        bayes_search = BayesSearchCV(\n",
        "            estimator=clf,\n",
        "            search_spaces=param_spaces[name],\n",
        "            n_iter=50,\n",
        "            cv=kfold,\n",
        "            scoring='accuracy',\n",
        "            n_jobs=-1,\n",
        "            random_state=42\n",
        "        )\n",
        "\n",
        "        # Garante que X_train_resampled seja um DataFrame com os nomes de coluna corretos\n",
        "        X_train_resampled = pd.DataFrame(X_train_resampled, columns=X_train.columns)\n",
        "\n",
        "        bayes_search.fit(X_train_resampled, y_train_resampled)\n",
        "        best_params[name] = bayes_search.best_params_\n",
        "        clf = bayes_search.best_estimator_\n",
        "        print(f\"Melhores parâmetros para {name}: {bayes_search.best_params_}\\n\")\n",
        "\n",
        "#Optuna para RF e XGB\n",
        "\n",
        "# Funções de objetivo para Optuna\n",
        "def rf_objective(trial):\n",
        "    n_estimators = trial.suggest_int(\"n_estimators\", 10, 200)\n",
        "    max_depth = trial.suggest_int(\"max_depth\", 2, 32, log=True)\n",
        "    clf = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth)\n",
        "    return cross_val_score(clf, X_train_resampled, y_train_resampled, cv=kfold, scoring=\"accuracy\").mean()\n",
        "\n",
        "def xgb_objective(trial):\n",
        "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-3, 1e-1, log=True)\n",
        "    n_estimators = trial.suggest_int(\"n_estimators\", 50, 500)\n",
        "    max_depth = trial.suggest_int(\"max_depth\", 3, 10)\n",
        "\n",
        "    # Encode the target variable to numeric values\n",
        "    le = LabelEncoder()\n",
        "    y_train_resampled_encoded = le.fit_transform(y_train_resampled)\n",
        "\n",
        "    clf = XGBClassifier(learning_rate=learning_rate, n_estimators=n_estimators,\n",
        "                        max_depth=max_depth, use_label_encoder=False, eval_metric='logloss')\n",
        "    return cross_val_score(clf, X_train_resampled, y_train_resampled_encoded, cv=kfold, scoring=\"accuracy\").mean()\n",
        "\n",
        "# Otimização com Optuna\n",
        "rf_study = optuna.create_study(direction=\"maximize\")\n",
        "rf_study.optimize(rf_objective, n_trials=5)\n",
        "classifiers['Random Forest'] = RandomForestClassifier(**rf_study.best_trial.params)\n",
        "print(\"Melhores hiperparâmetros para Random Forest:\", rf_study.best_trial.params)\n",
        "\n",
        "xgb_study = optuna.create_study(direction=\"maximize\")\n",
        "xgb_study.optimize(xgb_objective, n_trials=5)\n",
        "classifiers['XGBoost'] = XGBClassifier(**xgb_study.best_trial.params, use_label_encoder=False, eval_metric='logloss')\n",
        "print(\"Melhores hiperparâmetros para XGBoost:\", xgb_study.best_trial.params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DNIIQajYi4I"
      },
      "source": [
        "## Resumo Melhores Parâmetros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ULFB9uENYL2-"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parâmetros do XGBoost sem valores None:\n",
            "{'objective': 'binary:logistic', 'enable_categorical': False, 'eval_metric': 'logloss', 'missing': nan, 'use_label_encoder': False}\n"
          ]
        }
      ],
      "source": [
        "# Obter os parâmetros do classificador e remover os que têm valor None\n",
        "xgb_clean_params = {k: v for k, v in classifiers['XGBoost'].get_params().items() if v is not None}\n",
        "\n",
        "# Criar um novo classificador com os parâmetros limpos\n",
        "cleaned_xgb = XGBClassifier(**xgb_clean_params)\n",
        "\n",
        "print(\"Parâmetros do XGBoost sem valores None:\")\n",
        "print(xgb_clean_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Y2Q3OKn7TAG9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classificadores com os melhores parâmetros:\n",
            "KNN: KNeighborsClassifier(n_neighbors=1, p=1)\n",
            "SVM: SVC(probability=True)\n",
            "Decision Tree: DecisionTreeClassifier(criterion='entropy', max_depth=36)\n",
            "LVQ: MLPClassifier(learning_rate_init=0.1, max_iter=100, solver='sgd')\n",
            "MLP: MLPClassifier(hidden_layer_sizes=(50,), max_iter=100)\n",
            "Ensemble Neural Network: VotingClassifier(estimators=[('mlp_relu',\n",
            "                              MLPClassifier(hidden_layer_sizes=(50, 20),\n",
            "                                            max_iter=100)),\n",
            "                             ('mlp_tanh',\n",
            "                              MLPClassifier(activation='tanh',\n",
            "                                            hidden_layer_sizes=(50, 20),\n",
            "                                            max_iter=100)),\n",
            "                             ('mlp_logistic',\n",
            "                              MLPClassifier(activation='logistic',\n",
            "                                            hidden_layer_sizes=(50, 20),\n",
            "                                            max_iter=100))],\n",
            "                 n_jobs=-1, voting='soft')\n",
            "Stacking: StackingClassifier(estimators=[('nb', GaussianNB()),\n",
            "                               ('dt', DecisionTreeClassifier(max_depth=3))],\n",
            "                   final_estimator=LogisticRegression(), n_jobs=-1)\n",
            "Random Forest: RandomForestClassifier(max_depth=28, n_estimators=97)\n",
            "XGBoost: XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
            "              colsample_bylevel=None, colsample_bynode=None,\n",
            "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
            "              enable_categorical=False, eval_metric='logloss',\n",
            "              feature_types=None, gamma=None, grow_policy=None,\n",
            "              importance_type=None, interaction_constraints=None,\n",
            "              learning_rate=0.09504317284612004, max_bin=None,\n",
            "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
            "              max_delta_step=None, max_depth=6, max_leaves=None,\n",
            "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
            "              multi_strategy=None, n_estimators=188, n_jobs=None,\n",
            "              num_parallel_tree=None, random_state=None, ...)\n",
            "LightGBM: LGBMClassifier(max_depth=3, n_estimators=50, verbose=-1)\n"
          ]
        }
      ],
      "source": [
        "# Converter parâmetros otimizados para inicializar os classificadores\n",
        "best_classifiers = {\n",
        "    'KNN': KNeighborsClassifier(n_neighbors=1, p=1, weights='uniform'), # Otimizado com Bayesian Search\n",
        "    'SVM': svm,  # Nenhuma otimização aplicada\n",
        "    'Decision Tree': DecisionTreeClassifier(criterion='entropy', max_depth=36, min_samples_leaf=1, min_samples_split=2), # Otimizado com Bayesian Search\n",
        "    'LVQ': lvq,  # Nenhuma otimização aplicada\n",
        "    'MLP': mlp,  # Nenhuma otimização aplicada\n",
        "    'Ensemble Neural Network': ann_ensemble,  # Nenhuma otimização aplicada\n",
        "    'Stacking': stacking,  # Nenhuma otimização aplicada\n",
        "    'Random Forest': RandomForestClassifier(max_depth=28, n_estimators=97), # Otimizado com Optuna\n",
        "    'XGBoost': XGBClassifier(objective='binary:logistic', enable_categorical=False, eval_metric='logloss',\n",
        "                             learning_rate=0.09504317284612004, max_depth=6, n_estimators=188),  # Otimizado com Optuna\n",
        "    'LightGBM': lgbm # Nenhuma otimização aplicada\n",
        "}\n",
        "\n",
        "# Mostrar os melhores parâmetros para os classificadores otimizados\n",
        "print(\"Classificadores com os melhores parâmetros:\")\n",
        "\n",
        "for name, model in best_classifiers.items():\n",
        "  print(f\"{name}: {model}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZsvC5TygOx46"
      },
      "source": [
        "## Avaliando os modelos após Tunning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JREgrxR2pm5B"
      },
      "source": [
        "- Demora em torno de 20 minutos\n",
        "*   Avalia os modelos após o tunning usando Optuna e Bayesian Search (dicionário anterior)\n",
        "*   Calcula o tempo de execução e consumo de memória para cada modelo.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Definição das funções\n",
        "import time\n",
        "from memory_profiler import memory_usage\n",
        "import psutil\n",
        "import GPUtil\n",
        "import warnings\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, f1_score, recall_score, confusion_matrix\n",
        "from sklearn.model_selection import cross_validate\n",
        "\n",
        "# Filtrar warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Definindo os classificadores otimizados com os melhores parâmetros\n",
        "classifiers = best_classifiers\n",
        "\n",
        "def calculate_acsa(y_true, y_pred):\n",
        "    classes = np.unique(y_true)\n",
        "    class_accuracies = [\n",
        "        accuracy_score(y_true[y_true == c], y_pred[y_true == c]) for c in classes\n",
        "    ]\n",
        "    return np.mean(class_accuracies)\n",
        "\n",
        "def get_gpu_usage():\n",
        "    \"\"\"\n",
        "    Obtém o uso da GPU se disponível.\n",
        "    \"\"\"\n",
        "    gpus = GPUtil.getGPUs()\n",
        "    if not gpus:\n",
        "        return 0  # Sem GPU disponível\n",
        "    return sum([gpu.load for gpu in gpus]) / len(gpus) * 100  # Média de uso em %\n",
        "\n",
        "def evaluate_model(model, X, y, kfold):\n",
        "    \"\"\"\n",
        "    Avalia o modelo com métricas de desempenho e recursos computacionais (tempo, memória, CPU e GPU).\n",
        "    \"\"\"\n",
        "\n",
        "    # Converter para array numpy se for DataFrame/Series\n",
        "    X_numpy = X.values if hasattr(X, 'values') else X\n",
        "    y_numpy = y.values if hasattr(y, 'values') else y\n",
        "\n",
        "    # Iniciar medição de tempo, memória, CPU e GPU\n",
        "    start_time = time.time()\n",
        "    mem_usage_start = memory_usage()[0]\n",
        "    cpu_start = psutil.cpu_percent(interval=None)\n",
        "    gpu_start = get_gpu_usage()\n",
        "\n",
        "    # Usar cross_validate para calcular accuracy, f1 e recall em uma única chamada\n",
        "    scoring = ['accuracy', 'f1', 'recall']\n",
        "    scores = cross_validate(model, X_numpy, y_numpy, cv=kfold, scoring=scoring, return_estimator=True)\n",
        "\n",
        "    # Calcular tempo, memória, CPU e GPU após validação cruzada\n",
        "    training_time = time.time() - start_time\n",
        "    mem_usage_end = memory_usage()[0]\n",
        "    memory_consumed = mem_usage_end - mem_usage_start\n",
        "    cpu_end = psutil.cpu_percent(interval=None)\n",
        "    gpu_end = get_gpu_usage()\n",
        "\n",
        "    # Calcular média de uso de CPU e GPU\n",
        "    cpu_usage = (cpu_end + cpu_start) / 2\n",
        "    gpu_usage = (gpu_end + gpu_start) / 2\n",
        "\n",
        "    # Métricas médias da validação cruzada\n",
        "    accuracy = scores['test_accuracy'].mean()\n",
        "    f1 = scores['test_f1'].mean()\n",
        "    recall = scores['test_recall'].mean()\n",
        "\n",
        "    # Cálculo do ACSA manualmente\n",
        "    acsa_scores = []\n",
        "    for estimator, (train_idx, val_idx) in zip(scores['estimator'], kfold.split(X_numpy, y_numpy)):\n",
        "        X_val_fold = X_numpy[val_idx]\n",
        "        y_val_fold = y_numpy[val_idx]\n",
        "        y_pred_fold = estimator.predict(X_val_fold)\n",
        "        acsa_scores.append(calculate_acsa(y_val_fold, y_pred_fold))\n",
        "    acsa = np.mean(acsa_scores)\n",
        "\n",
        "    # Ajustar modelo nos dados completos e calcular a matriz de confusão\n",
        "    model.fit(X_numpy, y_numpy)\n",
        "    y_pred = model.predict(X_numpy)\n",
        "    conf_matrix = confusion_matrix(y_numpy, y_pred)\n",
        "\n",
        "    return accuracy, f1, recall, acsa, conf_matrix, training_time, memory_consumed, cpu_usage, gpu_usage\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "SjxnZ3mO_K-g"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "KNN - Accuracy: 0.9791, F1 Score: 0.9789, Recall: 0.9592, ACSA: 0.9793, Training Time (s): 2.7135, Memory Usage (MB): 35.5039, CPU Usage (%): 19.75, GPU Usage (%): 0.00\n",
            "Confusion Matrix:\n",
            "[[7821    0]\n",
            " [   0 7967]]\n",
            "\n",
            "SVM - Accuracy: 0.9680, F1 Score: 0.9673, Recall: 0.9386, ACSA: 0.9683, Training Time (s): 239.5132, Memory Usage (MB): -158.7734, CPU Usage (%): 29.15, GPU Usage (%): 0.00\n",
            "Confusion Matrix:\n",
            "[[7814    7]\n",
            " [ 461 7506]]\n",
            "\n",
            "Decision Tree - Accuracy: 0.9844, F1 Score: 0.9845, Recall: 0.9803, ACSA: 0.9845, Training Time (s): 1.8928, Memory Usage (MB): 3.8828, CPU Usage (%): 14.60, GPU Usage (%): 0.00\n",
            "Confusion Matrix:\n",
            "[[7821    0]\n",
            " [   0 7967]]\n",
            "\n",
            "LVQ - Accuracy: 0.9935, F1 Score: 0.9936, Recall: 0.9908, ACSA: 0.9936, Training Time (s): 68.5304, Memory Usage (MB): -36.6211, CPU Usage (%): 10.35, GPU Usage (%): 0.00\n",
            "Confusion Matrix:\n",
            "[[7817    4]\n",
            " [  22 7945]]\n",
            "\n",
            "MLP - Accuracy: 0.9902, F1 Score: 0.9902, Recall: 0.9843, ACSA: 0.9902, Training Time (s): 40.8061, Memory Usage (MB): 1.2891, CPU Usage (%): 22.20, GPU Usage (%): 0.00\n",
            "Confusion Matrix:\n",
            "[[7804   17]\n",
            " [  66 7901]]\n",
            "\n",
            "Ensemble Neural Network - Accuracy: 0.9942, F1 Score: 0.9942, Recall: 0.9900, ACSA: 0.9942, Training Time (s): 155.9444, Memory Usage (MB): -54.4570, CPU Usage (%): 19.65, GPU Usage (%): 0.00\n",
            "Confusion Matrix:\n",
            "[[7820    1]\n",
            " [  10 7957]]\n",
            "\n",
            "Stacking - Accuracy: 0.8867, F1 Score: 0.8892, Recall: 0.9030, ACSA: 0.8865, Training Time (s): 4.5069, Memory Usage (MB): 11.9648, CPU Usage (%): 18.70, GPU Usage (%): 0.00\n",
            "Confusion Matrix:\n",
            "[[6682 1139]\n",
            " [ 598 7369]]\n",
            "\n",
            "Random Forest - Accuracy: 0.9909, F1 Score: 0.9910, Recall: 0.9859, ACSA: 0.9910, Training Time (s): 25.3181, Memory Usage (MB): 43.5391, CPU Usage (%): 14.25, GPU Usage (%): 0.00\n",
            "Confusion Matrix:\n",
            "[[7821    0]\n",
            " [   0 7967]]\n",
            "\n",
            "XGBoost - Accuracy: 0.9908, F1 Score: 0.9908, Recall: 0.9853, ACSA: 0.9909, Training Time (s): 7.0045, Memory Usage (MB): 28.5703, CPU Usage (%): 52.10, GPU Usage (%): 0.00\n",
            "Confusion Matrix:\n",
            "[[7819    2]\n",
            " [  15 7952]]\n",
            "\n",
            "LightGBM - Accuracy: 0.9457, F1 Score: 0.9442, Recall: 0.9101, ACSA: 0.9461, Training Time (s): 1.6499, Memory Usage (MB): -4.1836, CPU Usage (%): 60.90, GPU Usage (%): 0.00\n",
            "Confusion Matrix:\n",
            "[[7712  109]\n",
            " [ 709 7258]]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Uso do código\n",
        "results = {}\n",
        "for name, clf in best_classifiers.items():\n",
        "    # Avaliar desempenho do classificador\n",
        "    accuracy, f1, recall, acsa, conf_matrix, training_time, memory_consumed, cpu_usage, gpu_usage = evaluate_model(clf, X_train_resampled, y_train_resampled, kfold)\n",
        "\n",
        "    results[name] = {\n",
        "        'Accuracy': accuracy,\n",
        "        'F1 Score': f1,\n",
        "        'Recall': recall,\n",
        "        'ACSA': acsa,\n",
        "        'Training Time (s)': training_time,\n",
        "        'Memory Usage (MB)': memory_consumed,\n",
        "        'CPU Usage (%)': cpu_usage,\n",
        "        'GPU Usage (%)': gpu_usage,\n",
        "        'Confusion Matrix': conf_matrix\n",
        "    }\n",
        "\n",
        "    print(f\"{name} - Accuracy: {accuracy:.4f}, F1 Score: {f1:.4f}, Recall: {recall:.4f}, ACSA: {acsa:.4f}, Training Time (s): {training_time:.4f}, Memory Usage (MB): {memory_consumed:.4f}, CPU Usage (%): {cpu_usage:.2f}, GPU Usage (%): {gpu_usage:.2f}\")\n",
        "    print(f\"Confusion Matrix:\\n{conf_matrix}\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "1PwfWABKthgx"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Score</th>\n",
              "      <th>Recall</th>\n",
              "      <th>ACSA</th>\n",
              "      <th>Training Time (s)</th>\n",
              "      <th>Memory Usage (MB)</th>\n",
              "      <th>CPU Usage (%)</th>\n",
              "      <th>GPU Usage (%)</th>\n",
              "      <th>Confusion Matrix</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>KNN</th>\n",
              "      <td>0.979098</td>\n",
              "      <td>0.978856</td>\n",
              "      <td>0.959209</td>\n",
              "      <td>0.979285</td>\n",
              "      <td>4.140716</td>\n",
              "      <td>35.933594</td>\n",
              "      <td>44.90</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[[7821, 0], [0, 7967]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SVM</th>\n",
              "      <td>0.968014</td>\n",
              "      <td>0.967327</td>\n",
              "      <td>0.938623</td>\n",
              "      <td>0.968288</td>\n",
              "      <td>247.687245</td>\n",
              "      <td>55.996094</td>\n",
              "      <td>28.25</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[[7814, 7], [461, 7506]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Decision Tree</th>\n",
              "      <td>0.983975</td>\n",
              "      <td>0.984058</td>\n",
              "      <td>0.980167</td>\n",
              "      <td>0.984011</td>\n",
              "      <td>1.791338</td>\n",
              "      <td>2.535156</td>\n",
              "      <td>14.75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[[7821, 0], [0, 7967]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LVQ</th>\n",
              "      <td>0.994046</td>\n",
              "      <td>0.994080</td>\n",
              "      <td>0.990837</td>\n",
              "      <td>0.994076</td>\n",
              "      <td>92.532249</td>\n",
              "      <td>-47.816406</td>\n",
              "      <td>7.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[[7816, 5], [20, 7947]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MLP</th>\n",
              "      <td>0.990309</td>\n",
              "      <td>0.990342</td>\n",
              "      <td>0.984687</td>\n",
              "      <td>0.990362</td>\n",
              "      <td>46.456718</td>\n",
              "      <td>28.582031</td>\n",
              "      <td>20.85</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[[7813, 8], [61, 7906]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ensemble Neural Network</th>\n",
              "      <td>0.994236</td>\n",
              "      <td>0.994266</td>\n",
              "      <td>0.990336</td>\n",
              "      <td>0.994273</td>\n",
              "      <td>124.469784</td>\n",
              "      <td>-121.117188</td>\n",
              "      <td>21.70</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[[7820, 1], [16, 7951]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Stacking</th>\n",
              "      <td>0.886687</td>\n",
              "      <td>0.889236</td>\n",
              "      <td>0.902975</td>\n",
              "      <td>0.886532</td>\n",
              "      <td>4.123944</td>\n",
              "      <td>-16.515625</td>\n",
              "      <td>27.70</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[[6682, 1139], [598, 7369]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Random Forest</th>\n",
              "      <td>0.991069</td>\n",
              "      <td>0.991104</td>\n",
              "      <td>0.986192</td>\n",
              "      <td>0.991114</td>\n",
              "      <td>22.565561</td>\n",
              "      <td>59.781250</td>\n",
              "      <td>20.65</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[[7821, 0], [0, 7967]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>XGBoost</th>\n",
              "      <td>0.990816</td>\n",
              "      <td>0.990845</td>\n",
              "      <td>0.985313</td>\n",
              "      <td>0.990867</td>\n",
              "      <td>5.662494</td>\n",
              "      <td>61.640625</td>\n",
              "      <td>54.05</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[[7819, 2], [15, 7952]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LightGBM</th>\n",
              "      <td>0.945718</td>\n",
              "      <td>0.944180</td>\n",
              "      <td>0.910131</td>\n",
              "      <td>0.946052</td>\n",
              "      <td>1.145050</td>\n",
              "      <td>1.058594</td>\n",
              "      <td>65.15</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[[7712, 109], [709, 7258]]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                         Accuracy  F1 Score    Recall      ACSA  \\\n",
              "KNN                      0.979098  0.978856  0.959209  0.979285   \n",
              "SVM                      0.968014  0.967327  0.938623  0.968288   \n",
              "Decision Tree            0.983975  0.984058  0.980167  0.984011   \n",
              "LVQ                      0.994046  0.994080  0.990837  0.994076   \n",
              "MLP                      0.990309  0.990342  0.984687  0.990362   \n",
              "Ensemble Neural Network  0.994236  0.994266  0.990336  0.994273   \n",
              "Stacking                 0.886687  0.889236  0.902975  0.886532   \n",
              "Random Forest            0.991069  0.991104  0.986192  0.991114   \n",
              "XGBoost                  0.990816  0.990845  0.985313  0.990867   \n",
              "LightGBM                 0.945718  0.944180  0.910131  0.946052   \n",
              "\n",
              "                         Training Time (s)  Memory Usage (MB)  CPU Usage (%)  \\\n",
              "KNN                               4.140716          35.933594          44.90   \n",
              "SVM                             247.687245          55.996094          28.25   \n",
              "Decision Tree                     1.791338           2.535156          14.75   \n",
              "LVQ                              92.532249         -47.816406           7.00   \n",
              "MLP                              46.456718          28.582031          20.85   \n",
              "Ensemble Neural Network         124.469784        -121.117188          21.70   \n",
              "Stacking                          4.123944         -16.515625          27.70   \n",
              "Random Forest                    22.565561          59.781250          20.65   \n",
              "XGBoost                           5.662494          61.640625          54.05   \n",
              "LightGBM                          1.145050           1.058594          65.15   \n",
              "\n",
              "                         GPU Usage (%)             Confusion Matrix  \n",
              "KNN                                0.0       [[7821, 0], [0, 7967]]  \n",
              "SVM                                0.0     [[7814, 7], [461, 7506]]  \n",
              "Decision Tree                      0.0       [[7821, 0], [0, 7967]]  \n",
              "LVQ                                0.0      [[7816, 5], [20, 7947]]  \n",
              "MLP                                0.0      [[7813, 8], [61, 7906]]  \n",
              "Ensemble Neural Network            0.0      [[7820, 1], [16, 7951]]  \n",
              "Stacking                           0.0  [[6682, 1139], [598, 7369]]  \n",
              "Random Forest                      0.0       [[7821, 0], [0, 7967]]  \n",
              "XGBoost                            0.0      [[7819, 2], [15, 7952]]  \n",
              "LightGBM                           0.0   [[7712, 109], [709, 7258]]  "
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Exibir resultados\n",
        "import pandas as pd\n",
        "df_results = pd.DataFrame.from_dict(results, orient='index')\n",
        "\n",
        "# Salvar em Excel\n",
        "df_results.to_excel('results_with_cost_benefit.xlsx')\n",
        "\n",
        "# Apresentar\n",
        "df_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lroaa666bSO"
      },
      "source": [
        "## Comparando Antes e Depois ADASYN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "777Kseeu6ljM"
      },
      "source": [
        "Comparando os desempenhos do treinamento dos classificadores KNN e Árvore de Decisão antes e depois de aplicar o balanceamento de classes usando a técnica ADASYN."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "gSeHtMSE616z"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      Classifier   Phase  Accuracy  F1 Score    Recall      ACSA\n",
            "0            KNN   Antes  0.964083  0.972762  0.966113  0.963098\n",
            "1            KNN  Depois  0.979098  0.978856  0.959209  0.979285\n",
            "2  Decision Tree   Antes  0.978917  0.984123  0.983934  0.976472\n",
            "3  Decision Tree  Depois  0.985305  0.985389  0.981800  0.985338\n",
            "4            MLP   Antes  0.988250  0.991168  0.992720  0.986071\n",
            "5            MLP  Depois  0.989993  0.990028  0.984561  0.990043\n"
          ]
        }
      ],
      "source": [
        "# Classificadores após o Tunning\n",
        "\n",
        "adasyn_classifiers = {\n",
        "    'KNN': KNeighborsClassifier(n_neighbors=1, p=1, weights='uniform'), # Otimizado com Bayesian Search\n",
        "    'Decision Tree': DecisionTreeClassifier(criterion='entropy', max_depth=36, min_samples_leaf=1, min_samples_split=2), # Otimizado com Bayesian Search\n",
        "    'MLP': mlp  # Nenhuma otimização aplicada\n",
        "}\n",
        "\n",
        "# Dicionário para armazenar os resultados\n",
        "results_adasyn = {\n",
        "    'Classifier': [],\n",
        "    'Phase': [],  # 'Antes' ou 'Depois' o balanceamento\n",
        "    'Accuracy': [],\n",
        "    'F1 Score': [],\n",
        "    'Recall': [],\n",
        "    'ACSA': []\n",
        "}\n",
        "\n",
        "# Iterando no dicionário de classificadores\n",
        "for name, clf in adasyn_classifiers.items():\n",
        "    # Avaliação antes do balanceamento\n",
        "    accuracy, f1, recall, acsa, conf_matrix, training_time, memory_consumed, cpu_usage, gpu_usage = evaluate_model(clf, X_train, y_train, kfold)\n",
        "    results_adasyn['Classifier'].append(name)\n",
        "    results_adasyn['Phase'].append('Antes')\n",
        "    results_adasyn['Accuracy'].append(accuracy)\n",
        "    results_adasyn['F1 Score'].append(f1)\n",
        "    results_adasyn['Recall'].append(recall)\n",
        "    results_adasyn['ACSA'].append(acsa)\n",
        "\n",
        "    # Avaliação após o balanceamento\n",
        "    accuracy, f1, recall, acsa, conf_matrix, training_time, memory_consumed, cpu_usage, gpu_usage = evaluate_model(clf, X_train_resampled, y_train_resampled, kfold)\n",
        "    results_adasyn['Classifier'].append(name)\n",
        "    results_adasyn['Phase'].append('Depois')\n",
        "    results_adasyn['Accuracy'].append(accuracy)\n",
        "    results_adasyn['F1 Score'].append(f1)\n",
        "    results_adasyn['Recall'].append(recall)\n",
        "    results_adasyn['ACSA'].append(acsa)\n",
        "\n",
        "# Conversão para um DataFrame\n",
        "df_results_adasyn = pd.DataFrame(results_adasyn)\n",
        "\n",
        "# Exibição do DataFrame\n",
        "print(df_results_adasyn)\n",
        "\n",
        "# Salvar o DataFrame em um arquivo Excel\n",
        "df_results_adasyn.to_excel('results_adasyn_comparison.xlsx', index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ik5UYhwsLZEL"
      },
      "source": [
        "## Desempenho Treino e Teste após Tunning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Demora 20 minutos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "aHAjbN64Leno"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                 Classifier        Etapa  Accuracy  F1 Score    Recall  \\\n",
            "0                       KNN  Treinamento  0.979098  0.978856  0.959209   \n",
            "1                       KNN        Teste  0.942667  0.956500  0.950807   \n",
            "2                       SVM  Treinamento  0.968014  0.967327  0.938623   \n",
            "3                       SVM        Teste  0.948000  0.961662  0.980925   \n",
            "4             Decision Tree  Treinamento  0.984609  0.984690  0.980921   \n",
            "5             Decision Tree        Teste  0.962333  0.971685  0.973379   \n",
            "6                       LVQ  Treinamento  0.994490  0.994522  0.991339   \n",
            "7                       LVQ        Teste  0.978667  0.984041  0.988457   \n",
            "8                       MLP  Treinamento  0.989803  0.989829  0.983558   \n",
            "9                       MLP        Teste  0.973000  0.979826  0.986952   \n",
            "10  Ensemble Neural Network  Treinamento  0.994173  0.994204  0.990336   \n",
            "11  Ensemble Neural Network        Teste  0.974333  0.980810  0.987952   \n",
            "12                 Stacking  Treinamento  0.886687  0.889236  0.902975   \n",
            "13                 Stacking        Teste  0.921667  0.941995  0.957332   \n",
            "14            Random Forest  Treinamento  0.990752  0.990790  0.985691   \n",
            "15            Random Forest        Teste  0.967000  0.975527  0.988457   \n",
            "16                  XGBoost  Treinamento  0.990816  0.990845  0.985313   \n",
            "17                  XGBoost        Teste  0.977667  0.983267  0.987450   \n",
            "18                 LightGBM  Treinamento  0.945718  0.944180  0.910131   \n",
            "19                 LightGBM        Teste  0.952667  0.964626  0.971894   \n",
            "\n",
            "        ACSA  \n",
            "0   0.979285  \n",
            "1   0.938715  \n",
            "2   0.968288  \n",
            "3   0.931913  \n",
            "4   0.984643  \n",
            "5   0.956927  \n",
            "6   0.994519  \n",
            "7   0.973887  \n",
            "8   0.989861  \n",
            "9   0.966189  \n",
            "10  0.994209  \n",
            "11  0.967689  \n",
            "12  0.886532  \n",
            "13  0.904255  \n",
            "14  0.990800  \n",
            "15  0.956516  \n",
            "16  0.990867  \n",
            "17  0.972893  \n",
            "18  0.946052  \n",
            "19  0.943284  \n"
          ]
        }
      ],
      "source": [
        "# Converter parâmetros otimizados para inicializar os classificadores\n",
        "best_classifiers = {\n",
        "    'KNN': KNeighborsClassifier(n_neighbors=1, p=1, weights='uniform'), # Otimizado com Bayesian Search\n",
        "    'SVM': svm,  # Nenhuma otimização aplicada\n",
        "    'Decision Tree': DecisionTreeClassifier(criterion='entropy', max_depth=36, min_samples_leaf=1, min_samples_split=2), # Otimizado com Bayesian Search\n",
        "    'LVQ': lvq,  # Nenhuma otimização aplicada\n",
        "    'MLP': mlp,  # Nenhuma otimização aplicada\n",
        "    'Ensemble Neural Network': ann_ensemble,  # Nenhuma otimização aplicada\n",
        "    'Stacking': stacking,  # Nenhuma otimização aplicada\n",
        "    'Random Forest': RandomForestClassifier(max_depth=28, n_estimators=97), # Otimizado com Optuna\n",
        "    'XGBoost': XGBClassifier(objective='binary:logistic', enable_categorical=False, eval_metric='logloss',\n",
        "                             learning_rate=0.09504317284612004, max_depth=6, n_estimators=188),  # Otimizado com Optuna\n",
        "    'LightGBM': lgbm # Nenhuma otimização aplicada\n",
        "}\n",
        "\n",
        "# Configurar K-Fold com estratificação\n",
        "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# Dicionário para armazenar os resultados\n",
        "results_train_teste = {\n",
        "    'Classifier': [],\n",
        "    'Etapa': [],  # 'Antes' ou 'Depois' o balanceamento\n",
        "    'Accuracy': [],\n",
        "    'F1 Score': [],\n",
        "    'Recall': [],\n",
        "    'ACSA': []\n",
        "}\n",
        "\n",
        "# Iterando no dicionário de classificadores\n",
        "for name, clf in best_classifiers.items():\n",
        "    # Avaliação antes do balanceamento\n",
        "    accuracy, f1, recall, acsa, conf_matrix, training_time, memory_consumed, cpu_usage, gpu_usage = evaluate_model(clf, X_train_resampled, y_train_resampled, kfold)\n",
        "    results_train_teste['Classifier'].append(name)\n",
        "    results_train_teste['Etapa'].append('Treinamento')\n",
        "    results_train_teste['Accuracy'].append(accuracy)\n",
        "    results_train_teste['F1 Score'].append(f1)\n",
        "    results_train_teste['Recall'].append(recall)\n",
        "    results_train_teste['ACSA'].append(acsa)\n",
        "\n",
        "    # Avaliação após o balanceamento\n",
        "    accuracy, f1, recall, acsa, conf_matrix, training_time, memory_consumed, cpu_usage, gpu_usage = evaluate_model(clf, X_test, y_test, kfold)\n",
        "    results_train_teste['Classifier'].append(name)\n",
        "    results_train_teste['Etapa'].append('Teste')\n",
        "    results_train_teste['Accuracy'].append(accuracy)\n",
        "    results_train_teste['F1 Score'].append(f1)\n",
        "    results_train_teste['Recall'].append(recall)\n",
        "    results_train_teste['ACSA'].append(acsa)\n",
        "\n",
        "# Conversão para um DataFrame\n",
        "df_results_train_teste = pd.DataFrame(results_train_teste)\n",
        "\n",
        "# Exibição do DataFrame\n",
        "print(df_results_train_teste)\n",
        "\n",
        "# Salvar o DataFrame em um arquivo Excel\n",
        "df_results_train_teste.to_excel('results_train_teste_comparison.xlsx', index=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGeDInlGjm2L"
      },
      "source": [
        "## Amostra para análise Estatística"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "uTcxxjHKk6Oo",
        "outputId": "4b89cc82-d8e0-451c-d5a7-2abb6d4328fe"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "import logging\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, f1_score, recall_score, confusion_matrix\n",
        "from xgboost import set_config\n",
        "\n",
        "# Filtrar warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "logging.getLogger('sklearn').setLevel(logging.ERROR)\n",
        "os.environ['PYTHONWARNINGS'] = 'ignore'\n",
        "set_config(verbosity=0)\n",
        "\n",
        "# Definindo os classificadores otimizados com os melhores parâmetros\n",
        "classifiers = best_classifiers\n",
        "\n",
        "def calculate_acsa(y_true, y_pred):\n",
        "    \"\"\"Calcula o Average Class-Specific Accuracy (ACSA).\"\"\"\n",
        "    classes = np.unique(y_true)\n",
        "    class_accuracies = [\n",
        "        accuracy_score(y_true[y_true == c], y_pred[y_true == c]) for c in classes\n",
        "    ]\n",
        "    return np.mean(class_accuracies)\n",
        "\n",
        "def evaluate_model(model, X, y, kfold, n_samples=10):\n",
        "    \"\"\"\n",
        "    Avalia o modelo usando validação cruzada múltiplas vezes.\n",
        "    Args:\n",
        "    model: Modelo de classificação\n",
        "    X: Features (DataFrame ou array)\n",
        "    y: Target (Series ou array)\n",
        "    kfold: Objeto de validação cruzada\n",
        "    n_samples: Número de iterações de avaliação\n",
        "    \"\"\"\n",
        "    # Converter para numpy arrays se necessário\n",
        "    X_numpy = X.values if hasattr(X, 'values') else np.array(X)\n",
        "    y_numpy = y.values if hasattr(y, 'values') else np.array(y)\n",
        "    results = {\n",
        "        'Accuracy': [],\n",
        "        'F1 Score': [],\n",
        "        'Recall': [],\n",
        "        'ACSA': [],\n",
        "        'Confusion Matrix': []\n",
        "    }\n",
        "    for sample in range(n_samples):\n",
        "        try:\n",
        "            # Realizando a validação cruzada\n",
        "            scores = cross_validate(\n",
        "                model,\n",
        "                X_numpy,\n",
        "                y_numpy,\n",
        "                cv=kfold,\n",
        "                scoring=['accuracy', 'f1', 'recall'],\n",
        "                return_estimator=True,\n",
        "                n_jobs=-1 # Usar todos os cores disponíveis\n",
        "            )\n",
        "            # Métricas médias da validação cruzada\n",
        "            results['Accuracy'].append(scores['test_accuracy'].mean())\n",
        "            results['F1 Score'].append(scores['test_f1'].mean())\n",
        "            results['Recall'].append(scores['test_recall'].mean())\n",
        "            # Cálculo do ACSA\n",
        "            acsa_scores = []\n",
        "            for estimator, (_, val_idx) in zip(scores['estimator'], kfold.split(X_numpy, y_numpy)):\n",
        "                X_val = X_numpy[val_idx]\n",
        "                y_val = y_numpy[val_idx]\n",
        "                y_pred = estimator.predict(X_val)\n",
        "                acsa_scores.append(calculate_acsa(y_val, y_pred))\n",
        "            results['ACSA'].append(np.mean(acsa_scores))\n",
        "            # Matriz de confusão usando o último modelo ajustado\n",
        "            model.fit(X_numpy, y_numpy)\n",
        "            y_pred_final = model.predict(X_numpy)\n",
        "            results['Confusion Matrix'].append(confusion_matrix(y_numpy, y_pred_final))\n",
        "        except Exception as e:\n",
        "            print(f\"Erro na amostra {sample}: {str(e)}\")\n",
        "            continue\n",
        "    return results\n",
        "\n",
        "def print_results(results_dict):\n",
        "    \"\"\"Imprime os resultados de forma organizada e gera DataFrames.\"\"\"\n",
        "    metrics_dfs = {metric: pd.DataFrame() for metric in ['Accuracy', 'F1 Score', 'Recall', 'ACSA']}\n",
        "\n",
        "    for name, metrics in results_dict.items():\n",
        "        print(f\"\\n{'='*50}\")\n",
        "        print(f\"Resultados para {name}:\")\n",
        "        print(f\"{'='*50}\")\n",
        "        # Métricas numéricas\n",
        "        for metric in ['Accuracy', 'F1 Score', 'Recall', 'ACSA']:\n",
        "            values = metrics[metric]\n",
        "            if values: # Verifica se há valores\n",
        "                print(f\"\\n{metric}:\")\n",
        "                for value in values:\n",
        "                    print(f\" {value:.4f}\")\n",
        "                # Adiciona os resultados ao DataFrame correspondente\n",
        "                metrics_dfs[metric][name] = values\n",
        "\n",
        "    # Retorna os DataFrames\n",
        "    return metrics_dfs\n",
        "\n",
        "def save_to_excel(metrics_dfs, filename='metrics_results.xlsx'):\n",
        "    \"\"\"Salva os DataFrames em uma planilha Excel, com cada aba representando uma métrica distinta.\"\"\"\n",
        "    with pd.ExcelWriter(filename) as writer:\n",
        "        for metric, df in metrics_dfs.items():\n",
        "            df.to_excel(writer, sheet_name=metric)\n",
        "\n",
        "# Uso do código\n",
        "if __name__ == \"__main__\":\n",
        "    # Definindo a validação cruzada\n",
        "    kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=None)\n",
        "    # Inicializando resultados\n",
        "    results = {}\n",
        "    # Avaliando cada classificador\n",
        "    for name, clf in classifiers.items():\n",
        "        print(f\"\\nAvaliando {name}...\")\n",
        "        results[name] = evaluate_model(\n",
        "            clf,\n",
        "            X_train_resampled,\n",
        "            y_train_resampled,\n",
        "            kfold,\n",
        "            n_samples=10\n",
        "        )\n",
        "    # Imprimindo resultados e gerando DataFrames\n",
        "    metrics_dfs = print_results(results)\n",
        "\n",
        "    # Salvando os DataFrames em uma planilha Excel\n",
        "    save_to_excel(metrics_dfs)\n",
        "\n",
        "    # Exemplo de como acessar os DataFrames\n",
        "    accuracy_df = metrics_dfs['Accuracy']\n",
        "    f1_score_df = metrics_dfs['F1 Score']\n",
        "    recall_df = metrics_dfs['Recall']\n",
        "    acsa_df = metrics_dfs['ACSA']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0WVIGz29R7P_"
      },
      "outputs": [],
      "source": [
        "save_to_excel(metrics_dfs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOm8zAO4KJLA"
      },
      "source": [
        "## Teste de Estresse novos dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Gerando dados sintéticos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "hspEQcvVNI7l"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exemplo de dados sintéticos:\n",
            "         f1        f2        f3        f4        f5        f6        f7  \\\n",
            "0 -3.269112  3.513117 -0.529201 -0.932867  0.536414 -2.790119 -0.869287   \n",
            "1  4.321401 -1.526260 -0.692351 -1.781169 -0.273729 -1.907548 -0.659039   \n",
            "2 -2.211783 -4.441093  0.051198 -1.974622 -0.213457  0.847032 -0.501784   \n",
            "3 -4.923394  4.344866 -2.132596  0.117327  1.452617 -1.079046  1.012637   \n",
            "4  4.372500 -2.568167 -0.385022 -1.694910 -0.936506 -0.958699  0.382989   \n",
            "\n",
            "         f8        f9       f13  ...       f24       f25       f26       f27  \\\n",
            "0 -3.719915 -0.211384  1.033881  ...  2.644457  0.907962  0.123480 -0.798858   \n",
            "1  1.883620  0.392634 -0.014270  ...  1.787822  0.097827  0.436006 -0.417870   \n",
            "2 -1.866255 -0.048089  0.496199  ...  2.296966  0.511500  1.935154  0.051362   \n",
            "3 -1.152980  1.352203 -0.916321  ...  3.351479 -0.140375  0.307613  0.959610   \n",
            "4  0.100247 -0.606865 -0.667780  ... -4.048788 -0.187329 -2.238231 -1.220818   \n",
            "\n",
            "        f28       f29       f30       f31       f32       f33  \n",
            "0 -0.852225 -1.174514  2.275825  5.605097 -1.551209  0.009613  \n",
            "1  0.479508  3.028572  0.050228  2.044662  0.917148  1.601615  \n",
            "2 -0.627313  0.991862  1.180641  1.013767 -4.379881 -1.364261  \n",
            "3 -1.315816  2.031906 -1.435910  0.315642 -1.017634 -4.803853  \n",
            "4 -0.526248  0.022906 -0.499730 -0.634299  0.881883  2.908487  \n",
            "\n",
            "[5 rows x 30 columns]\n",
            "\n",
            "Distribuição das classes:\n",
            "target\n",
            "1    100\n",
            "0    100\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Gerar Dados Sintéticos\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "def generate_synthetic_data(n_samples=200, n_features=30, n_informative=10, n_redundant=5, feature_names=None, random_state=42):\n",
        "    \"\"\"\n",
        "    Gera dados sintéticos para teste de estresse de classificadores.\n",
        "\n",
        "    Args:\n",
        "    n_samples (int): Número de amostras.\n",
        "    n_features (int): Número total de características.\n",
        "    n_informative (int): Número de características informativas.\n",
        "    n_redundant (int): Número de características redundantes.\n",
        "    feature_names (list): Lista de nomes para as colunas geradas.\n",
        "    random_state (int): Semente para reprodutibilidade.\n",
        "\n",
        "    Returns:\n",
        "    X_synthetic (DataFrame): Dados de entrada sintéticos.\n",
        "    y_synthetic (Series): Classes correspondentes.\n",
        "    \"\"\"\n",
        "    # Gerar dados\n",
        "    X, y = make_classification(\n",
        "        n_samples=n_samples,\n",
        "        n_features=n_features,\n",
        "        n_informative=n_informative,\n",
        "        n_redundant=n_redundant,\n",
        "        n_classes=2,\n",
        "        flip_y=0.1,  # Introduzir ruído\n",
        "        class_sep=0.8,  # Reduzir separação entre classes para maior desafio\n",
        "        random_state=random_state\n",
        "    )\n",
        "\n",
        "    # Converter para DataFrame\n",
        "    if feature_names is None:\n",
        "        feature_names = [f\"feature_{i}\" for i in range(1, n_features + 1)]\n",
        "    X_synthetic = pd.DataFrame(X, columns=feature_names)\n",
        "    y_synthetic = pd.Series(y, name=\"target\")\n",
        "\n",
        "    return X_synthetic, y_synthetic\n",
        "\n",
        "# Gerar dados sintéticos com os mesmos nomes de colunas dos dados de treinamento\n",
        "X_synthetic, y_synthetic = generate_synthetic_data(\n",
        "    n_samples=200,\n",
        "    n_features=X_train_resampled.shape[1],\n",
        "    n_informative=10,\n",
        "    n_redundant=5,\n",
        "    feature_names=X_train_resampled.columns.tolist()\n",
        ")\n",
        "\n",
        "# Visualizar os dados gerados\n",
        "print(\"Exemplo de dados sintéticos:\")\n",
        "print(X_synthetic.head())\n",
        "print(\"\\nDistribuição das classes:\")\n",
        "print(y_synthetic.value_counts())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Teste de Estresse com os dados Sintéticos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iniciando teste de estresse nos modelos...\n",
            "Testando modelo: KNN...\n",
            "O modelo KNN não está ajustado. Treinando com dados fornecidos...\n",
            "Testando modelo: SVM...\n",
            "O modelo SVM não está ajustado. Treinando com dados fornecidos...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\willi\\Documents\\Projetos\\mestrado_mineracao\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\willi\\Documents\\Projetos\\mestrado_mineracao\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testando modelo: Decision Tree...\n",
            "O modelo Decision Tree não está ajustado. Treinando com dados fornecidos...\n",
            "Testando modelo: LVQ...\n",
            "O modelo LVQ não está ajustado. Treinando com dados fornecidos...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\willi\\Documents\\Projetos\\mestrado_mineracao\\venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testando modelo: MLP...\n",
            "O modelo MLP não está ajustado. Treinando com dados fornecidos...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\willi\\Documents\\Projetos\\mestrado_mineracao\\venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testando modelo: Ensemble Neural Network...\n",
            "O modelo Ensemble Neural Network não está ajustado. Treinando com dados fornecidos...\n",
            "Testando modelo: Stacking...\n",
            "O modelo Stacking não está ajustado. Treinando com dados fornecidos...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\willi\\Documents\\Projetos\\mestrado_mineracao\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\willi\\Documents\\Projetos\\mestrado_mineracao\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testando modelo: Random Forest...\n",
            "O modelo Random Forest não está ajustado. Treinando com dados fornecidos...\n",
            "Testando modelo: XGBoost...\n",
            "O modelo XGBoost não está ajustado. Treinando com dados fornecidos...\n",
            "Testando modelo: LightGBM...\n",
            "O modelo LightGBM não está ajustado. Treinando com dados fornecidos...\n",
            "Testes concluídos.\n",
            "Resultados exportados para 'results_stress_test.xlsx'.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(                    Modelo  Acurácia  ACSa  Precisão  Recall  F1-Score  \\\n",
              " 2            Decision Tree      57.0  57.0     59.59    57.0     53.88   \n",
              " 7            Random Forest      57.0  57.0     61.86    57.0     52.09   \n",
              " 8                  XGBoost      57.0  57.0     58.33    57.0     55.21   \n",
              " 3                      LVQ      56.5  56.5     57.41    56.5     55.13   \n",
              " 4                      MLP      55.5  55.5     56.01    55.5     54.54   \n",
              " 5  Ensemble Neural Network      55.5  55.5     55.54    55.5     55.41   \n",
              " 9                 LightGBM      55.0  55.0     55.57    55.0     53.82   \n",
              " 0                      KNN      51.5  51.5     51.64    51.5     50.46   \n",
              " 1                      SVM      50.0  50.0     25.00    50.0     33.33   \n",
              " 6                 Stacking      50.0  50.0     25.00    50.0     33.33   \n",
              " \n",
              "    Total_Amostras  \n",
              " 2             200  \n",
              " 7             200  \n",
              " 8             200  \n",
              " 3             200  \n",
              " 4             200  \n",
              " 5             200  \n",
              " 9             200  \n",
              " 0             200  \n",
              " 1             200  \n",
              " 6             200  ,\n",
              "                     Modelo  Precisão  Recall  F1-Score  Quantidade_Amostras  \\\n",
              " 5  Ensemble Neural Network     56.04    51.0     53.40                  100   \n",
              " 4                      MLP     57.75    41.0     47.95                  100   \n",
              " 3                      LVQ     60.00    39.0     47.27                  100   \n",
              " 9                 LightGBM     57.35    39.0     46.43                  100   \n",
              " 0                      KNN     52.11    37.0     43.27                  100   \n",
              " 8                  XGBoost     61.67    37.0     46.25                  100   \n",
              " 2            Decision Tree     64.58    31.0     41.89                  100   \n",
              " 7            Random Forest     69.44    25.0     36.76                  100   \n",
              " 1                      SVM      0.00     0.0      0.00                  100   \n",
              " 6                 Stacking      0.00     0.0      0.00                  100   \n",
              " \n",
              "    Proporção_Amostras  \n",
              " 5                50.0  \n",
              " 4                50.0  \n",
              " 3                50.0  \n",
              " 9                50.0  \n",
              " 0                50.0  \n",
              " 8                50.0  \n",
              " 2                50.0  \n",
              " 7                50.0  \n",
              " 1                50.0  \n",
              " 6                50.0  ,\n",
              "                     Modelo  Precisão  Recall  F1-Score  Quantidade_Amostras  \\\n",
              " 1                      SVM     50.00   100.0     66.67                  100   \n",
              " 6                 Stacking     50.00   100.0     66.67                  100   \n",
              " 7            Random Forest     54.27    89.0     67.42                  100   \n",
              " 2            Decision Tree     54.61    83.0     65.87                  100   \n",
              " 8                  XGBoost     55.00    77.0     64.17                  100   \n",
              " 3                      LVQ     54.81    74.0     62.98                  100   \n",
              " 9                 LightGBM     53.79    71.0     61.21                  100   \n",
              " 4                      MLP     54.26    70.0     61.14                  100   \n",
              " 0                      KNN     51.16    66.0     57.64                  100   \n",
              " 5  Ensemble Neural Network     55.05    60.0     57.42                  100   \n",
              " \n",
              "    Proporção_Amostras  \n",
              " 1                50.0  \n",
              " 6                50.0  \n",
              " 7                50.0  \n",
              " 2                50.0  \n",
              " 8                50.0  \n",
              " 3                50.0  \n",
              " 9                50.0  \n",
              " 4                50.0  \n",
              " 0                50.0  \n",
              " 5                50.0  )"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.exceptions import NotFittedError\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "\n",
        "def stress_test_models(best_classifiers, X_synthetic, y_synthetic, X_train=None, y_train=None, export_excel=True):\n",
        "    \"\"\"\n",
        "    Realiza testes de estresse nos modelos e gera relatório em Excel com 3 abas, incluindo a métrica ACSa.\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    best_classifiers : dict\n",
        "        Dicionário contendo os modelos treinados\n",
        "    X_synthetic : array-like\n",
        "        Dados sintéticos de features\n",
        "    y_synthetic : array-like\n",
        "        Labels sintéticos correspondentes\n",
        "    X_train : array-like, optional\n",
        "        Dados de treinamento para treinar o modelo caso não esteja ajustado.\n",
        "    y_train : array-like, optional\n",
        "        Labels de treinamento para treinar o modelo caso não esteja ajustado.\n",
        "    export_excel : bool, optional\n",
        "        Se True, exporta os resultados para um arquivo Excel.\n",
        "    \"\"\"\n",
        "    print(\"Iniciando teste de estresse nos modelos...\")\n",
        "\n",
        "    # Dicionários para resultados\n",
        "    results_geral = {\n",
        "        'Modelo': [],\n",
        "        'Acurácia': [],\n",
        "        'ACSa': [],\n",
        "        'Precisão': [],\n",
        "        'Recall': [],\n",
        "        'F1-Score': [],\n",
        "        'Total_Amostras': []\n",
        "    }\n",
        "\n",
        "    results_classe_0 = {\n",
        "        'Modelo': [],\n",
        "        'Precisão': [],\n",
        "        'Recall': [],\n",
        "        'F1-Score': [],\n",
        "        'Quantidade_Amostras': [],\n",
        "        'Proporção_Amostras': []\n",
        "    }\n",
        "\n",
        "    results_classe_1 = {\n",
        "        'Modelo': [],\n",
        "        'Precisão': [],\n",
        "        'Recall': [],\n",
        "        'F1-Score': [],\n",
        "        'Quantidade_Amostras': [],\n",
        "        'Proporção_Amostras': []\n",
        "    }\n",
        "\n",
        "    for nome_modelo, modelo in best_classifiers.items():\n",
        "        print(f\"Testando modelo: {nome_modelo}...\")\n",
        "        try:\n",
        "            # Verifica se o modelo está treinado\n",
        "            y_pred = modelo.predict(X_synthetic)\n",
        "        except NotFittedError:\n",
        "            if X_train is not None and y_train is not None:\n",
        "                print(f\"O modelo {nome_modelo} não está ajustado. Treinando com dados fornecidos...\")\n",
        "                modelo.fit(X_train, y_train)\n",
        "                y_pred = modelo.predict(X_synthetic)\n",
        "            else:\n",
        "                print(f\"O modelo {nome_modelo} não está ajustado e não foram fornecidos dados de treinamento.\")\n",
        "                continue\n",
        "\n",
        "        # Métricas gerais\n",
        "        accuracy = accuracy_score(y_synthetic, y_pred)\n",
        "        precision = precision_score(y_synthetic, y_pred, average='weighted')\n",
        "        recall = recall_score(y_synthetic, y_pred, average='weighted')\n",
        "        f1 = f1_score(y_synthetic, y_pred, average='weighted')\n",
        "\n",
        "        # Métricas por classe\n",
        "        precision_per_class = precision_score(y_synthetic, y_pred, average=None)\n",
        "        recall_per_class = recall_score(y_synthetic, y_pred, average=None)\n",
        "        f1_per_class = f1_score(y_synthetic, y_pred, average=None)\n",
        "        amostras_por_classe = dict(zip(*np.unique(y_synthetic, return_counts=True)))\n",
        "        total_amostras = len(y_synthetic)\n",
        "\n",
        "        # Cálculo da ACSa\n",
        "        acsa = sum(\n",
        "            (amostras_por_classe.get(classe, 0) / total_amostras) * recall_per_class[idx]\n",
        "            for idx, classe in enumerate([0, 1])\n",
        "        )\n",
        "\n",
        "        # Adicionar resultados gerais\n",
        "        results_geral['Modelo'].append(nome_modelo)\n",
        "        results_geral['Acurácia'].append(round(accuracy * 100, 2))\n",
        "        results_geral['ACSa'].append(round(acsa * 100, 2))\n",
        "        results_geral['Precisão'].append(round(precision * 100, 2))\n",
        "        results_geral['Recall'].append(round(recall * 100, 2))\n",
        "        results_geral['F1-Score'].append(round(f1 * 100, 2))\n",
        "        results_geral['Total_Amostras'].append(total_amostras)\n",
        "\n",
        "        # Resultados Classe 0\n",
        "        results_classe_0['Modelo'].append(nome_modelo)\n",
        "        results_classe_0['Precisão'].append(round(precision_per_class[0] * 100, 2))\n",
        "        results_classe_0['Recall'].append(round(recall_per_class[0] * 100, 2))\n",
        "        results_classe_0['F1-Score'].append(round(f1_per_class[0] * 100, 2))\n",
        "        results_classe_0['Quantidade_Amostras'].append(amostras_por_classe.get(0, 0))\n",
        "        results_classe_0['Proporção_Amostras'].append(\n",
        "            round(amostras_por_classe.get(0, 0) / total_amostras * 100, 2)\n",
        "        )\n",
        "\n",
        "        # Resultados Classe 1\n",
        "        results_classe_1['Modelo'].append(nome_modelo)\n",
        "        results_classe_1['Precisão'].append(round(precision_per_class[1] * 100, 2))\n",
        "        results_classe_1['Recall'].append(round(recall_per_class[1] * 100, 2))\n",
        "        results_classe_1['F1-Score'].append(round(f1_per_class[1] * 100, 2))\n",
        "        results_classe_1['Quantidade_Amostras'].append(amostras_por_classe.get(1, 0))\n",
        "        results_classe_1['Proporção_Amostras'].append(\n",
        "            round(amostras_por_classe.get(1, 0) / total_amostras * 100, 2)\n",
        "        )\n",
        "\n",
        "    # Criar DataFrames\n",
        "    df_geral = pd.DataFrame(results_geral).sort_values('Acurácia', ascending=False)\n",
        "    df_classe_0 = pd.DataFrame(results_classe_0).sort_values('Recall', ascending=False)\n",
        "    df_classe_1 = pd.DataFrame(results_classe_1).sort_values('Recall', ascending=False)\n",
        "\n",
        "    print(\"Testes concluídos.\")\n",
        "    \n",
        "    # Exportar para Excel\n",
        "    if export_excel:\n",
        "        with pd.ExcelWriter('results_stress_test.xlsx', engine='openpyxl') as writer:\n",
        "            df_geral.to_excel(writer, sheet_name='Geral', index=False)\n",
        "            df_classe_0.to_excel(writer, sheet_name='Classe_0', index=False)\n",
        "            df_classe_1.to_excel(writer, sheet_name='Classe_1', index=False)\n",
        "        print(\"Resultados exportados para 'results_stress_test.xlsx'.\")\n",
        "\n",
        "    return df_geral, df_classe_0, df_classe_1\n",
        "\n",
        "\n",
        "stress_test_models(best_classifiers, X_synthetic, y_synthetic, X_train_resampled, y_train_resampled, export_excel=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Explainable AI (XAi)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vamos usar o SHAP para explicar o modelo Random Forest e o LIME para explicar o modelo XGBoost, que são dois dos modelos com bons desepenhos desempenho segundo a planilha \"results_with_cost_benefit\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exemplo de Explicação com SHAP no KNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Utilizamos 30 amostras no SHAP para ganhar tempo e velocidade.\n",
        "- Com 30 amostras demora 10 minutos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [10:56<00:00, 21.89s/it]\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1150x660 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import shap\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Criar e treinar o modelo KNN\n",
        "knn = KNeighborsClassifier(n_neighbors=1, p=1)\n",
        "knn.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "# Usar um subconjunto menor de dados para o explainer\n",
        "background = shap.sample(X_train_resampled, 30)  # Amostra menor para melhorar a velocidade\n",
        "explainer = shap.KernelExplainer(knn.predict_proba, background)\n",
        "\n",
        "# Calcular os valores SHAP para um subconjunto do conjunto de teste\n",
        "X_test_subset = shap.sample(X_test, 30)  # Usar um subconjunto do teste\n",
        "shap_values = explainer.shap_values(X_test_subset)\n",
        "\n",
        "# Visualizar os valores SHAP\n",
        "shap.summary_plot(shap_values, X_test_subset)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exemplo de Explicação com LIME no XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('f7 > -0.17', 0.27566831421468757),\n",
              " ('f9 <= -0.23', -0.24191387490672223),\n",
              " ('-0.51 < f5 <= -0.02', -0.19103915062299198),\n",
              " ('f8 > -0.25', 0.1802652317935608),\n",
              " ('-0.21 < f6 <= 0.53', -0.14038283188613804),\n",
              " ('f21 <= -0.33', -0.03286149457164773),\n",
              " ('f25 > -0.20', -0.03095130678033942),\n",
              " ('f27 <= -0.17', 0.03081904735348857),\n",
              " ('f22 <= -0.32', 0.027906729980667913),\n",
              " ('f24 > -0.22', 0.02680318617097293)]"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import lime\n",
        "import lime.lime_tabular\n",
        "from xgboost import XGBClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display, Image\n",
        "\n",
        "# Criar e treinar o modelo XGBoost com os parâmetros especificados\n",
        "model_xgb = XGBClassifier(n_estimators=188)\n",
        "model_xgb.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "# Criar o explainer do LIME\n",
        "explainer = lime.lime_tabular.LimeTabularExplainer(\n",
        "    training_data=X_train_resampled.values,\n",
        "    feature_names=X_train_resampled.columns,\n",
        "    class_names=['N', 'P'],  # Ajuste conforme suas classes\n",
        "    mode='classification'\n",
        ")\n",
        "\n",
        "# Explicar uma previsão específica (por exemplo, a primeira instância do conjunto de teste)\n",
        "i = 0  # Índice da instância a ser explicada\n",
        "exp = explainer.explain_instance(X_test.iloc[i].values, model_xgb.predict_proba)\n",
        "\n",
        "# Gerar a figura com os resultados do LIME\n",
        "fig = exp.as_pyplot_figure(label=1)  # label=1 para a classe positiva\n",
        "plt.tight_layout()\n",
        "\n",
        "# Salvar a figura\n",
        "plt.savefig('lime_results.png', dpi=300, bbox_inches='tight')\n",
        "\n",
        "# Mostrar a figura na célula de saída\n",
        "display(fig)\n",
        "plt.close()\n",
        "\n",
        "# Mostrar as características mais importantes\n",
        "print(\"Características mais importantes:\")\n",
        "exp.as_list()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Este resultado do LIME (Local Interpretable Model-agnostic Explanations) fornece uma explicação local para uma previsão específica feita por um modelo de machine learning. \n",
        "\n",
        "Cada linha representa uma característica (feature) e sua contribuição para a previsão do modelo para uma instância particular. \n",
        "\n",
        "Vamos analisar os componentes principais:\n",
        "\n",
        "1) Interpretação das Características\n",
        "\n",
        "1. **f7 > -0.17** (0.2757): Esta é a característica mais influente. Quando f7 é maior que -0.17, isso aumenta a probabilidade da previsão em aproximadamente 27.57%.\n",
        "\n",
        "2. **f9 <= -0.23** (-0.2419): A segunda característica mais importante. Quando f9 é menor ou igual a -0.23, isso diminui a probabilidade da previsão em cerca de 24.19%.\n",
        "\n",
        "3. **-0.51 < f5 <= -0.02** (-0.1910): Quando f5 está entre -0.51 e -0.02, isso reduz a probabilidade da previsão em aproximadamente 19.10%.\n",
        "\n",
        "4. **f8 > -0.25** (0.1803): Se f8 é maior que -0.25, isso aumenta a probabilidade da previsão em cerca de 18.03%.\n",
        "\n",
        "5. **-0.21 < f6 <= 0.53** (-0.1404): Quando f6 está entre -0.21 e 0.53, isso diminui a probabilidade da previsão em aproximadamente 14.04%.\n",
        "\n",
        "2) Características Menos Influentes\n",
        "\n",
        "As características restantes (f21, f25, f27, f22, f24) têm um impacto menor na previsão, com contribuições absolutas abaixo de 0.05 ou 5%.\n",
        "\n",
        "3) Observações Gerais\n",
        "\n",
        "- Os valores positivos indicam que a característica aumenta a probabilidade da previsão, enquanto os negativos a diminuem.\n",
        "- As características estão ordenadas por magnitude de impacto, do mais influente ao menos influente.\n",
        "- O LIME criou intervalos para algumas características contínuas (por exemplo, f5 e f6), o que pode ajudar a interpretar melhor o comportamento do modelo em diferentes faixas de valores.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ht5NaQt7eJ-C"
      },
      "source": [
        "# Roteiro"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBsbCN7EdMOY"
      },
      "source": [
        "- Registro dos resultados em **dataframe** (FEITO)\n",
        "- Visualização de Resultados: Gráficos de caixa (boxplot), barras, etc. (A FAZER)\n",
        "- Análise Estatística: Relatório de classificação e testes de significância estatística. (FEITO)\n",
        "- Aplicar o protocolo utilizado de comparação de classificadores de Janez Demsar.(FEITO)\n",
        "- Apresentar desempenhos de treinamento e teste para todos os modelos. (FEITO)\n",
        "- Análise de Custo-Benefício: Avaliar os recursos computacionais utilizados por cada modelo (tempo de processamento e memória) em relação ao desempenho alcançado. (FEITO)\n",
        "- Teste de Estresse dos Modelos: Realizar testes com dados novos e desconhecidos para avaliar a robustez dos modelos. (FEITO)\n",
        "- Métricas de Complexidade do Modelo: Avaliar a complexidade dos modelos, como número de parâmetros e tempo de inferência. (FEITO)\n",
        "- Explainable AI (XAI): Explicar as previsões de pelo menos dois dos modelos utilizando ferramentas de XAI, como SHAP ou LIME, para aumentar a compreensão sobre os fatores que influenciam as decisões dos modelos. Escolher o melhor modelo a partir da comparação estatística realizada para aplicar o XAI. (FEITO)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0c70u2REOBdF"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "wJD6QN8jntDk",
        "5lroaa666bSO",
        "RGeDInlGjm2L"
      ],
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
